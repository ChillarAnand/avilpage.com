<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Avil Page</title><link>https://avilpage.com/</link><description>Avil Page - Personal &amp; tech blog by Chillar Anand</description><atom:link href="https://avilpage.com/rss.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Wed, 21 Dec 2022 02:01:31 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Hands-on RabbitMQ Tutorial</title><link>https://avilpage.com/2022/12/hands-on-rabbitmq-tutorial.html</link><dc:creator>Chillar Anand</dc:creator><description>&lt;p&gt;A short hands-on guide to get started with RabbitMQ for people who are in a hurry.&lt;/p&gt;
&lt;h4&gt;What is RabbitMQ?&lt;/h4&gt;
&lt;p&gt;&lt;img src="https://avilpage.com/images/rabbitmq-overview.png" alt="RabbitMQ"&gt;&lt;/p&gt;
&lt;p style="text-align:center;"&gt;Image Credit: CloudAMQP&lt;/p&gt;

&lt;p&gt;RabbitMQ&lt;sup id="fnref:wikipedia-rabbitmq"&gt;&lt;a class="footnote-ref" href="https://avilpage.com/2022/12/hands-on-rabbitmq-tutorial.html#fn:wikipedia-rabbitmq"&gt;1&lt;/a&gt;&lt;/sup&gt; is an open-source message broker software that implements the Advanced Message Queuing Protocol (AMQP). With RabbitMQ, producer and consumer applications can communicate asynchronously, and they will be completely decoupled. &lt;/p&gt;
&lt;h4&gt;RabbitMQ Terminology&lt;/h4&gt;
&lt;p&gt;&lt;b&gt;Producer&lt;/b&gt;: A producer is a client that publishes messages to the RabbitMQ broker. Producers write data to exchanges.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Consumer&lt;/b&gt;: A consumer is a client that subscribes to queues and processes the messages. Consumers read data from queues.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Queue&lt;/b&gt;: A queue is a buffer that stores messages. A queue is bound to an exchange and receives messages from it.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Exchange&lt;/b&gt;: An exchange is a message routing agent that receives messages from producers and routes them to queues.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Binding&lt;/b&gt;: A binding is a link between an exchange and a queue. It is created with a routing key. The producer sends messages to the exchange with a routing key. The exchange routes the message to the queues that are bound with a matching routing key.&lt;/p&gt;
&lt;h4&gt;RabbitMQ Setup&lt;/h4&gt;
&lt;p&gt;We can use the official RabbitMQ docker image to run RabbitMQ locally. We can run the following command to start a RabbitMQ container:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ docker run --rm --name&lt;span class="o"&gt;=&lt;/span&gt;rabbitmq -p &lt;span class="m"&gt;15672&lt;/span&gt;:15672 -p &lt;span class="m"&gt;5672&lt;/span&gt;:5672 rabbitmq:3-management
&lt;/pre&gt;
&lt;p&gt;This image has rabbitmq management plugin enabled. We can access the management UI at &lt;a href="http://localhost:15672"&gt;http://localhost:15672&lt;/a&gt;. The default username and password are both &lt;code&gt;guest&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;It also has &lt;code&gt;rabbitmqadmin&lt;/code&gt; command line tool installed, which can manage RabbitMQ. &lt;/p&gt;
&lt;h4&gt;Passing Messages from UI&lt;/h4&gt;
&lt;p&gt;We can use the management UI to send and receive messages. We can create a new queue and exchange from the &lt;code&gt;Queues&lt;/code&gt; section.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://avilpage.com/images/rabbitmq-queue.png" alt="RabbitMQ Queue"&gt;&lt;/p&gt;
&lt;p&gt;Once a queue is created, we can publish and consume messages from that queue. &lt;/p&gt;
&lt;p&gt;&lt;img src="https://avilpage.com/images/rabbitmq-publish.png" alt="RabbitMQ Publish"&gt;&lt;/p&gt;
&lt;h4&gt;Passing Messages from CLI&lt;/h4&gt;
&lt;p&gt;Instead of using web UI, we can use &lt;code&gt;rabbitmqadmin&lt;/code&gt; CLI tool&lt;sup id="fnref:rabbitmq-cli"&gt;&lt;a class="footnote-ref" href="https://avilpage.com/2022/12/hands-on-rabbitmq-tutorial.html#fn:rabbitmq-cli"&gt;2&lt;/a&gt;&lt;/sup&gt; to send and receive messages. Let's create a topic exchange and a queue. &lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ docker &lt;span class="nb"&gt;exec&lt;/span&gt; rabbitmq rabbitmqadmin &lt;span class="nb"&gt;declare&lt;/span&gt; exchange &lt;span class="nv"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;direct &lt;span class="nv"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;orders
&lt;span class="c1"&gt;# =&amp;gt; exchange declared&lt;/span&gt;
&lt;/pre&gt;
&lt;pre class="code literal-block"&gt;$ docker &lt;span class="nb"&gt;exec&lt;/span&gt; rabbitmq rabbitmqadmin &lt;span class="nb"&gt;declare&lt;/span&gt; queue &lt;span class="nv"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;orders
&lt;span class="c1"&gt;# =&amp;gt; queue declared&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;Let's publish a message to the exchange:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ docker &lt;span class="nb"&gt;exec&lt;/span&gt; rabbitmq rabbitmqadmin publish &lt;span class="nv"&gt;routing_key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;orders &lt;span class="nv"&gt;payload&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'dummy message'&lt;/span&gt;
&lt;span class="c1"&gt;# =&amp;gt; Message published&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;To receive messages from the queue, we can use the following command:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ docker &lt;span class="nb"&gt;exec&lt;/span&gt; rabbitmq rabbitmqadmin get &lt;span class="nv"&gt;queue&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;orders
&lt;/pre&gt;
&lt;p&gt;&lt;img src="https://avilpage.com/images/rabbitmq-get-message.png" alt="RabbitMQ CLI"&gt;&lt;/p&gt;
&lt;h4&gt;Passing Messages from REST API&lt;/h4&gt;
&lt;p&gt;We can also use REST API to send and receive messages. Let's create a new exchange and queue:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ curl -u guest:guest -X PUT -H &lt;span class="s2"&gt;"content-type:application/json"&lt;/span&gt; -d &lt;span class="s1"&gt;'{"type":"direct"}'&lt;/span&gt; http://localhost:15672/api/exchanges/%2f/orders
&lt;/pre&gt;
&lt;pre class="code literal-block"&gt;$ curl -u guest:guest -X PUT -H &lt;span class="s2"&gt;"content-type:application/json"&lt;/span&gt; -d &lt;span class="s1"&gt;'{"type":"topic", "durable": true}'&lt;/span&gt; http://localhost:15672/api/queues/%2f/orders
&lt;/pre&gt;
&lt;p&gt;We can publish a message to the exchange:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ curl -u guest:guest -X POST -H &lt;span class="s2"&gt;"content-type:application/json"&lt;/span&gt; -d &lt;span class="s1"&gt;'{"routing_key":"orders","payload":"dummy message","payload_encoding":"string", "properties": {} }'&lt;/span&gt; http://localhost:15672/api/exchanges/%2f/orders/publish
&lt;/pre&gt;
&lt;p&gt;To receive messages from the queue, we can use the following command:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ curl -u guest:guest -X GET http://localhost:15672/api/queues/%2f/orders/get
&lt;/pre&gt;
&lt;h4&gt;Conclusion&lt;/h4&gt;
&lt;p&gt;In this post, we have seen how to get started with RabbitMQ. We have seen how to use the management UI, CLI and REST API to send and receive messages.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:wikipedia-rabbitmq"&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/RabbitMQ"&gt;https://en.wikipedia.org/wiki/RabbitMQ&lt;/a&gt; &lt;a class="footnote-backref" href="https://avilpage.com/2022/12/hands-on-rabbitmq-tutorial.html#fnref:wikipedia-rabbitmq" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:rabbitmq-cli"&gt;
&lt;p&gt;&lt;a href="https://www.rabbitmq.com/management-cli.html"&gt;https://www.rabbitmq.com/management-cli.html&lt;/a&gt; &lt;a class="footnote-backref" href="https://avilpage.com/2022/12/hands-on-rabbitmq-tutorial.html#fnref:rabbitmq-cli" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description><category>rabbitmq</category><category>tutorial</category><guid>https://avilpage.com/2022/12/hands-on-rabbitmq-tutorial.html</guid><pubDate>Tue, 20 Dec 2022 23:42:21 GMT</pubDate></item><item><title>Hands-on Apache Kafka Tutorial</title><link>https://avilpage.com/2022/12/hands-on-apache-kafka-tutorial.html</link><dc:creator>Chillar Anand</dc:creator><description>&lt;p&gt;A short hands-on guide to get started with Apache Kafka for people who are in a hurry.&lt;/p&gt;
&lt;p&gt;In this guide, we will learn what is Apache Kafka, how to install and run it. We will also learn how to create/modify a topic and produce/consume messages from it.&lt;/p&gt;
&lt;h4&gt;What is Apache Kafka?&lt;/h4&gt;
&lt;p&gt;&lt;img src="https://avilpage.com/images/kafka-overview.jpg" alt="Apache Kafka"&gt;&lt;/p&gt;
&lt;p&gt;Apache Kafka&lt;sup id="fnref:wikipedia apache kafka"&gt;&lt;a class="footnote-ref" href="https://avilpage.com/2022/12/hands-on-apache-kafka-tutorial.html#fn:wikipedia%20apache%20kafka"&gt;1&lt;/a&gt;&lt;/sup&gt; is a distributed event store and streaming-processing platform. It is used to
build real-time data pipelines and streaming apps. It is horizontally scalable, fault-tolerant, and has high throughput.&lt;/p&gt;
&lt;h4&gt;Kafka Terminology&lt;/h4&gt;
&lt;p&gt;&lt;b&gt;Topic&lt;/b&gt;: A topic is a category or feed name to which records are published/consumed. It is configured with a set of
key-value pairs called topic configuration.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Producer&lt;/b&gt;: A producer is a client that publishes records to the Kafka cluster. Producers write data to topics and
partitions.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Consumer&lt;/b&gt;: A consumer is a client that subscribes to topics and processes the records. Consumers read data from
topics and partitions.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Consumer Group&lt;/b&gt;: A consumer group is a group of consumers that share a common purpose. Consumer groups enable a
pool of processes to divide the work of consuming and processing records.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Broker&lt;/b&gt;: A broker is a server that hosts a set of topics/partitions. It receives data from producers and sends
data to consumers.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;ZooKeeper&lt;/b&gt;: ZooKeeper is used to store the cluster configuration and the state of the cluster. All Kafka brokers
connect to ZooKeeper.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Kraft&lt;/b&gt;: Kraft(Apache Kafka Raft) is a consensus protocol that is used to manage the metadata of the Kafka cluster.
It is introduced to remove dependency on ZooKeeper.&lt;/p&gt;
&lt;h4&gt;Installing Apache Kafka&lt;/h4&gt;
&lt;p&gt;We can use cp-all-in-one&lt;sup id="fnref:cp-all-in-one"&gt;&lt;a class="footnote-ref" href="https://avilpage.com/2022/12/hands-on-apache-kafka-tutorial.html#fn:cp-all-in-one"&gt;2&lt;/a&gt;&lt;/sup&gt; docker compose files to run Apache Kafka locally. This image contains all the
components of Confluent Platform including Apache Kafka, Apache Zookeeper, Confluent Schema Registry, Confluent REST
Proxy, Confluent Control Center, and others.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ git clone https://github.com/confluentinc/cp-all-in-one
$ &lt;span class="nb"&gt;cd&lt;/span&gt; cp-all-in-one/cp-all-in-one
$ docker-compose up
&lt;/pre&gt;
&lt;p&gt;Confluent Control Center is a web UI to manage and monitor Apache Kafka.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://avilpage.com/images/kafka-control-center.png" alt="Kafka Control Center"&gt;&lt;/p&gt;
&lt;p&gt;We can visit it &lt;a href="http://localhost:9021"&gt;http://localhost:9021&lt;/a&gt; and monitor the cluster from this UI.&lt;/p&gt;
&lt;h4&gt;Producing and Consuming Messages&lt;/h4&gt;
&lt;p&gt;Kafka stores messages in topics. A topic is a category or feed name to which messages are published/consumed.&lt;/p&gt;
&lt;p&gt;Let us create a topic called &lt;code&gt;test&lt;/code&gt; with &lt;code&gt;kafka-topics&lt;/code&gt; command.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ docker-compose &lt;span class="nb"&gt;exec&lt;/span&gt; broker kafka-topics --bootstrap-server localhost:9092 --topic &lt;span class="nb"&gt;test&lt;/span&gt; --create 
&lt;/pre&gt;
&lt;p&gt;This will create a topic called &lt;code&gt;test&lt;/code&gt; with a single partition and a replication factor of 1. In multi-node cluster, we
can use &lt;code&gt;--replication-factor&lt;/code&gt;, &lt;code&gt;--partitions&lt;/code&gt; to specify the number of replicas/partitions for the topic.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ docker-compose &lt;span class="nb"&gt;exec&lt;/span&gt; broker kafka-topics --bootstrap-server localhost:9092 --topic &lt;span class="nb"&gt;test&lt;/span&gt; --partitions &lt;span class="m"&gt;3&lt;/span&gt; --replication-factor &lt;span class="m"&gt;2&lt;/span&gt; --create --if-not-exists
&lt;/pre&gt;
&lt;p&gt;To produce messages to a topic named &lt;code&gt;test&lt;/code&gt;, we can use &lt;code&gt;kafka-console-producer&lt;/code&gt; and add messages to the topic:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ docker-compose &lt;span class="nb"&gt;exec&lt;/span&gt; broker kafka-console-producer --broker-list localhost:9092 --topic &lt;span class="nb"&gt;test&lt;/span&gt;

&amp;gt;order received
&amp;gt;order updated
&amp;gt;order shipped
&amp;gt;order delivered
&amp;gt;&lt;span class="o"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;"status"&lt;/span&gt;: &lt;span class="s2"&gt;"completed"&lt;/span&gt;&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;To consume messages from the same topic:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ docker-compose &lt;span class="nb"&gt;exec&lt;/span&gt; broker kafka-console-consumer --bootstrap-server localhost:9092 --topic &lt;span class="nb"&gt;test&lt;/span&gt; --from-beginning

order received
order updated
order shipped
order delivered
&lt;span class="o"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;"status"&lt;/span&gt;: &lt;span class="s2"&gt;"completed"&lt;/span&gt;&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;Since we have not defined schema for the messages, Kafka will store the messages as byte arrays. We can explicitly define the schema for the messages using Confluent Schema Registry if required.&lt;/p&gt;
&lt;p&gt;We can list all the topics in cluster using &lt;code&gt;kafka-topics&lt;/code&gt;:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ docker-compose &lt;span class="nb"&gt;exec&lt;/span&gt; broker kafka-topics --bootstrap-server localhost:9092 --list

default_ksql_processing_log
docker-connect-configs
docker-connect-offsets
docker-connect-status
&lt;span class="nb"&gt;test&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;To show details of a topic:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ docker-compose &lt;span class="nb"&gt;exec&lt;/span&gt; broker kafka-topics --bootstrap-server localhost:9092 --describe --topic &lt;span class="nb"&gt;test&lt;/span&gt;

Topic: &lt;span class="nb"&gt;test&lt;/span&gt; TopicId: 7CckqkXsQXCNY0MNHYRv2w PartitionCount: &lt;span class="m"&gt;1&lt;/span&gt;   ReplicationFactor: &lt;span class="m"&gt;1&lt;/span&gt;    Configs: 
    Topic: &lt;span class="nb"&gt;test&lt;/span&gt; Partition: &lt;span class="m"&gt;0&lt;/span&gt;    Leader: &lt;span class="m"&gt;1&lt;/span&gt;   Replicas: &lt;span class="m"&gt;1&lt;/span&gt; Isr: &lt;span class="m"&gt;1&lt;/span&gt;  Offline:         
&lt;/pre&gt;
&lt;p&gt;By default all messages are stored in the topic for 7 days. We can change this retention period using &lt;code&gt;retention.ms&lt;/code&gt; configuration:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ docker-compose &lt;span class="nb"&gt;exec&lt;/span&gt; broker kafka-topics --bootstrap-server localhost:9092 --alter --topic &lt;span class="nb"&gt;test&lt;/span&gt; --config retention.ms&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;10000&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;To see all the available consumer groups, we can use &lt;code&gt;kafka-consumer-groups&lt;/code&gt;:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ docker-compose &lt;span class="nb"&gt;exec&lt;/span&gt; broker kafka-consumer-groups --bootstrap-server localhost:9092 --list
&lt;/pre&gt;
&lt;h4&gt;Kafka Rest Proxy&lt;/h4&gt;
&lt;p&gt;Kafka Rest Proxy&lt;sup id="fnref:kafka rest proxy"&gt;&lt;a class="footnote-ref" href="https://avilpage.com/2022/12/hands-on-apache-kafka-tutorial.html#fn:kafka%20rest%20proxy"&gt;3&lt;/a&gt;&lt;/sup&gt; is a RESTful interface to Apache Kafka. It provides a RESTful interface to produce
and consume messages, view the state of the cluster, and perform administrative actions without using the native Kafka
protocol or clients.&lt;/p&gt;
&lt;p&gt;To produce messages to a &lt;code&gt;test&lt;/code&gt; topic with curl:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ curl -X POST -H &lt;span class="s2"&gt;"Content-Type: application/vnd.kafka.json.v2+json"&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    --data &lt;span class="s1"&gt;'{"records":[{"value":{"status": "completed"}}]}'&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    &lt;span class="s2"&gt;"http://localhost:8082/topics/test"&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;To consume messages from the same topic:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ curl -X GET -H &lt;span class="s2"&gt;"Accept: application/vnd.kafka.json.v2+json"&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    &lt;span class="s2"&gt;"http://localhost:8082/topics/test"&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;We can dynamically configure Kafka cluster settings as well.&lt;/p&gt;
&lt;p&gt;To change log level of various components of Kafka cluster using Kafka Rest Proxy.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ curl -X POST -H &lt;span class="s2"&gt;"Content-Type: application/vnd.kafka.v2+json"&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    --data &lt;span class="s1"&gt;'{"log4j.logger.kafka.server":"DEBUG"}'&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    &lt;span class="s2"&gt;"http://localhost:8082/config"&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;We can update the log level of various components of Kafka cluster and check the logs.&lt;/p&gt;
&lt;h4&gt;Conclusion&lt;/h4&gt;
&lt;p&gt;In this article, we have seen how to install Apache Kafka locally using Docker. We have also seen how to produce and consume messages using Kafka console commands and Kafka Rest Proxy.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:wikipedia apache kafka"&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Apache_Kafka"&gt;https://en.wikipedia.org/wiki/Apache_Kafka&lt;/a&gt; &lt;a class="footnote-backref" href="https://avilpage.com/2022/12/hands-on-apache-kafka-tutorial.html#fnref:wikipedia%20apache%20kafka" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:cp-all-in-one"&gt;
&lt;p&gt;&lt;a href="https://github.com/confluentinc/cp-all-in-one"&gt;https://github.com/confluentinc/cp-all-in-one&lt;/a&gt; &lt;a class="footnote-backref" href="https://avilpage.com/2022/12/hands-on-apache-kafka-tutorial.html#fnref:cp-all-in-one" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:kafka rest proxy"&gt;
&lt;p&gt;&lt;a href="https://github.com/confluentinc/kafka-rest"&gt;https://github.com/confluentinc/kafka-rest&lt;/a&gt; &lt;a class="footnote-backref" href="https://avilpage.com/2022/12/hands-on-apache-kafka-tutorial.html#fnref:kafka%20rest%20proxy" title="Jump back to footnote 3 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description><category>kafka</category><category>tutorial</category><guid>https://avilpage.com/2022/12/hands-on-apache-kafka-tutorial.html</guid><pubDate>Sat, 17 Dec 2022 01:42:21 GMT</pubDate></item><item><title>Common Crawl on Laptop - Building Web Directory</title><link>https://avilpage.com/2022/12/common-crawl-laptop-web-directory.html</link><dc:creator>Chillar Anand</dc:creator><description>&lt;p&gt;This series of posts discuss processing of common crawl dataset on laptop.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://avilpage.com/2022/11/common-crawl-laptop-extract-subset.html"&gt;Extracting Subset of Common Crawl&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://avilpage.com/2022/12/common-crawl-laptop-web-directory.html"&gt;Building web directory&lt;/a&gt; (this post)&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;Introduction&lt;/h4&gt;
&lt;p&gt;In the earlier post, we have extracted all telugu web page urls to a csv file. In this post, let's explore these urls and build a web directory from it.&lt;/p&gt;
&lt;h4&gt;Explore Data&lt;/h4&gt;
&lt;p&gt;Let's see how many urls are present in the extracted subset of data.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ wc -l telugu.csv
  &lt;span class="m"&gt;852025&lt;/span&gt; telugu.csv 
&lt;/pre&gt;
&lt;p&gt;In the earlier post, we have installed &lt;code&gt;duckdb&lt;/code&gt; and used it for processing parquet files. &lt;code&gt;duckdb&lt;/code&gt; can execute SQL queries directly on csv file. Let's use it to explore the data stored in telugu.csv.&lt;/p&gt;
&lt;p&gt;Let's see how many unique domains are present in the data.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ duckdb -c &lt;span class="s2"&gt;"""&lt;/span&gt;
&lt;span class="s2"&gt;    SELECT COUNT(DISTINCT url_host_name_reversed) as unique_sites&lt;/span&gt;
&lt;span class="s2"&gt;    FROM read_csv('telugu.csv', auto_detect = TRUE);&lt;/span&gt;
&lt;span class="s2"&gt;"""&lt;/span&gt;
┌──────────────┐
│ unique_sites │
├──────────────┤
│ &lt;span class="m"&gt;13632&lt;/span&gt;        │
└──────────────┘
&lt;/pre&gt;
&lt;p&gt;There ~14k unique domains. Let's see page density across these domains.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ duckdb -c &lt;span class="s2"&gt;"""&lt;/span&gt;
&lt;span class="s2"&gt;SELECT count    AS page_count,&lt;/span&gt;
&lt;span class="s2"&gt;COUNT(*) AS sites&lt;/span&gt;
&lt;span class="s2"&gt;FROM (SELECT url_host_name_reversed, COUNT(*) AS count&lt;/span&gt;
&lt;span class="s2"&gt;FROM read_csv('te.csv', auto_detect = TRUE)&lt;/span&gt;
&lt;span class="s2"&gt;GROUP BY url_host_name_reversed) AS t&lt;/span&gt;
&lt;span class="s2"&gt;GROUP BY page_count&lt;/span&gt;
&lt;span class="s2"&gt;ORDER BY page_count;&lt;/span&gt;
&lt;span class="s2"&gt;"""&lt;/span&gt;
┌────────────┬───────┐
│ page_count │ sites │
├────────────┼───────┤
│ &lt;span class="m"&gt;1&lt;/span&gt;          │ &lt;span class="m"&gt;6326&lt;/span&gt;  │
│ &lt;span class="m"&gt;2&lt;/span&gt;          │ &lt;span class="m"&gt;1904&lt;/span&gt;  │
│ &lt;span class="m"&gt;3&lt;/span&gt;          │ &lt;span class="m"&gt;733&lt;/span&gt;   │
│ &lt;span class="m"&gt;4&lt;/span&gt;          │ &lt;span class="m"&gt;459&lt;/span&gt;   │
│ &lt;span class="m"&gt;5&lt;/span&gt;          │ &lt;span class="m"&gt;315&lt;/span&gt;   │
&lt;/pre&gt;
&lt;p&gt;About ~75% of the sites have less than 5 pages. It is highly unlikely that these sites complete content is in Telugu language. After manually checking a few of these sites, I found that there are a lot of false positives. &lt;/p&gt;
&lt;p&gt;In the earlier post, we have extracted all pages where there is Telugu language content. Let's filter out pages where Telugu is &lt;strong&gt;primary&lt;/strong&gt; language.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ duckdb -c &lt;span class="s2"&gt;"""&lt;/span&gt;
&lt;span class="s2"&gt;  COPY (&lt;/span&gt;
&lt;span class="s2"&gt;    SELECT * FROM read_csv('cct.csv', auto_detect=true) &lt;/span&gt;
&lt;span class="s2"&gt;    WHERE content_languages like 'tel%'&lt;/span&gt;
&lt;span class="s2"&gt;  ) TO 'te_primary.csv' (DELIMITER ',', HEADER TRUE);&lt;/span&gt;
&lt;span class="s2"&gt;"""&lt;/span&gt;
&lt;/pre&gt;
&lt;pre class="code literal-block"&gt;$ wc -l te_primary.csv
  &lt;span class="m"&gt;573130&lt;/span&gt; te_primary.csv
&lt;/pre&gt;
&lt;pre class="code literal-block"&gt;$ duckdb -c &lt;span class="s2"&gt;"SELECT COUNT(DISTINCT url_host_name_reversed) as unique_sites FROM read_csv('te_primary.csv', auto_detect = TRUE)"&lt;/span&gt;                           
┌──────────────┐
│ unique_sites │
├──────────────┤
│ &lt;span class="m"&gt;5666&lt;/span&gt;         │
└──────────────┘    
&lt;/pre&gt;
&lt;p&gt;Let's see how page density per domain has changed.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ duckdb -c &lt;span class="s2"&gt;"""&lt;/span&gt;
&lt;span class="s2"&gt;SELECT count    AS page_count,&lt;/span&gt;
&lt;span class="s2"&gt;COUNT(*) AS sites&lt;/span&gt;
&lt;span class="s2"&gt;FROM (SELECT url_host_name_reversed, COUNT(*) AS count&lt;/span&gt;
&lt;span class="s2"&gt;FROM read_csv('te_primary.csv', auto_detect = TRUE)&lt;/span&gt;
&lt;span class="s2"&gt;GROUP BY url_host_name_reversed) AS t&lt;/span&gt;
&lt;span class="s2"&gt;GROUP BY page_count&lt;/span&gt;
&lt;span class="s2"&gt;ORDER BY page_count&lt;/span&gt;
&lt;span class="s2"&gt;;&lt;/span&gt;
&lt;span class="s2"&gt;"""&lt;/span&gt;
┌────────────┬───────┐
│ page_count │ sites │
├────────────┼───────┤
│ &lt;span class="m"&gt;1&lt;/span&gt;          │ &lt;span class="m"&gt;2183&lt;/span&gt;  │
│ &lt;span class="m"&gt;2&lt;/span&gt;          │ &lt;span class="m"&gt;843&lt;/span&gt;   │
│ &lt;span class="m"&gt;3&lt;/span&gt;          │ &lt;span class="m"&gt;235&lt;/span&gt;   │
│ &lt;span class="m"&gt;4&lt;/span&gt;          │ &lt;span class="m"&gt;146&lt;/span&gt;   │
│ &lt;span class="m"&gt;5&lt;/span&gt;          │ &lt;span class="m"&gt;98&lt;/span&gt;    │
&lt;/pre&gt;
&lt;p&gt;Page density remains almost the same. &lt;/p&gt;
&lt;p&gt;Let's filter out sites which have at least 5 pages in Telugu. This will eliminate a lot of false positives. Let's look at the most popular sites from the results.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;   &lt;span class="m"&gt;1&lt;/span&gt;   │ Rank,Domain,Open Page Rank
   &lt;span class="m"&gt;2&lt;/span&gt;   │ &lt;span class="m"&gt;25&lt;/span&gt;,support.google.com,8.55
   &lt;span class="m"&gt;3&lt;/span&gt;   │ &lt;span class="m"&gt;57&lt;/span&gt;,t.me,7.76
   &lt;span class="m"&gt;4&lt;/span&gt;   │ &lt;span class="m"&gt;76&lt;/span&gt;,chrome.google.com,7.49
   &lt;span class="m"&gt;5&lt;/span&gt;   │ &lt;span class="m"&gt;163&lt;/span&gt;,support.mozilla.org,6.99
   &lt;span class="m"&gt;6&lt;/span&gt;   │ &lt;span class="m"&gt;170&lt;/span&gt;,groups.google.com,6.94
&lt;/pre&gt;
&lt;p&gt;A lot of unrelated domains are present here because there might be 10+ pages in telugu in these domains as well. But we don't need these.&lt;/p&gt;
&lt;p&gt;Let's look at only home page(or translated home page) where primary content language is telugu.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ duckdb -c &lt;span class="s2"&gt;"""&lt;/span&gt;
&lt;span class="s2"&gt;  SELECT COUNT(distinct url) &lt;/span&gt;
&lt;span class="s2"&gt;  FROM read_csv('te_primary.csv', auto_detect=true) &lt;/span&gt;
&lt;span class="s2"&gt;  WHERE (url_path = '/' or url_path = '/te/') and url_query is null;&lt;/span&gt;
&lt;span class="s2"&gt;"""&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;Now the domain count has reduced to 6k. Let's export these domains to csv file.&lt;/p&gt;
&lt;p&gt;To categorize these domains, Common-crawl doesn't yet provide any kind of categorisation. For now, we can use Open PageRank to sort these domains based on rank. &lt;/p&gt;
&lt;p&gt;We can download top 10 million domains from Open PageRank&lt;sup id="fnref:pagerank"&gt;&lt;a class="footnote-ref" href="https://avilpage.com/2022/12/common-crawl-laptop-web-directory.html#fn:pagerank"&gt;3&lt;/a&gt;&lt;/sup&gt;. Here is a simple python script to extract telugu domains from the list.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;

&lt;span class="n"&gt;domains_file&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'domains.csv'&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;domains_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'r'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;telugu_domains&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;readlines&lt;/span&gt;&lt;span class="p"&gt;()]&lt;/span&gt;

&lt;span class="n"&gt;telugu_domains&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'.'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;reversed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;domain&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'.'&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;domain&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;telugu_domains&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'t10m.csv'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'Domain'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;isin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;telugu_domains&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;

&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'t10m_telugu.csv'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;Now, we have list of all telugu domains sorted by rank. In the next post, we will use this list to categorize the domains.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:common-crawl"&gt;
&lt;p&gt;&lt;a href="https://commoncrawl.org"&gt;https://commoncrawl.org&lt;/a&gt; &lt;a class="footnote-backref" href="https://avilpage.com/2022/12/common-crawl-laptop-web-directory.html#fnref:common-crawl" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:columnar-index-wiki"&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Column-oriented_DBMS"&gt;https://en.wikipedia.org/wiki/Column-oriented_DBMS&lt;/a&gt; &lt;a class="footnote-backref" href="https://avilpage.com/2022/12/common-crawl-laptop-web-directory.html#fnref:columnar-index-wiki" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:pagerank"&gt;
&lt;p&gt;&lt;a href="https://www.domcop.com/openpagerank"&gt;https://www.domcop.com/openpagerank&lt;/a&gt; &lt;a class="footnote-backref" href="https://avilpage.com/2022/12/common-crawl-laptop-web-directory.html#fnref:pagerank" title="Jump back to footnote 3 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:duckdb"&gt;
&lt;p&gt;&lt;a href="https://duckdb.org"&gt;https://duckdb.org&lt;/a&gt; &lt;a class="footnote-backref" href="https://avilpage.com/2022/12/common-crawl-laptop-web-directory.html#fnref:duckdb" title="Jump back to footnote 4 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description><category>command-line</category><category>common-crawl</category><category>data-analysis</category><guid>https://avilpage.com/2022/12/common-crawl-laptop-web-directory.html</guid><pubDate>Thu, 08 Dec 2022 02:11:39 GMT</pubDate></item><item><title>Common Crawl On Laptop - Extracting Subset Of Data</title><link>https://avilpage.com/2022/11/common-crawl-laptop-extract-subset.html</link><dc:creator>Chillar Anand</dc:creator><description>&lt;p&gt;This series of posts discuss processing of common crawl dataset on laptop.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://avilpage.com/2022/11/common-crawl-laptop-extract-subset.html"&gt;Extracting Subset of Common Crawl&lt;/a&gt; (this post)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://avilpage.com/2022/12/common-crawl-laptop-web-directory.html"&gt;Building web directory&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;Introduction&lt;/h4&gt;
&lt;p&gt;Common Crawl(CC)&lt;sup id="fnref:common-crawl"&gt;&lt;a class="footnote-ref" href="https://avilpage.com/2022/11/common-crawl-laptop-extract-subset.html#fn:common-crawl"&gt;1&lt;/a&gt;&lt;/sup&gt; is an open repository of web containing peta bytes of data since 2008. As the dataset is huge, most of the tutorials use AWS EMR/Athena to process the data.&lt;/p&gt;
&lt;p&gt;In this post, let's learn how to extract a subset of data(entire telugu language web pages) and process it on our local machine.&lt;/p&gt;
&lt;h4&gt;Exploring Common Crawl&lt;/h4&gt;
&lt;p&gt;CC provides monthly data dumps in WARC format. Each crawl consists of about ~3 billion web pages with a compressed size of ~100 TB.&lt;/p&gt;
&lt;p&gt;In addition to WARC files, CC provides index files as well as columnar index&lt;sup id="fnref:columnar-index-wiki"&gt;&lt;a class="footnote-ref" href="https://avilpage.com/2022/11/common-crawl-laptop-extract-subset.html#fn:columnar-index-wiki"&gt;2&lt;/a&gt;&lt;/sup&gt; files so that users can easily search, filter and download the data.&lt;/p&gt;
&lt;h4&gt;Common Crawl Index&lt;/h4&gt;
&lt;p&gt;Each crawl index is spread over 300 files consisting of ~250 GB of data. For this post, let use the latest crawl which is &lt;code&gt;CC-MAIN-2022-40&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The index files can be accessed from AWS S3 or https. We can use aws cli to list all the files along with the sizes.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ aws s3 ls --recursive --human-readable --summarize s3://commoncrawl/cc-index/collections/CC-MAIN-2022-40
&lt;span class="m"&gt;2022&lt;/span&gt;-10-08 &lt;span class="m"&gt;16&lt;/span&gt;:07:59  &lt;span class="m"&gt;621&lt;/span&gt;.9 MiB cc-index/collections/CC-MAIN-2022-40/indexes/cdx-00000.gz
&lt;span class="m"&gt;2022&lt;/span&gt;-10-08 &lt;span class="m"&gt;16&lt;/span&gt;:08:26  &lt;span class="m"&gt;721&lt;/span&gt;.6 MiB cc-index/collections/CC-MAIN-2022-40/indexes/cdx-00001.gz
...
&lt;span class="m"&gt;2022&lt;/span&gt;-10-08 &lt;span class="m"&gt;16&lt;/span&gt;:42:39  &lt;span class="m"&gt;146&lt;/span&gt;.6 MiB cc-index/collections/CC-MAIN-2022-40/indexes/cluster.idx
&lt;span class="m"&gt;2022&lt;/span&gt;-10-08 &lt;span class="m"&gt;16&lt;/span&gt;:42:33   &lt;span class="m"&gt;30&lt;/span&gt; Bytes cc-index/collections/CC-MAIN-2022-40/metadata.yaml

Total Objects: &lt;span class="m"&gt;302&lt;/span&gt;
   Total Size: &lt;span class="m"&gt;236&lt;/span&gt;.1 GiB
&lt;/pre&gt;
&lt;p&gt;Let's download an index file to our local machine and see how the data is arranged. We can use &lt;code&gt;aws&lt;/code&gt; cli to download the data from s3 bucket or use wget to download it from https endpoint.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span class="c1"&gt;# from s3&lt;/span&gt;
$ aws s3 cp s3://commoncrawl/cc-index/collections/CC-MAIN-2022-40/indexes/cdx-00000.gz .

&lt;span class="c1"&gt;# from https&lt;/span&gt;
$ wget https://data.commoncrawl.org/cc-index/collections/CC-MAIN-2022-40/indexes/cdx-00000.gz
&lt;/pre&gt;
&lt;p&gt;Let's print top five lines of the file.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ zcat &amp;lt; cdx-00000.gz &lt;span class="p"&gt;|&lt;/span&gt; head -n &lt;span class="m"&gt;5&lt;/span&gt;
&lt;span class="m"&gt;0&lt;/span&gt;,1,184,137&lt;span class="o"&gt;)&lt;/span&gt;/1klikbet &lt;span class="m"&gt;20221005193707&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;"url"&lt;/span&gt;: &lt;span class="s2"&gt;"http://137.184.1.0/1klikbet/"&lt;/span&gt;, &lt;span class="s2"&gt;"mime"&lt;/span&gt;: &lt;span class="s2"&gt;"text/html"&lt;/span&gt;, &lt;span class="s2"&gt;"mime-detected"&lt;/span&gt;: &lt;span class="s2"&gt;"text/html"&lt;/span&gt;, &lt;span class="s2"&gt;"status"&lt;/span&gt;: &lt;span class="s2"&gt;"200"&lt;/span&gt;, &lt;span class="s2"&gt;"digest"&lt;/span&gt;: &lt;span class="s2"&gt;"XTKGORHKLZCHDBBOMYCYYIZVRPMXNRII"&lt;/span&gt;, &lt;span class="s2"&gt;"length"&lt;/span&gt;: &lt;span class="s2"&gt;"7065"&lt;/span&gt;, &lt;span class="s2"&gt;"offset"&lt;/span&gt;: &lt;span class="s2"&gt;"83437"&lt;/span&gt;, &lt;span class="s2"&gt;"filename"&lt;/span&gt;: &lt;span class="s2"&gt;"crawl-data/CC-MAIN-2022-40/segments/1664030337663.75/warc/CC-MAIN-20221005172112-20221005202112-00011.warc.gz"&lt;/span&gt;, &lt;span class="s2"&gt;"charset"&lt;/span&gt;: &lt;span class="s2"&gt;"UTF-8"&lt;/span&gt;, &lt;span class="s2"&gt;"languages"&lt;/span&gt;: &lt;span class="s2"&gt;"ind"&lt;/span&gt;&lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="m"&gt;0&lt;/span&gt;,1,184,137&lt;span class="o"&gt;)&lt;/span&gt;/7meter &lt;span class="m"&gt;20221005192131&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;"url"&lt;/span&gt;: &lt;span class="s2"&gt;"http://137.184.1.0/7meter/"&lt;/span&gt;, &lt;span class="s2"&gt;"mime"&lt;/span&gt;: &lt;span class="s2"&gt;"text/html"&lt;/span&gt;, &lt;span class="s2"&gt;"mime-detected"&lt;/span&gt;: &lt;span class="s2"&gt;"text/html"&lt;/span&gt;, &lt;span class="s2"&gt;"status"&lt;/span&gt;: &lt;span class="s2"&gt;"200"&lt;/span&gt;, &lt;span class="s2"&gt;"digest"&lt;/span&gt;: &lt;span class="s2"&gt;"KUJAMRT6MXYR3RTWRJTIWJ5T2ZUB3EBH"&lt;/span&gt;, &lt;span class="s2"&gt;"length"&lt;/span&gt;: &lt;span class="s2"&gt;"7456"&lt;/span&gt;, &lt;span class="s2"&gt;"offset"&lt;/span&gt;: &lt;span class="s2"&gt;"142680"&lt;/span&gt;, &lt;span class="s2"&gt;"filename"&lt;/span&gt;: &lt;span class="s2"&gt;"crawl-data/CC-MAIN-2022-40/segments/1664030337663.75/warc/CC-MAIN-20221005172112-20221005202112-00182.warc.gz"&lt;/span&gt;, &lt;span class="s2"&gt;"charset"&lt;/span&gt;: &lt;span class="s2"&gt;"UTF-8"&lt;/span&gt;, &lt;span class="s2"&gt;"languages"&lt;/span&gt;: &lt;span class="s2"&gt;"ind"&lt;/span&gt;&lt;span class="o"&gt;}&lt;/span&gt;
...
&lt;/pre&gt;
&lt;p&gt;The last column of each line contains the language information. We can use these index files, and we can  extract all the lines containing &lt;code&gt;tel&lt;/code&gt; language code.&lt;/p&gt;
&lt;h4&gt;Columnar Index&lt;/h4&gt;
&lt;p&gt;We can also use columnar index to filter out telugu language web pages. Let's download a single file from the index.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span class="c1"&gt;# from s3&lt;/span&gt;
$ aws s3 cp s3://commoncrawl/cc-index/table/cc-main/warc/crawl&lt;span class="o"&gt;=&lt;/span&gt;CC-MAIN-2022-40/subset&lt;span class="o"&gt;=&lt;/span&gt;warc/part-00000-26160df0-1827-4787-a515-95ecaa2c9688.c000.gz.parquet .

&lt;span class="c1"&gt;# from https&lt;/span&gt;
$ wget https://data.commoncrawl.org/cc-index/table/cc-main/warc/crawl&lt;span class="o"&gt;=&lt;/span&gt;CC-MAIN-2022-40/subset&lt;span class="o"&gt;=&lt;/span&gt;warc/part-00000-26160df0-1827-4787-a515-95ecaa2c9688.c000.gz.parquet
&lt;/pre&gt;
&lt;p&gt;We can use Python pandas to read the parquet file and filter out telugu language web pages. Columnar index has &lt;code&gt;content_languages&lt;/code&gt; column which can be used to filter out telugu pages.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ python -c &lt;span class="s2"&gt;"""&lt;/span&gt;
&lt;span class="s2"&gt;import pandas as pd&lt;/span&gt;
&lt;span class="s2"&gt;filename = 'part-00000-26160df0-1827-4787-a515-95ecaa2c9688.c000.gz.parquet'&lt;/span&gt;
&lt;span class="s2"&gt;df = pd.read_parquet(filename)&lt;/span&gt;
&lt;span class="s2"&gt;df = df[df['content_languages'].str.startswith('tel', na=False)]&lt;/span&gt;
&lt;span class="s2"&gt;df.to_csv('telugu.csv')&lt;/span&gt;
&lt;span class="s2"&gt;"""&lt;/span&gt;
&lt;/pre&gt;
&lt;h4&gt;Improving Performance&lt;/h4&gt;
&lt;h5&gt;Faster Downloads&lt;/h5&gt;
&lt;p&gt;I have used Macbook M1 with local ISP to download and extract the index. It took around 7 minutes to download a single file and 2 minutes to extract the data. To process 300 index files, it takes ~2 days.&lt;/p&gt;
&lt;p&gt;Let's see how we can speed it up.&lt;/p&gt;
&lt;p&gt;My Wi-Fi speed is ~4MBps when downloading the index file. To download faster, I have created t2.micro(free-tier) EC2 instance on AWS. In this machine, download speed is ~10MBps. We can use other instances, but I am trying to use only free resources. In this machine, single file download is taking ~3 minutes.&lt;/p&gt;
&lt;p&gt;CC dataset is hosted in us-east-1 region. So, I have created a new t2.micro instance in us-east-1 region. This instance is taking &amp;lt;20 seconds to download a single file. We can download entire index in less than 2 hours.&lt;/p&gt;
&lt;h5&gt;Faster Performance&lt;/h5&gt;
&lt;p&gt;To extract data from index files, we have used Python pandas without specifying the engine. By default, it uses &lt;code&gt;pyarrow&lt;/code&gt; which is a bit slow. To improve speed we can use &lt;code&gt;fastparquet&lt;/code&gt; as engine which is ~5x faster than &lt;code&gt;pyarrow&lt;/code&gt;.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;

&lt;span class="n"&gt;filename&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'part-00000-26160df0-1827-4787-a515-95ecaa2c9688.c000.gz.parquet'&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_parquet&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;engine&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'fastparquet'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;To get better performance, we can use duckdb. Duckdb is an in-process SQL OLAP DBMS and it can execute SQL queries directly on parquet files with &lt;code&gt;parquet&lt;/code&gt; extension.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ brew install duckdb

$ duckdb -c &lt;span class="s1"&gt;'INSTALL parquet;'&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;We can write a simple SQL query to filter out the required rows.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ duckdb -c &lt;span class="s2"&gt;"""&lt;/span&gt;
&lt;span class="s2"&gt;LOAD parquet;&lt;/span&gt;
&lt;span class="s2"&gt;COPY (select * from PARQUET_SCAN('part-00000-26160df0-1827-4787-a515-95ecaa2c9688.c000.gz.parquet') where content_languages ilike '%tel%') TO 'telugu.csv' (DELIMITER ',', HEADER TRUE);&lt;/span&gt;
&lt;span class="s2"&gt;"""&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;Duckdb can execute SQL queries on remote files as well with &lt;code&gt;httpfs&lt;/code&gt; extension.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ duckdb -c &lt;span class="s1"&gt;'INSTALL httpfs;'&lt;/span&gt;

$ duckdb -c &lt;span class="s2"&gt;"""&lt;/span&gt;
&lt;span class="s2"&gt;    LOAD httpfs;&lt;/span&gt;
&lt;span class="s2"&gt;    LOAD parquet;&lt;/span&gt;

&lt;span class="s2"&gt;    COPY (select * from PARQUET_SCAN('s3://commoncrawl/cc-index/table/cc-main/warc/crawl=CC-MAIN-2022-40/subset=warc/part-00001-26160df0-1827-4787-a515-95ecaa2c9688.c000.gz.parquet') where content_languages ilike '%tel%') TO 'telugu.csv' (DELIMITER ',', HEADER TRUE);"""&lt;/span&gt;
&lt;span class="s2"&gt;"""&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;Duckdb can also read series of parquet files and treat them as a single table. We can use this feature to process all the index files in a single command.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ duckdb -c &lt;span class="s2"&gt;"""&lt;/span&gt;
&lt;span class="s2"&gt;    LOAD httpfs;&lt;/span&gt;
&lt;span class="s2"&gt;    LOAD parquet;&lt;/span&gt;

&lt;span class="s2"&gt;    SET s3_region='us-east-1';&lt;/span&gt;
&lt;span class="s2"&gt;    SET s3_access_key_id='s3_secret_access_key';&lt;/span&gt;
&lt;span class="s2"&gt;    SET s3_secret_access_key='s3_secret_access_key';&lt;/span&gt;

&lt;span class="s2"&gt;    COPY (select * from PARQUET_SCAN('s3://commoncrawl/cc-index/table/cc-main/warc/crawl=CC-MAIN-2022-40/subset=warc/*.parquet') where content_languages ilike '%tel%') TO 'telugu.csv' (DELIMITER ',', HEADER TRUE);&lt;/span&gt;
&lt;span class="s2"&gt;"""&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;Depending on the file size, duckdb takes 10-15 seconds to process a single file. Since we don't need all the columns for further data processing, we can limit columns to required 5 columns.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ duckdb -c &lt;span class="s2"&gt;"""&lt;/span&gt;
&lt;span class="s2"&gt;    COPY (select url, content_languages, warc_filename, warc_record_offset, warc_record_length from PARQUET_SCAN('s3://commoncrawl/cc-index/table/cc-main/warc/crawl=CC-MAIN-2022-40/subset=warc/*.parquet') where content_languages ilike '%tel%') TO 'telugu.csv' (DELIMITER ',', HEADER TRUE);&lt;/span&gt;
&lt;span class="s2"&gt;"""&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;By limiting columns&lt;sup id="fnref:cc-gg"&gt;&lt;a class="footnote-ref" href="https://avilpage.com/2022/11/common-crawl-laptop-extract-subset.html#fn:cc-gg"&gt;3&lt;/a&gt;&lt;/sup&gt; there is another 65% improvement in performance. Now duckdb can process a file in 3 to 8 seconds depending on the size of the file. We can process entire index in ~20 minutes.&lt;/p&gt;
&lt;h4&gt;Conclusion&lt;/h4&gt;
&lt;p&gt;With a single command, we can extract a subset of index from CC in ~2 hours. So far we have processed all files in a single process. We can also parallelize the process using &lt;code&gt;parallel&lt;/code&gt; to get faster results.&lt;/p&gt;
&lt;p&gt;In the upcoming posts, let's see how we can fetch the data from WARC files using this index and do further data processing.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:common-crawl"&gt;
&lt;p&gt;&lt;a href="https://commoncrawl.org"&gt;https://commoncrawl.org&lt;/a&gt; &lt;a class="footnote-backref" href="https://avilpage.com/2022/11/common-crawl-laptop-extract-subset.html#fnref:common-crawl" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:columnar-index-wiki"&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Column-oriented_DBMS"&gt;https://en.wikipedia.org/wiki/Column-oriented_DBMS&lt;/a&gt; &lt;a class="footnote-backref" href="https://avilpage.com/2022/11/common-crawl-laptop-extract-subset.html#fnref:columnar-index-wiki" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:cc-gg"&gt;
&lt;p&gt;&lt;a href="https://groups.google.com/g/common-crawl/c/WYwkW97RM4s"&gt;https://groups.google.com/g/common-crawl/c/WYwkW97RM4s&lt;/a&gt; &lt;a class="footnote-backref" href="https://avilpage.com/2022/11/common-crawl-laptop-extract-subset.html#fnref:cc-gg" title="Jump back to footnote 3 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description><category>command-line</category><category>common-crawl</category><category>data-analysis</category><guid>https://avilpage.com/2022/11/common-crawl-laptop-extract-subset.html</guid><pubDate>Thu, 17 Nov 2022 01:11:39 GMT</pubDate></item><item><title>Build &amp; Distribute a Python C Extension Module</title><link>https://avilpage.com/2022/11/build-distribute-a-python-c-extension-module.html</link><dc:creator>Chillar Anand</dc:creator><description>&lt;h4&gt;Introduction&lt;/h4&gt;
&lt;p&gt;Python is a great language for prototyping and building applications. Python is an interpreted language, and it is not compiled. This means that the code is not optimized for the machine it is running on. This is where C comes in. &lt;/p&gt;
&lt;p&gt;C is a compiled language, and it is much faster than Python. So, if you want to write a Python module that is fast, you can write it in C and compile it. This is called a C extension module. In this article, we will see how to build and distribute a Python C extension module using wheels.&lt;/p&gt;
&lt;h4&gt;Building a C extension module&lt;/h4&gt;
&lt;p&gt;Let's start by creating a simple C extension module called &lt;code&gt;maths&lt;/code&gt;. In this, we will create a &lt;code&gt;square&lt;/code&gt; function that takes a number and returns its square.&lt;/p&gt;
&lt;p&gt;First, create a directory called &lt;code&gt;maths&lt;/code&gt; and create a file called &lt;code&gt;maths.c&lt;/code&gt; inside it. This is where we will write our C code.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;Python.h&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;


&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;square&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;num&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;


&lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="n"&gt;PyObject&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nf"&gt;py_square&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;PyObject&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;PyObject&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;n_num&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;&lt;span class="n"&gt;PyArg_ParseTuple&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;"i"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;n_num&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;NULL&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;square&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_num&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;Py_BuildValue&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"i"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;


&lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="n"&gt;PyMethodDef&lt;/span&gt; &lt;span class="n"&gt;mathsMethods&lt;/span&gt;&lt;span class="p"&gt;[]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;"square"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;py_square&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;METH_VARARGS&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;"Function for calculating square in C"&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;
  &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nb"&gt;NULL&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;NULL&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;NULL&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;};&lt;/span&gt;


&lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="nc"&gt;PyModuleDef&lt;/span&gt; &lt;span class="n"&gt;maths&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="n"&gt;PyModuleDef_HEAD_INIT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="s"&gt;"maths"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="s"&gt;"Custom maths module"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="mi"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="n"&gt;mathsMethods&lt;/span&gt;
&lt;span class="p"&gt;};&lt;/span&gt;


&lt;span class="n"&gt;PyMODINIT_FUNC&lt;/span&gt; &lt;span class="nf"&gt;PyInit_maths&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;PyModule_Create&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;maths&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;We need to create a &lt;code&gt;setup.py&lt;/code&gt; file to build our module. This file tells Python how to build our module.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;setuptools&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;setup&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Extension&lt;/span&gt;

&lt;span class="n"&gt;setup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"maths"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;version&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"0.1"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;ext_modules&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;Extension&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"maths"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"maths.c"&lt;/span&gt;&lt;span class="p"&gt;])]&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;Now, we can build our module by running &lt;code&gt;python setup.py build&lt;/code&gt;. This will create a &lt;code&gt;build&lt;/code&gt; directory with a &lt;code&gt;lib&lt;/code&gt; directory inside it.
This &lt;code&gt;lib&lt;/code&gt; directory contains our compiled module. We can import this module in Python and use it.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;maths&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;maths&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;square&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mi"&gt;25&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;Instead of testing our module by importing it in Python, we can also test it by running &lt;code&gt;python setup.py test&lt;/code&gt;. This will run the tests in the &lt;code&gt;test&lt;/code&gt; directory. We can create a &lt;code&gt;test&lt;/code&gt; directory and create a file called &lt;code&gt;test_maths.py&lt;/code&gt; inside it. This is where we will write our tests.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;unittest&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;maths&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;TestMaths&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;unittest&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TestCase&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;test_square&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;assertEqual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;maths&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;square&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;
&lt;h4&gt;Distributing a C extension module&lt;/h4&gt;
&lt;p&gt;Now that we have built our module, we can distribute it. We can distribute it as a source distribution or a binary distribution. A source distribution is a zip file that contains the source code of our module. We can distribute our module as a source distribution by running &lt;code&gt;python setup.py sdist&lt;/code&gt;. This will create a &lt;code&gt;dist&lt;/code&gt; directory with a zip file inside it. This zip file contains our source code.&lt;/p&gt;
&lt;p&gt;However, source distribution of C extension modules is not recommended. This is because the user needs to have a C compiler installed on their machine to build the module. Most users just want to &lt;code&gt;pip install&lt;/code&gt; the module and use it. So, we need to distribute our module as a binary distribution.&lt;/p&gt;
&lt;p&gt;We can use &lt;code&gt;cibuildwheel&lt;/code&gt; package to build wheels across all platforms. We can install it by running &lt;code&gt;pip install cibuildwheel&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;To build a wheel for a specific platform and a specific architecture, we can run &lt;code&gt;cibuildwheel --platform &amp;lt;platform&amp;gt; --architecture &amp;lt;architecture&amp;gt;&lt;/code&gt;. For example, to build a wheel for Linux x86_64, we can run &lt;code&gt;cibuildwheel --platform linux --architecture x86_64&lt;/code&gt;. This will create a &lt;code&gt;wheelhouse&lt;/code&gt; directory with a wheel file inside it. This wheel file contains our compiled module.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;cibuildwheel&lt;/code&gt; runs on most CI servers. With proper workflows, we can easily get wheels for all platforms and architectures. We can then upload these wheels to PyPI and users can easily install these wheels.&lt;/p&gt;
&lt;h4&gt;Conclusion&lt;/h4&gt;
&lt;p&gt;In this article, we saw how to build and distribute a Python C extension module using wheels. We saw how to build a C extension module and how to distribute it as a binary distribution. We also saw how to use &lt;code&gt;cibuildwheel&lt;/code&gt; to build wheels across all platforms and architectures.&lt;/p&gt;</description><category>c</category><category>python</category><guid>https://avilpage.com/2022/11/build-distribute-a-python-c-extension-module.html</guid><pubDate>Tue, 01 Nov 2022 16:01:29 GMT</pubDate></item><item><title>Speed Up AMD64(Intel) VMs on ARM(M1 Mac) Host</title><link>https://avilpage.com/2022/10/speedup-amd64-containers-on-arm.html</link><dc:creator>Chillar Anand</dc:creator><description>&lt;h4&gt;Introduction&lt;/h4&gt;
&lt;p&gt;From 2020, Apple has transitioned from Intel to ARM based Apple Silicon M1. If we run &lt;code&gt;uname -mp&lt;/code&gt; on these devices, we can see the CPU architecture details.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ uname -mp
arm64 arm
&lt;/pre&gt;
&lt;p&gt;Let's run the same command on a device using Intel x86 processor.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ uname -mp
x86_64 x86_64
&lt;/pre&gt;
&lt;p&gt;Many popular docker images&lt;sup id="fnref:dhub"&gt;&lt;a class="footnote-ref" href="https://avilpage.com/2022/10/speedup-amd64-containers-on-arm.html#fn:dhub"&gt;1&lt;/a&gt;&lt;/sup&gt; doesn't have ARM64 support yet. When setting up a dev environment in M1 Mac, there are high chances that we stumble on these containers if we are using plain docker or ARM64 VM. So, there is a need to spin up x86_64 VMs.&lt;/p&gt;
&lt;p&gt;In this article, lets see how the performance affects when running a cross architecture containers and how to speed it up.&lt;/p&gt;
&lt;h4&gt;Setup&lt;/h4&gt;
&lt;p&gt;Lima&lt;sup id="fnref:lima"&gt;&lt;a class="footnote-ref" href="https://avilpage.com/2022/10/speedup-amd64-containers-on-arm.html#fn:lima"&gt;2&lt;/a&gt;&lt;/sup&gt; can run foreign architecture(x6_64) VMs on Mac. Let's install lima, start a AMD64 VM &amp;amp; ARM64 VM and install k3s&lt;sup id="fnref:k3s"&gt;&lt;a class="footnote-ref" href="https://avilpage.com/2022/10/speedup-amd64-containers-on-arm.html#fn:k3s"&gt;3&lt;/a&gt;&lt;/sup&gt; in them. k3s will run multiple process in the background and let's see how resource consumption varies in these VMs.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ brew install lima

$ limactl start linux_arm64
$ limactl start linux_amd64
&lt;/pre&gt;
&lt;p&gt;When starting a VM, we can edit &lt;code&gt;arch&lt;/code&gt; parameter in the configuration. Once VM starts, we can see the details by running &lt;code&gt;limactl list&lt;/code&gt;.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ limactl list
NAME                ARCH
linux_amd64         x86_64
linux_arm64         aarch64
&lt;/pre&gt;
&lt;p&gt;Lets login to each VM &amp;amp; install k3s.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ limactl shell linux_arm64

$ curl -sfL https://get.k3s.io &lt;span class="p"&gt;|&lt;/span&gt; sh -
&lt;/pre&gt;
&lt;pre class="code literal-block"&gt;$ limactl shell linux_amd64

$ curl -sfL https://get.k3s.io &lt;span class="p"&gt;|&lt;/span&gt; sh -
&lt;/pre&gt;
&lt;p&gt;If we look at resource consumption on the host machine, x86_84 VM is using way more resources than ARM64 VM. This is because of the emulation layer that is running on top of the VM.&lt;/p&gt;
&lt;p align="center"&gt;
&lt;img src="https://avilpage.com/images/arch-arm-docker.png"&gt;
&lt;/p&gt;

&lt;p&gt;We can login to individual VMs, run &lt;code&gt;top&lt;/code&gt; to see the load average as well.&lt;/p&gt;
&lt;h4&gt;Fast Mode&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;lima&lt;/code&gt; provides &lt;code&gt;fast-mode&lt;/code&gt; option for cross architecture VMs which will speed up the performance.&lt;/p&gt;
&lt;p&gt;For that, we need to log in to VMs and install emulators.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ sudo systemctl start containerd
$ sudo nerdctl run --privileged --rm tonistiigi/binfmt --install all
&lt;/pre&gt;
&lt;p&gt;After that we can restart the VMs and monitor the resource consumption. On an average, we can see that the resource consumption is reduced by 50%.&lt;/p&gt;
&lt;h4&gt;Conclusion&lt;/h4&gt;
&lt;p&gt;In this article, we saw how to run cross architecture VMs on M1 Mac and how to speed up the performance. We can use this technique to run cross architecture containers on Linux as well.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:dhub"&gt;
&lt;p&gt;&lt;a href="https://hub.docker.com/search?q=&amp;amp;page=10"&gt;https://hub.docker.com/search?q=&amp;amp;page=10&lt;/a&gt; &lt;a class="footnote-backref" href="https://avilpage.com/2022/10/speedup-amd64-containers-on-arm.html#fnref:dhub" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:lima"&gt;
&lt;p&gt;&lt;a href="https://github.com/lima-vm/lima"&gt;https://github.com/lima-vm/lima&lt;/a&gt; &lt;a class="footnote-backref" href="https://avilpage.com/2022/10/speedup-amd64-containers-on-arm.html#fnref:lima" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:k3s"&gt;
&lt;p&gt;&lt;a href="https://avilpage.com/2022/10/local-kubernetes-with-k3s-on-mac.html"&gt;Install k3s on Mac M1&lt;/a&gt; &lt;a class="footnote-backref" href="https://avilpage.com/2022/10/speedup-amd64-containers-on-arm.html#fnref:k3s" title="Jump back to footnote 3 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description><category>devops</category><category>linux</category><category>macbook</category><guid>https://avilpage.com/2022/10/speedup-amd64-containers-on-arm.html</guid><pubDate>Thu, 20 Oct 2022 17:08:56 GMT</pubDate></item><item><title>Local Kubernetes Cluster with K3s on MacBook M1</title><link>https://avilpage.com/2022/10/local-kubernetes-with-k3s-on-mac.html</link><dc:creator>Chillar Anand</dc:creator><description>&lt;div class="embed-responsive embed-responsive-16by9"&gt;
&lt;iframe class="embed-responsive-item" src="https://www.youtube.com/embed/vi5eRgBMs90" allowfullscreen&gt;
&lt;/iframe&gt;
&lt;/div&gt;

&lt;h4&gt;Introduction&lt;/h4&gt;
&lt;p&gt;Kubernetes(k8s)&lt;sup id="fnref:k8s"&gt;&lt;a class="footnote-ref" href="https://avilpage.com/2022/10/local-kubernetes-with-k3s-on-mac.html#fn:k8s"&gt;1&lt;/a&gt;&lt;/sup&gt; is an open-source system for managing large scale containerized applications. K3s&lt;sup id="fnref:k3s"&gt;&lt;a class="footnote-ref" href="https://avilpage.com/2022/10/local-kubernetes-with-k3s-on-mac.html#fn:k3s"&gt;2&lt;/a&gt;&lt;/sup&gt; is lightweight K8s in a single binary file. However, K3s won't work directly on Macbook as it needs systemd/OpenRC.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;curl&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;sfL&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;https&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="k"&gt;get&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;k3s&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;io&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;sh&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;ERROR&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;Can&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ow"&gt;not&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;systemd&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ow"&gt;or&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;openrc&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;to&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;use&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;as&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;process&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;supervisor&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;k3s&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;To setup k8s/k3s on Mac, we need to setup a Linux layer on top of Mac. An easy way to spin up Linux VMs on Macbook M1(Apple Silicon) is to use multipass&lt;sup id="fnref:multipass"&gt;&lt;a class="footnote-ref" href="https://avilpage.com/2022/10/local-kubernetes-with-k3s-on-mac.html#fn:multipass"&gt;3&lt;/a&gt;&lt;/sup&gt;. In this article, lets see how to setup K3s on Mac using multipass&lt;/p&gt;
&lt;h4&gt;K3s Setup&lt;/h4&gt;
&lt;p&gt;Install multipass with brew by running the following command.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ brew install --cask multipass
&lt;/pre&gt;
&lt;p&gt;Once it is installed, spin up a new VM by specifying memory and disk space.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ multipass launch --name k3s --mem 4G --disk 40G
&lt;/pre&gt;
&lt;p&gt;Once VM is launched, we can see VM details.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ multipass info k3s
Name:           k3s
State:          Running
IPv4:           &lt;span class="m"&gt;192&lt;/span&gt;.168.64.4
                &lt;span class="m"&gt;10&lt;/span&gt;.42.0.0
                &lt;span class="m"&gt;10&lt;/span&gt;.42.0.1
Release:        Ubuntu &lt;span class="m"&gt;22&lt;/span&gt;.04.1 LTS
Image hash:     78b5ca0da456 &lt;span class="o"&gt;(&lt;/span&gt;Ubuntu &lt;span class="m"&gt;22&lt;/span&gt;.04 LTS&lt;span class="o"&gt;)&lt;/span&gt;
Load:           &lt;span class="m"&gt;1&lt;/span&gt;.34 &lt;span class="m"&gt;2&lt;/span&gt;.10 &lt;span class="m"&gt;1&lt;/span&gt;.70
Disk usage:     &lt;span class="m"&gt;3&lt;/span&gt;.7G out of &lt;span class="m"&gt;38&lt;/span&gt;.6G
Memory usage:   &lt;span class="m"&gt;1&lt;/span&gt;.2G out of &lt;span class="m"&gt;3&lt;/span&gt;.8G
Mounts:         /Users/chillaranand/test/k8s &lt;span class="o"&gt;=&lt;/span&gt;&amp;gt; ~/k8s
                    UID map: &lt;span class="m"&gt;503&lt;/span&gt;:default
                    GID map: &lt;span class="m"&gt;20&lt;/span&gt;:default
&lt;/pre&gt;
&lt;p&gt;We can even mount Mac directories on the VM.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ multipass mount ~/test/k8s k3s:~/k8s
&lt;/pre&gt;
&lt;p&gt;This will be useful when we are making changes on host directories and want to apply changes on the cluster which is inside VM.&lt;/p&gt;
&lt;p&gt;Now, we can install k3s by running the install script inside the VM.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ multipass shell k3s

ubuntu@k3s:~$ curl -sfL https://get.k3s.io &lt;span class="p"&gt;|&lt;/span&gt; sh -
&lt;/pre&gt;
&lt;p&gt;This will setup a k3s cluster on the VM. We can use kubectl and deploy applications on this cluster.&lt;/p&gt;
&lt;p&gt;By default, k3s config file will be located at &lt;code&gt;/etc/rancher/k3s/k3s.yaml&lt;/code&gt;. With this config file, we can use Lens&lt;sup id="fnref:lens"&gt;&lt;a class="footnote-ref" href="https://avilpage.com/2022/10/local-kubernetes-with-k3s-on-mac.html#fn:lens"&gt;4&lt;/a&gt;&lt;/sup&gt; to manage k8s cluster.&lt;/p&gt;
&lt;p align="center"&gt;
&lt;img src="https://avilpage.com/images/k8s-mac-m1.jpg"&gt;
&lt;/p&gt;

&lt;p&gt;Lets find out IP of the VM &amp;amp; k8s token so that we can spin up a new VM and add it to this cluster.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span class="c1"&gt;# get token &amp;amp; ip of k3s&lt;/span&gt;
&lt;span class="o"&gt;$&lt;/span&gt; &lt;span class="n"&gt;multipass&lt;/span&gt; &lt;span class="n"&gt;exec&lt;/span&gt; &lt;span class="n"&gt;k3s&lt;/span&gt; &lt;span class="n"&gt;sudo&lt;/span&gt; &lt;span class="n"&gt;cat&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="k"&gt;var&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;lib&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;rancher&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;k3s&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;server&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;token&lt;/span&gt;
&lt;span class="o"&gt;$&lt;/span&gt; &lt;span class="n"&gt;multipass&lt;/span&gt; &lt;span class="n"&gt;info&lt;/span&gt; &lt;span class="n"&gt;k3s&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;grep&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="n"&gt;ip&lt;/span&gt;
&lt;/pre&gt;
&lt;pre class="code literal-block"&gt;$ multipass launch --name k3s-worker --mem 2G --disk 20G

$ multipass shell k3s-worker

ubuntu@k3s-worker:~$ curl -sfL https://get.k3s.io &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="nv"&gt;K3S_URL&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;https://192.168.64.4:6443 &lt;span class="nv"&gt;K3S_TOKEN&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"hs48af...947fh4::server:3tfkwjd...4jed73"&lt;/span&gt; sh -
&lt;/pre&gt;
&lt;p&gt;We can verify if the node is added correctly from k3s VM.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span class="n"&gt;ubuntu&lt;/span&gt;&lt;span class="nv"&gt;@k3s&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="o"&gt;~&lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;kubectl&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;get&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;nodes&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;NAME&lt;/span&gt;&lt;span class="w"&gt;         &lt;/span&gt;&lt;span class="n"&gt;STATUS&lt;/span&gt;&lt;span class="w"&gt;   &lt;/span&gt;&lt;span class="n"&gt;ROLES&lt;/span&gt;&lt;span class="w"&gt;                  &lt;/span&gt;&lt;span class="n"&gt;AGE&lt;/span&gt;&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="n"&gt;VERSION&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;k3s&lt;/span&gt;&lt;span class="w"&gt;          &lt;/span&gt;&lt;span class="n"&gt;Ready&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;control&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;plane&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;master&lt;/span&gt;&lt;span class="w"&gt;   &lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="n"&gt;v1&lt;/span&gt;&lt;span class="mf"&gt;.24.6&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;k3s1&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;k3s&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;worker&lt;/span&gt;&lt;span class="w"&gt;   &lt;/span&gt;&lt;span class="n"&gt;Ready&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;none&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt;                 &lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="n"&gt;m15s&lt;/span&gt;&lt;span class="w"&gt;   &lt;/span&gt;&lt;span class="n"&gt;v1&lt;/span&gt;&lt;span class="mf"&gt;.24.6&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;k3s1&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;Once we are done with experimenting k3s, we can delete the VMs.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ multipass delete k3s k3s-worker
$ multipass purge
&lt;/pre&gt;
&lt;h4&gt;Conclusion&lt;/h4&gt;
&lt;p&gt;multipass is a great tool to spin up Linux VMs on Mac with single command. K3s is better tool to setup k8s cluster locally for development and testing.&lt;/p&gt;
&lt;p&gt;Even though we have mentioned this tutorial is meant for Mac M1, it should work fine on any Linux distribution as well.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:k8s"&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Kubernetes"&gt;https://en.wikipedia.org/wiki/Kubernetes&lt;/a&gt; &lt;a class="footnote-backref" href="https://avilpage.com/2022/10/local-kubernetes-with-k3s-on-mac.html#fnref:k8s" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:k3s"&gt;
&lt;p&gt;&lt;a href="https://k3s.io/"&gt;https://k3s.io/&lt;/a&gt; &lt;a class="footnote-backref" href="https://avilpage.com/2022/10/local-kubernetes-with-k3s-on-mac.html#fnref:k3s" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:multipass"&gt;
&lt;p&gt;&lt;a href="https://github.com/canonical/multipass"&gt;https://github.com/canonical/multipass&lt;/a&gt; &lt;a class="footnote-backref" href="https://avilpage.com/2022/10/local-kubernetes-with-k3s-on-mac.html#fnref:multipass" title="Jump back to footnote 3 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:lens"&gt;
&lt;p&gt;&lt;a href="https://k8slens.dev/"&gt;https://k8slens.dev/&lt;/a&gt; &lt;a class="footnote-backref" href="https://avilpage.com/2022/10/local-kubernetes-with-k3s-on-mac.html#fnref:lens" title="Jump back to footnote 4 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description><category>devops</category><category>kubernetes</category><category>macbook</category><guid>https://avilpage.com/2022/10/local-kubernetes-with-k3s-on-mac.html</guid><pubDate>Tue, 11 Oct 2022 02:38:36 GMT</pubDate></item><item><title>How To Root Xiamo Redmi 9 Prime Without TWRP</title><link>https://avilpage.com/2022/09/how-to-root-redmi-9-prime-lancelot.html</link><dc:creator>Chillar Anand</dc:creator><description>&lt;h4&gt;Introduction&lt;/h4&gt;
&lt;p&gt;Rooting&lt;sup id="fnref:root"&gt;&lt;a class="footnote-ref" href="https://avilpage.com/2022/09/how-to-root-redmi-9-prime-lancelot.html#fn:root"&gt;1&lt;/a&gt;&lt;/sup&gt; an android device voids warranty but gives a great control over the device. For most of the popular devices, TWRP&lt;sup id="fnref:twrp"&gt;&lt;a class="footnote-ref" href="https://avilpage.com/2022/09/how-to-root-redmi-9-prime-lancelot.html#fn:twrp"&gt;2&lt;/a&gt;&lt;/sup&gt; recovery is available. Once a device bootloader is unlocked, we can install TWRP recovery. After that we can flash Magisk to gain root access.&lt;/p&gt;
&lt;p&gt;For some devices like Redmi 9 Prime(codename: lancelot), TWRP recovery is not available officially. There are couple of unofficial images but they are not working as expected and are causing bootloop.&lt;/p&gt;
&lt;p&gt;In this article, lets see how to root lancelot device.&lt;/p&gt;
&lt;h4&gt;Rooting Lancelot&lt;/h4&gt;
&lt;p&gt;First ensure that the device bootloader is unlocked and your system has adb &amp;amp; fastboot installed. To root without TWRP, we need to obtain patched &lt;code&gt;boot.img&lt;/code&gt; &amp;amp; &lt;code&gt;vbmeta.img&lt;/code&gt; and flash them in fastboot mode.&lt;/p&gt;
&lt;p&gt;First we need to download the stock ROM of the device to extract boot.img file. We can go to manufacturers site and download the same stock ROM&lt;sup id="fnref:lancelot"&gt;&lt;a class="footnote-ref" href="https://avilpage.com/2022/09/how-to-root-redmi-9-prime-lancelot.html#fn:lancelot"&gt;3&lt;/a&gt;&lt;/sup&gt; that is running on the device. Once the ROM is downloaded, we can unzip it. There we can find boot.img file.&lt;/p&gt;
&lt;p align="center"&gt;
&lt;img src="https://avilpage.com/images/root-redmi-9-prime.png"&gt;
&lt;/p&gt;

&lt;p&gt;We need to patch this file. To patch this, download magisk app on the device. Click on install and select the boot.img file to patch. After a few minutes, it will generate a patched boot file.&lt;/p&gt;
&lt;p align="center"&gt;
&lt;img height="440" width="220" src="https://avilpage.com/images/root-redmi-9-prime-2.jpeg"&gt;
&lt;/p&gt;

&lt;p&gt;We can download this file to system by running the following command.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ adb pull -p /storage/emulated/0/Download/magisk_patched-25200_cU1ws.img .
&lt;/pre&gt;
&lt;p&gt;Now we need to download patched vbmeta file. This is available in XDA&lt;sup id="fnref:xda"&gt;&lt;a class="footnote-ref" href="https://avilpage.com/2022/09/how-to-root-redmi-9-prime-lancelot.html#fn:xda"&gt;4&lt;/a&gt;&lt;/sup&gt; forum. Click &lt;a href="https://forum.xda-developers.com/attachments/vbmeta_redmi9-img.5082027/"&gt;this link&lt;/a&gt; to download it.&lt;/p&gt;
&lt;p&gt;Once we have both patched files, we can reboot the device in fastboot mode by using the following commands.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ adb devices

$ adb reboot bootloader
&lt;/pre&gt;
&lt;p&gt;When the device is in fastboot mode, run the following commands to root it.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ fastboot --disable-verity --disable-verification flash vbmeta vbmeta_redmi9.img

$ fastboot flash boot magisk_patched-25200_cU1ws.img

$ fastboot reboot
&lt;/pre&gt;
&lt;p&gt;Once the deivce is rebooted, we can install root checker app and verify that the device is rooted successfully.&lt;/p&gt;
&lt;h4&gt;Final Thoughts&lt;/h4&gt;
&lt;p&gt;When we buy a Mac or PC(Linux/Windows), it is rooted by default. For Linux/Mac, we can run programs as sudo. For windows, we can just run a program as an administrator. There are no extra steps to root/jailbreak these devices.&lt;/p&gt;
&lt;p&gt;But most mobile companies make rooting hard and only tech savy users can root the device. It would be great if mobile phones are rooted by default.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:root"&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Rooting_(Android)"&gt;https://en.wikipedia.org/wiki/Rooting_(Android)&lt;/a&gt; &lt;a class="footnote-backref" href="https://avilpage.com/2022/09/how-to-root-redmi-9-prime-lancelot.html#fnref:root" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:twrp"&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/TWRP_(software)"&gt;https://en.wikipedia.org/wiki/TWRP_(software)&lt;/a&gt; &lt;a class="footnote-backref" href="https://avilpage.com/2022/09/how-to-root-redmi-9-prime-lancelot.html#fnref:twrp" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:lancelot"&gt;
&lt;p&gt;&lt;a href="https://xiaomifirmwareupdater.com/miui/lancelot/"&gt;https://xiaomifirmwareupdater.com/miui/lancelot/&lt;/a&gt; &lt;a class="footnote-backref" href="https://avilpage.com/2022/09/how-to-root-redmi-9-prime-lancelot.html#fnref:lancelot" title="Jump back to footnote 3 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:xda"&gt;
&lt;p&gt;&lt;a href="https://forum.xda-developers.com/t/guide-magisk-root-access-for-redmi-9-mediatek-helio-g80-without-twrp.4149531/"&gt;Guide @ XDA&lt;/a&gt; &lt;a class="footnote-backref" href="https://avilpage.com/2022/09/how-to-root-redmi-9-prime-lancelot.html#fnref:xda" title="Jump back to footnote 4 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description><category>android</category><category>root</category><guid>https://avilpage.com/2022/09/how-to-root-redmi-9-prime-lancelot.html</guid><pubDate>Wed, 28 Sep 2022 00:44:45 GMT</pubDate></item><item><title>Integrating Frappe Health with SNOMED CT</title><link>https://avilpage.com/2022/08/frappe-health-snomed-ct.html</link><dc:creator>Chillar Anand</dc:creator><description>&lt;h4&gt;Introduction&lt;/h4&gt;
&lt;p&gt;Frappe Health&lt;sup id="fnref:FH"&gt;&lt;a class="footnote-ref" href="https://avilpage.com/2022/08/frappe-health-snomed-ct.html#fn:FH"&gt;1&lt;/a&gt;&lt;/sup&gt; is an open-source Healthcare Information System(HIS), to efficiently manage clinics, hospitals, and other healthcare organizations. Frappe Health is built on the Frappe Framework&lt;sup id="fnref:ff"&gt;&lt;a class="footnote-ref" href="https://avilpage.com/2022/08/frappe-health-snomed-ct.html#fn:ff"&gt;2&lt;/a&gt;&lt;/sup&gt;, a low code highly customizable framework.&lt;/p&gt;
&lt;p&gt;Frappe Health provides support for integrating various medical coding standards&lt;sup id="fnref:mcs"&gt;&lt;a class="footnote-ref" href="https://avilpage.com/2022/08/frappe-health-snomed-ct.html#fn:mcs"&gt;3&lt;/a&gt;&lt;/sup&gt;. In the patient encounter doctype, doctors can search and add pre-configured medical codes.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://avilpage.com/images/snomed-frappe-health1.png"&gt;&lt;/p&gt;
&lt;p&gt;In this article, let’s see how to integrate Frappe Health with SNOMED CT.&lt;/p&gt;
&lt;h4&gt;SNOMED CT Integration&lt;/h4&gt;
&lt;p&gt;SNOMED CT&lt;sup id="fnref:snomed"&gt;&lt;a class="footnote-ref" href="https://avilpage.com/2022/08/frappe-health-snomed-ct.html#fn:snomed"&gt;4&lt;/a&gt;&lt;/sup&gt; is a comprehensive collection of medical terms which helps consistent data exchange between systems. It can also cross-map to other standards like ICD-10, LOINC, etc.&lt;/p&gt;
&lt;p&gt;Since SNOMED CT is a huge dataset, it takes a lot of effort to import the entire dataset into Frappe Health. It also provides REST API to query SNOMED terms. Also, if your healthcare organization is focusing on only a specific domain, it doesn’t make sense to import the entire dataset.&lt;/p&gt;
&lt;p&gt;In such scenarios, it is better to map only the required diagnosis, symptoms, and other clinical objects.&lt;/p&gt;
&lt;p&gt;Frappe Health has a Diagnosis doctype where practitioners can enter diagnosis. We can add an additional field called &lt;code&gt;Snomed Code&lt;/code&gt; to link diagnosis to relevant SNOMED code.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://avilpage.com/images/snomed-frappe-health2.png"&gt;&lt;/p&gt;
&lt;p&gt;Frappe framework provides server script&lt;sup id="fnref:ss"&gt;&lt;a class="footnote-ref" href="https://avilpage.com/2022/08/frappe-health-snomed-ct.html#fn:ss"&gt;5&lt;/a&gt;&lt;/sup&gt; to dynamically run python script on any document event. We can write a simple python script to fetch relevant SNOMED code using SNOMED REST API. This script can be executed whenever the clinical object gets modified.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://avilpage.com/images/snomed-frappe-health3.png"&gt;&lt;/p&gt;
&lt;p&gt;Here is a simple python server script that adds relevant snomed codes to diagnosis.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span class="n"&gt;diagnosis&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;diagnosis&lt;/span&gt;

&lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"https://browser.ihtsdotools.org/snowstorm/snomed-ct/browser/MAIN/descriptions?&amp;amp;limit=50&amp;amp;term="&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;diagnosis&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s2"&gt;"&amp;amp;conceptActive=true&amp;amp;lang=english&amp;amp;skipTo=0&amp;amp;returnLimit=100"&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;frappe&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;make_get_request&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;code&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'items'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'concept'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'id'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;description&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'items'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'concept'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'fsn'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'term'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;mc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;frappe&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_doc&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;
    &lt;span class="s1"&gt;'doctype'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'Medical Code'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'code'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;code&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'medical_code_standard'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'SNOMED'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'description'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;description&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="p"&gt;})&lt;/span&gt;
&lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;mc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;insert&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;except&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;pass&lt;/span&gt;

&lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;medical_code&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;medical_code&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;After saving this script, if we go ahead and create or modify any diagnosis, it will automatically add relevant Snomed code to the diagnosis as shown below.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://avilpage.com/images/snomed-frappe-health4.png"&gt;&lt;/p&gt;
&lt;p&gt;The server script makes sure all the diagnosis objects are codified automatically without any manual effort.&lt;/p&gt;
&lt;p&gt;Since Frappe Framework &amp;amp; Frappe Health are low code, extremely customizable, we are able to integrate it with SNOMED in just a few minutes. Similarly, we can codify other clinical objects like Symptoms, Procedures, Medications, etc.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:FH"&gt;
&lt;p&gt;&lt;a href="https://github.com/frappe/health"&gt;https://github.com/frappe/health&lt;/a&gt; &lt;a class="footnote-backref" href="https://avilpage.com/2022/08/frappe-health-snomed-ct.html#fnref:FH" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:ff"&gt;
&lt;p&gt;&lt;a href="https://frappeframework.com"&gt;https://frappeframework.com&lt;/a&gt; &lt;a class="footnote-backref" href="https://avilpage.com/2022/08/frappe-health-snomed-ct.html#fnref:ff" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:mcs"&gt;
&lt;p&gt;&lt;a href="https://frappehealth.com/docs/v13/user/manual/en/healthcare/medical_code_standard"&gt;https://frappehealth.com/docs/v13/user/manual/en/healthcare/medical_code_standard&lt;/a&gt; &lt;a class="footnote-backref" href="https://avilpage.com/2022/08/frappe-health-snomed-ct.html#fnref:mcs" title="Jump back to footnote 3 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:snomed"&gt;
&lt;p&gt;&lt;a href="https://www.nlm.nih.gov/healthit/snomedct/index.html"&gt;https://www.nlm.nih.gov/healthit/snomedct/index.html&lt;/a&gt; &lt;a class="footnote-backref" href="https://avilpage.com/2022/08/frappe-health-snomed-ct.html#fnref:snomed" title="Jump back to footnote 4 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:ss"&gt;
&lt;p&gt;&lt;a href="https://frappeframework.com/docs/user/en/desk/scripting/server-script"&gt;https://frappeframework.com/docs/user/en/desk/scripting/server-script&lt;/a&gt; &lt;a class="footnote-backref" href="https://avilpage.com/2022/08/frappe-health-snomed-ct.html#fnref:ss" title="Jump back to footnote 5 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description><category>frappe-framework</category><category>HealthIT</category><guid>https://avilpage.com/2022/08/frappe-health-snomed-ct.html</guid><pubDate>Wed, 31 Aug 2022 10:59:13 GMT</pubDate></item><item><title>Mastering DICOM - #3 Setup Modality Worklist SCP</title><link>https://avilpage.com/2022/07/dicom-modality-worklist-scp.html</link><dc:creator>Chillar Anand</dc:creator><description>&lt;h4&gt;Introduction&lt;/h4&gt;
&lt;p&gt;In the earlier article, we have learnt how to setup DICOM for digging deeper into DICOM protocol. In this article, let us learn how to setup a modality worklist(WML) SCP. Modalities can send C-FIND queries to this SCP and retrieve worklist information&lt;/p&gt;
&lt;h4&gt;Using Orthanc Worklist Plugin&lt;/h4&gt;
&lt;p&gt;Orthanc server has worklist plugin&lt;sup id="fnref:owp"&gt;&lt;a class="footnote-ref" href="https://avilpage.com/2022/07/dicom-modality-worklist-scp.html#fn:owp"&gt;1&lt;/a&gt;&lt;/sup&gt; which will serve worklist files that are stored in a particular directory. Let us download sample worklist files from Orthanc repository and keep in "WorklistDatabase" directory.&lt;/p&gt;
&lt;p&gt;Generate default configuration by running the following command.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ ./Orthanc --config&lt;span class="o"&gt;=&lt;/span&gt;config.json
&lt;/pre&gt;
&lt;p&gt;In the orthanc configuration file, enable worklist plugin, specify the worklist database directory so that Orthanc can locate relevant worklist files, add required modalities and restart the server.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;  "Plugins" : [
    "libModalityWorklists.dylib"
  ],

  "Worklists" : {
    "Enable": true,
    "Database": "./WorklistsDatabase",
    "FilterIssuerAet": false,
    "LimitAnswers": 0
  },

  "DicomModalities" : {
      "PYNETDICOM" : ["PYNETDICOM", "127.0.0.1", 4243],
      "FINDSCU" : ["FINDSCU", "127.0.0.1", 4244]
  }
&lt;/pre&gt;
&lt;p&gt;Once the plugin is enabled, we can use findscu to send C-FIND query.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;$ findscu -W -k &lt;span class="s2"&gt;"ScheduledProcedureStepSequence"&lt;/span&gt; &lt;span class="m"&gt;127&lt;/span&gt;.0.0.1 &lt;span class="m"&gt;4242&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;This will retrieve all worklist files from the server.&lt;/p&gt;
&lt;h4&gt;Using wlmscpfs&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;dcmtk&lt;/code&gt; &lt;sup id="fnref:dcmtk"&gt;&lt;a class="footnote-ref" href="https://avilpage.com/2022/07/dicom-modality-worklist-scp.html#fn:dcmtk"&gt;2&lt;/a&gt;&lt;/sup&gt; is a collection of utilities for DICOM standard. It has &lt;code&gt;wlmscpfs&lt;/code&gt; application which implements basic Service Class Provider(SCP). We can start the service by running the following command.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;wlmscpfs --debug --data-files-path WorklistsDatabase 4242
&lt;/pre&gt;
&lt;p&gt;Once the service is started modalities can send C-FIND query to this service.&lt;/p&gt;
&lt;h4&gt;Conclusion&lt;/h4&gt;
&lt;p&gt;We have seen how to setup MWL SCP using Orthanc &amp;amp; wmlscpfs. Now that we have PACS &amp;amp; WML SCP up and running, in the next article lets see how to dig deeper in to the dicom standard.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:owp"&gt;
&lt;p&gt;&lt;a href="https://book.orthanc-server.com/plugins/worklists-plugin.html"&gt;https://book.orthanc-server.com/plugins/worklists-plugin.html&lt;/a&gt; &lt;a class="footnote-backref" href="https://avilpage.com/2022/07/dicom-modality-worklist-scp.html#fnref:owp" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:dcmtk"&gt;
&lt;p&gt;&lt;a href="https://github.com/DCMTK/dcmtk"&gt;https://github.com/DCMTK/dcmtk&lt;/a&gt; &lt;a class="footnote-backref" href="https://avilpage.com/2022/07/dicom-modality-worklist-scp.html#fnref:dcmtk" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description><category>dicom</category><category>HealthIT</category><guid>https://avilpage.com/2022/07/dicom-modality-worklist-scp.html</guid><pubDate>Sun, 31 Jul 2022 12:49:29 GMT</pubDate></item></channel></rss>