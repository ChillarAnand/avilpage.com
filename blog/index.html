<!DOCTYPE html>
<html prefix="
og: http://ogp.me/ns# article: http://ogp.me/ns/article#
" lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="Avil Page - Personal &amp; tech blog by Pandikunta Anand Reddy (aka Chillar Anand)">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Avil Page</title>
<link href="../assets/css/bootstrap.min.css" rel="stylesheet" type="text/css">
<link href="../assets/css/baguetteBox.min.css" rel="stylesheet" type="text/css">
<link href="../assets/css/rst.css" rel="stylesheet" type="text/css">
<link href="../assets/css/code.css" rel="stylesheet" type="text/css">
<link href="../assets/css/theme.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" hreflang="en" href="../rss.xml">
<link rel="canonical" href="https://avilpage.com/blog/">
<link rel="next" href="index-20.html" type="text/html">
<!--[if lt IE 9]><script src="../assets/js/html5.js"></script><![endif]--><style>

 h1 {
     font-weight: bold;
     font-size: 25px;
 }

</style>
</head>
<body>
    <a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

    <!-- Menubar -->
    <nav class="navbar navbar-expand-md static-top mb-4
                navbar-dark
                bg-dark
                "><div class="container">
<!-- This keeps the margins nice -->
            <a class="navbar-brand" href="../">

                    <span id="blog-title">Avil Page</span>
            </a>
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>

            <div class="collapse navbar-collapse" id="bs-navbar">
                <ul class="navbar-nav mr-auto">
<li class="nav-item">
<a href="../guides.html" class="nav-link">Guides</a>
                </li>
<li class="nav-item">
<a href="../archive.html" class="nav-link">Blog</a>
                </li>
<li class="nav-item">
<a href="../books.html" class="nav-link">Books</a>
                </li>
<li class="nav-item">
<a href="../talks.html" class="nav-link">Talks</a>
                </li>
<li class="nav-item">
<a href="../projects.html" class="nav-link">Projects</a>
                </li>
<li class="nav-item">
<a href="../rss.xml" class="nav-link">RSS</a>

                    
                </li>
</ul>
<ul class="navbar-nav navbar-right"></ul>
</div>
<!-- /.navbar-collapse -->
        </div>
<!-- /.container -->
    </nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="row justify-content-md-center">
        <div class="body-content col col-lg-6">
            <!--Body content-->
            
    
    
<div class="postindex">
    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../2024/12/install-cockpit-on-remote-linux-vm.html" class="u-url">Install Cockpit on Remote Linux VM</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Chillar Anand
            </span></p>
            <p class="dateline">
            <a href="../2024/12/install-cockpit-on-remote-linux-vm.html" rel="bookmark">
            <time class="published dt-published" datetime="2024-12-31T04:24:07+05:30" itemprop="datePublished" title="2025-12-31">2025-12-31</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <h4>Introduction</h4>
<p><img alt="Cockpit" src="../images/cockpit-how-to.png"></p>
<p>Cockpit is an easy to use web-based interface(like a cPanel) for managing Linux servers. When we want to provide access to non-developers or people who are new to linux, it is a good idea to get them started with Cockpit. It provides a user-friendly interface to manage services, containers, storage, logs, and more.</p>
<h4>Setup</h4>
<p>Let's create a new Ubuntu VM and install Cockpit on it.</p>
<pre class="code literal-block">sudo apt update
. /etc/os-release
sudo apt install -t <span class="si">${</span><span class="nv">VERSION_CODENAME</span><span class="si">}</span>-backports cockpit
</pre>
<p>Once the installation is complete, we can get the public ip of the VM and access the Cockpit web interface running on port 9090.</p>
<p>It will be difficult to remember the public ip of the VM. So, let's create a DNS record for the VM. Let's add an <code>A</code> record in DNS settings to point <code>cockpit.avilpage.com</code> to the public ip of the VM.</p>
<h4>Reverse Proxy</h4>
<p>Let's set up a reverse proxy to access the Cockpit web interface using a subdomain.</p>
<pre class="code literal-block">sudo apt install caddy
</pre>
<p>Add the below configuration to <code>/etc/caddy/Caddyfile</code>.</p>
<pre class="code literal-block">cockpit.avilpage.com <span class="o">{</span>
    reverse_proxy localhost:9090
<span class="o">}</span>
</pre>
<p>We need <code>Origins</code> to Cockpit configuration at <code>/etc/cockpit/cockpit.conf</code> to allow requests from the subdomain.</p>
<pre class="code literal-block"><span class="o">[</span>WebService<span class="o">]</span>
<span class="nv">Origins</span> <span class="o">=</span> https://cockpit.avilpage.com
</pre>
<p>Restart both services and open <a href="https://cockpit.avilpage.com">https://cockpit.avilpage.com</a> in browser.</p>
<pre class="code literal-block">sudo systemctl restart cockpit
sudo systemctl restart caddy
</pre>
<h4>Conclusion</h4>
<p>Cockpit web UI is a great tool to manage Linux servers even for non-developers. Users can browse/manage logs, services, etc. It also provides a terminal to run commands on the server</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../2024/11/mastering-partial-covered-calls.html" class="u-url">Mastering "Partial Covered Calls" - Part 1</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Chillar Anand
            </span></p>
            <p class="dateline">
            <a href="../2024/11/mastering-partial-covered-calls.html" rel="bookmark">
            <time class="published dt-published" datetime="2024-11-30T12:22:10+05:30" itemprop="datePublished" title="2024-11-30">2024-11-30</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <h4>Covered Calls</h4>
<p>In a covered call strategy, we buy one lot of stocks (or 1 Future) and sell at the money call option. The payoff diagram looks like this:</p>
<p><img alt="Covered Call" src="../images/covered-call.png"></p>
<p>There are 2 drawbacks of this strategy:</p>
<ol>
<li>It requires a lot of capital to buy the shares. We can't fully use the margin from pledging the stocks.</li>
<li>We need to sell the stocks at expiry if stock price closes above the strike price.</li>
</ol>
<p>To overcome this limitation, we can use a strategy called "partial covered calls."</p>
<h4>Partial Covered Calls</h4>
<p>Instead of buying one lot of shares, we can buy "partial" or "fractional" lot of shares and then sell a far away call option instead of at the money call option. </p>
<p>For example, we can buy 0.15 lot of shares and sell a call option which is 10% away from the current price. The payoff diagram looks like this:</p>
<p><img alt="Partial Covered Call" src="../images/partial-covered-call.png"></p>
<p>Here we can pledge the stocks we have bought and use the margin to sell call option using that margin.</p>
<p>Since we are selling a call option which is far away from the current price, the probability of the call option getting exercised is very low. So we can keep the premium we received from selling the call option.</p>
<p>In addition to that, we get the long term capital appreciation of the stocks we have bought and there won't be short term capital gains tax on them.</p>
<h4>Conclusion</h4>
<p>If you want to hold the stock for long but still want to generate regular income from it, then partial covered calls is a good strategy to consider.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../2024/10/cube-cubicle.html" class="u-url">Cube &amp; Cubicle</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Chillar Anand
            </span></p>
            <p class="dateline">
            <a href="../2024/10/cube-cubicle.html" rel="bookmark">
            <time class="published dt-published" datetime="2024-10-31T09:05:37+05:30" itemprop="datePublished" title="2024-10-31">2024-10-31</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <h4>Rubiks Cube</h4>
<p>When I was in college, I was traveling to a friend's place and missed bus at midnight. The next bus was at 4 AM. While I was bored waiting for the bus, I found Rubik's Cube in a shop.</p>
<p>I scrambled the cube and spent the next 4 hours trying to solve the cube. I managed to solve one color. When I tried to solve the next color, the pieces in the previous layer started missing.</p>
<p>Even after spending a lot of time in the next 3 weeks, I couldn't solve it and gave up.</p>
<p>After a couple of years, when I "learnt" about the internet, I searched and found simple algorithms to solve the cube. Within a few days, I was able to solve the cube in a minute.</p>
<h4>Office Cubicles</h4>
<p>In the final year of college, there were placements. When I was preparing resume, I included "I can solve Rubik's Cube in a minute" in it.</p>
<p>During the interview, interviewer asked me if I can really solve the cube in a minute. He asked me to get my cube and show him during the lunch break. I did.
Luckily, I got hired.</p>
<p>Even though, I was hired for Wipro I didn't join. I went to Bangalore and started applying for start-up jobs.</p>
<p>I went for an interview at a web development company in Malleswaram, Bangalore. The CEO looked at my résumé, took out a cube from his desk. He handed the cube to me, showed an empty cubicle behind me and said, "If you solve the cube in a minute, that cubicle is yours."</p>
<p>Just by learning the cube, I was able to land a job an at an MNC(Multi National Company) and a startup as well.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../2024/09/tailscale-cgnat-conflicts-resolution.html" class="u-url">tailscale: Resolving CGNAT (100.x.y.z) Conflicts</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Chillar Anand
            </span></p>
            <p class="dateline">
            <a href="../2024/09/tailscale-cgnat-conflicts-resolution.html" rel="bookmark">
            <time class="published dt-published" datetime="2024-09-07T12:50:05+05:30" itemprop="datePublished" title="2024-09-07">2024-09-07</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <h4>Introduction</h4>
<p>In an earlier blog post, I wrote about using tailscale to remotely access any device<sup id="fnref:ap"><a class="footnote-ref" href="../2024/09/tailscale-cgnat-conflicts-resolution.html#fn:ap">1</a></sup>. Tailscale uses 100.64.0.0/10 subnet<sup id="fnref:ts100"><a class="footnote-ref" href="../2024/09/tailscale-cgnat-conflicts-resolution.html#fn:ts100">2</a></sup> to assign unique IP addresses to each device.</p>
<p>When a tailscale node joins another campus network<sup id="fnref:pn"><a class="footnote-ref" href="../2024/09/tailscale-cgnat-conflicts-resolution.html#fn:pn">3</a></sup> (schools, universities, offices) that uses the same subnet, it will face conflicts. Let's see how to resolve this.</p>
<h4>Private Network</h4>
<p><img src="../images/tailscale-cgnat2.png" alt="tailscale dashboard"></p>
<p>In the above scenario, node C1 will be able to connect C2 &amp; C3 as they are in the same network.</p>
<p>Once we start tailscale on node C1, it will get a 100.x.y.z IP address from tailscale subnet. Now, node C1 will not be able to connect to node C2 &amp; C3.</p>
<p>To avoid conflicts with the existing network, we can configure tailscale to use a "smaller" subnet using "ipPool".</p>
<pre class="code literal-block"><span class="p">{</span>
    <span class="nt">"acls"</span><span class="p">:</span> <span class="p">[</span>
        <span class="s2">"..."</span>
    <span class="p">],</span>
    <span class="nt">"nodeAttrs"</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span>
            <span class="nt">"target"</span><span class="p">:</span> <span class="p">[</span>
                <span class="s2">"autogroup:admin"</span>
            <span class="p">],</span>
            <span class="nt">"ipPool"</span><span class="p">:</span> <span class="p">[</span>
                <span class="s2">"100.100.96.0/20"</span>
            <span class="p">]</span>
        <span class="p">}</span>
    <span class="p">]</span>
<span class="p">}</span>
</pre>
<p>Once it is configured, taiscale will start assigning IP addresses from the new subnet. Even though ip address allocation is limited, we can't still access nodes in other subnets due to a bug<sup id="fnref:tsb"><a class="footnote-ref" href="../2024/09/tailscale-cgnat-conflicts-resolution.html#fn:tsb">5</a></sup> in tailscale.</p>
<p>As a workaround, we can manually update the iptables to route traffic to the correct subnet.</p>
<p>Lets look at the iptables rules added by tailscale by stopping it and then starting it.</p>
<p><img src="../images/tailscale-cgnat3.png" alt="tailscale iptables rules"></p>
<p><img src="../images/tailscale-cgnat4.png" alt="tailscale iptables rules"></p>
<p>The highlighted rule drops any incoming packet that doesn't originate from tailscale0 interface, and source IP is 100.64.0.0/10 (100.64.0.0 to 100.127.255.255).</p>
<p>Let's delete this rule and add a new rule to restrict the source IP to 100.100.96.0/20 (100.100.96.1 to 100.100.111.254).</p>
<pre class="code literal-block">$ sudo iptables --delete ts-input --source <span class="m">100</span>.64.0.0/10 ! -i tailscale0 -j DROP
$ sudo iptables --insert ts-input <span class="m">3</span> --source <span class="m">100</span>.100.96.0/20 ! -i tailscale0 -j DROP
</pre>
<p><img src="../images/tailscale-cgnat5.png" alt="tailscale iptables rules"></p>
<h4>Conclusion</h4>
<p>By configuring tailscale to use a smaller subnet, we can avoid conflicts with existing networks. Even though there is a bug in tailscale, we can manually update iptables to route traffic to the correct subnet.</p>
<div class="footnote">
<hr>
<ol>
<li id="fn:ap">
<p><a href="../2023/09/tailscale-remote-ssh-raspberry-pi.html">tailscale: Remotely access any device</a> <a class="footnote-backref" href="../2024/09/tailscale-cgnat-conflicts-resolution.html#fnref:ap" title="Jump back to footnote 1 in the text">↩</a></p>
</li>
<li id="fn:ts100">
<p><a href="https://tailscale.com/kb/1015/100.x-addresses">https://tailscale.com/kb/1015/100.x-addresses</a> <a class="footnote-backref" href="../2024/09/tailscale-cgnat-conflicts-resolution.html#fnref:ts100" title="Jump back to footnote 2 in the text">↩</a></p>
</li>
<li id="fn:pn">
<p><a href="https://en.wikipedia.org/wiki/Private_network">https://en.wikipedia.org/wiki/Private_network</a> <a class="footnote-backref" href="../2024/09/tailscale-cgnat-conflicts-resolution.html#fnref:pn" title="Jump back to footnote 3 in the text">↩</a></p>
</li>
<li id="fn:ip">
<p><a href="https://tailscale.com/kb/1304/ip-pool">https://tailscale.com/kb/1304/ip-pool</a> <a class="footnote-backref" href="../2024/09/tailscale-cgnat-conflicts-resolution.html#fnref:ip" title="Jump back to footnote 4 in the text">↩</a></p>
</li>
<li id="fn:tsb">
<p><a href="https://github.com/tailscale/tailscale/issues/1381">https://github.com/tailscale/tailscale/issues/1381</a> <a class="footnote-backref" href="../2024/09/tailscale-cgnat-conflicts-resolution.html#fnref:tsb" title="Jump back to footnote 5 in the text">↩</a></p>
</li>
</ol>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../2024/08/mastering-kraken2-fda-argos-index.html" class="u-url">Mastering Kraken2 - Part 4 - Build FDA-ARGOS Index</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Chillar Anand
            </span></p>
            <p class="dateline">
            <a href="../2024/08/mastering-kraken2-fda-argos-index.html" rel="bookmark">
            <time class="published dt-published" datetime="2024-08-24T15:28:00+05:30" itemprop="datePublished" title="2024-08-24">2024-08-24</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <h4>Mastering Kraken2</h4>
<p><a href="../2024/07/mastering-kraken2-initial-runs.html">Part 1 - Initial Runs</a></p>
<p><a href="../2024/07/mastering-kraken2-performance-optimisation.html">Part 2 - Classification Performance Optimisation</a></p>
<p><a href="../2024/07/mastering-kraken2-build-custom-db.html">Part 3 - Build custom database indices</a></p>
<p><a href="../2024/08/mastering-kraken2-fda-argos-index.html">Part 4 - Build FDA-ARGOS index</a> (this post)</p>
<p>Part 5 - Regular vs Fast Builds (upcoming)</p>
<p>Part 6 - Benchmarking (upcoming)</p>
<h4>Introduction</h4>
<p>In the previous post, we learnt how to build a custom index for Kraken2.</p>
<p>FDA-ARGOS<sup id="fnref:argos"><a class="footnote-ref" href="../2024/08/mastering-kraken2-fda-argos-index.html#fn:argos">1</a></sup> is a popular database with quality reference genomes for diagnostic usage. Let's build an index for FDA-ARGOS.</p>
<h4>FDA-ARGOS Kraken2 Index</h4>
<p>FDA-ARGOS db is available at NCBI<sup id="fnref:ncbi"><a class="footnote-ref" href="../2024/08/mastering-kraken2-fda-argos-index.html#fn:ncbi">2</a></sup> from which we can download the assembly file.</p>
<p><img src="../images/fda-argos-kraken2-index.png" alt="FDA-ARGOS NCBI" class="img-fluid"></p>
<p>We can extract accession numbers from the assembly file and then download the genomes from these accession ids.</p>
<pre class="code literal-block">$ grep -e <span class="s2">"^#"</span> -v PRJNA231221_AssemblyDetails.txt <span class="p">|</span> cut -d<span class="s1">$'\t'</span> -f1 &gt; accessions.txt

$ wc accessions.txt
 <span class="m">1428</span>  <span class="m">1428</span> <span class="m">22848</span> accessions.txt

$ ncbi-genome-download --section genbank --assembly-accessions accessions.txt --progress-bar bacteria --parallel <span class="m">40</span>
</pre>
<p>It took ~8 minutes to download all the genomes, and the downloaded file size is ~4GB.</p>
<p>We can use kraken-db-builder<sup id="fnref:kdb"><a class="footnote-ref" href="../2024/08/mastering-kraken2-fda-argos-index.html#fn:kdb">3</a></sup> tool to build index from these genbank genome files.</p>
<pre class="code literal-block"><span class="c1"># kraken-db-builder needs this to convert gbff to fasta format</span>
$ conda install -c bioconda any2fasta

$ kraken-db-builder --genomes-dir genbank --threads <span class="m">36</span> --db-name k2_argos
</pre>
<p>It took ~30 minutes to build the index.</p>
<h4>Conclusion</h4>
<p>We have built a Kraken2 index for the FDA-ARGOS database on 2024-Aug-24.</p>
<ul>
<li><a href="https://github.com/ChillarAnand/avilpage.com/tree/master/scripts/kraken2_argos">FDA-ARGOS Library</a></li>
<li>
<a href="https://drive.google.com/file/d/1PbwriW3i3pkXJMFF5nq9OK_EqrwPiLWr/view">Kraken2 Gzipped Index file</a> (gzip size: 2.6GB, index size: 3.8GB, md5sum: 1dd946d2e405dfec35ed3e319e9dfeac)</li>
<li><a href="https://github.com/ChillarAnand/avilpage.com/tree/master/scripts/kraken2_argos">Kraken2 Inspect file</a></li>
</ul>
<p>In the next post, we will look at the differences between regular and fast builds.</p>
<div class="footnote">
<hr>
<ol>
<li id="fn:argos">
<p><a href="https://www.nature.com/articles/s41467-019-11306-6">https://www.nature.com/articles/s41467-019-11306-6</a> <a class="footnote-backref" href="../2024/08/mastering-kraken2-fda-argos-index.html#fnref:argos" title="Jump back to footnote 1 in the text">↩</a></p>
</li>
<li id="fn:ncbi">
<p><a href="https://www.ncbi.nlm.nih.gov/bioproject/231221">https://www.ncbi.nlm.nih.gov/bioproject/231221</a> <a class="footnote-backref" href="../2024/08/mastering-kraken2-fda-argos-index.html#fnref:ncbi" title="Jump back to footnote 2 in the text">↩</a></p>
</li>
<li id="fn:kdb">
<p><a href="https://avilpage.com/kdb.html">https://avilpage.com/kdb.html</a> <a class="footnote-backref" href="../2024/08/mastering-kraken2-fda-argos-index.html#fnref:kdb" title="Jump back to footnote 3 in the text">↩</a></p>
</li>
</ol>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../2024/08/midnight-coding-narendra-modi-ivanka-trump.html" class="u-url">Midnight Coding for Narendra Modi &amp; Ivanka Trump</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Chillar Anand
            </span></p>
            <p class="dateline">
            <a href="../2024/08/midnight-coding-narendra-modi-ivanka-trump.html" rel="bookmark">
            <time class="published dt-published" datetime="2024-08-18T05:55:43+05:30" itemprop="datePublished" title="2024-08-18">2024-08-18</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p><img src="../images/midnight-modi-trump.png" alt="GES 2017, modi trump mitra"></p>
<h4>Introduction</h4>
<p>In 2017, GES Event was held in Hyderabad, India. Narendra Modi (the Prime Minister of India) &amp; Ivanka Trump (daughter of the then US President Donald Trump) were the chief guests.</p>
<p>At that time, I was part of Invento team, and we decided to develop a new version of Mitra robot for the event.</p>
<h4>The Challenge</h4>
<p>We had to develop the new version of Mitra robot in a short span of time. Entire team worked day and night to meet the deadlines and finish the new version.</p>
<p>We went to Hyderabad from Bangalore a few days before to prepare for the event. We have cleared multiple security checks, did some demos for various people before the event.</p>
<p>A day before the event, around 9 PM we discovered a critical bug in the software. Due to that bug, the Robot motors were running at full speed which was dangerous. If the robot hits someone at full speed, it could cause serious injuries.</p>
<p>I spent a few hours debugging the issue and even tried rolling back a few versions. Still, I couldn't pinpoint the issue.</p>
<p>Since we need only a small set of Robot features, we decided to create a new version of the software with only limited features. I spent the next few hours creating a new release.</p>
<p>After that, we spent the next few hours doing extensive testing to make sure there are no bugs in the new version.</p>
<p>It was almost morning by the time we were done with testing. We quickly went to hotel to have some rest and get back early for the event.</p>
<h4>Conclusion</h4>
<p>Mitra robot welcoming Modi &amp; Trump went very well. You can read about Balaji Viswanathan's experience at GES 2017 on Quora<sup id="fnref:quora"><a class="footnote-ref" href="../2024/08/midnight-coding-narendra-modi-ivanka-trump.html#fn:quora">1</a></sup>.</p>
<p><img src="../images/midnight-modi-trump-anand.jpg" alt="GES 2017, modi trump mitra anand"></p>
<div class="footnote">
<hr>
<ol>
<li id="fn:quora">
<p><a href="https://www.quora.com/How-was-Balaji-Viswanathans-overall-experience-attending-the-Global-Entrepreneurship-Summit-2017-held-in-Hyderabad-Where-his-Inventos-Mitra-is-launched">Answer on Quora</a> <a class="footnote-backref" href="../2024/08/midnight-coding-narendra-modi-ivanka-trump.html#fnref:quora" title="Jump back to footnote 1 in the text">↩</a></p>
</li>
</ol>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../2024/08/guide-systemd-timer-cronjob.html" class="u-url">How (and when) to use systemd timer instead of cronjob</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Chillar Anand
            </span></p>
            <p class="dateline">
            <a href="../2024/08/guide-systemd-timer-cronjob.html" rel="bookmark">
            <time class="published dt-published" datetime="2024-08-05T13:07:50+05:30" itemprop="datePublished" title="2024-08-05">2024-08-05</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <h4>Introduction</h4>
<pre class="code literal-block">* * * * * bash demo.sh
</pre>
<p>Just a single line of code is sufficient to schedule a cron job. However, there are some scenarios where I find systemd timer more useful than cronjob.</p>
<h4>How to use systemd timer</h4>
<p>We need to create a service file(contains the script to be run) and a timer(contains the schedule).</p>
<pre class="code literal-block"><span class="c1"># demo.service</span>
<span class="o">[</span>Unit<span class="o">]</span>
<span class="nv">Description</span><span class="o">=</span>Demo service

<span class="o">[</span>Service<span class="o">]</span>
<span class="nv">ExecStart</span><span class="o">=</span>bash demo.sh
</pre>
<pre class="code literal-block"><span class="c1"># demo.timer</span>
<span class="o">[</span>Unit<span class="o">]</span>
<span class="nv">Description</span><span class="o">=</span>Run myscript.service every <span class="m">1</span> minutes

<span class="o">[</span>Timer<span class="o">]</span>
<span class="nv">OnBootSec</span><span class="o">=</span>1min
<span class="nv">OnUnitActiveSec</span><span class="o">=</span>1min

<span class="o">[</span>Install<span class="o">]</span>
<span class="nv">WantedBy</span><span class="o">=</span>multi-user.target
</pre>
<p>We can copy these files to <code>/etc/systemd/system/</code> and enable the timer.</p>
<pre class="code literal-block">$ sudo cp demo.service demo.timer /etc/systemd/system/

$ sudo systemctl daemon-reload

$ sudo systemctl <span class="nb">enable</span> --now demo.timer
</pre>
<p>We can use <code>systemctl</code> to see when the task is executed last and when it will be executed next.</p>
<pre class="code literal-block">$ sudo systemctl list-timers --all
</pre>
<p><img src="../images/systemd-timer-cronjob.png" alt="systemd timer"></p>
<h4>Use Cases</h4>
<ul>
<li>
<p>Singleton - In the above example, lets say <code>demo.sh</code> takes ~10 minutes to run. With cron job, in ten minutes we will have 10 instances of <code>demo.sh</code> running. This is not ideal. With systemd timer, it will ensure only one instance of <code>demo.sh</code> is running at a time.</p>
</li>
<li>
<p>On demand runs - If we want to test out the script/job, systemd allows us to immediately run it with usual <code>systemctl start demo</code> without needing to run the script manually.</p>
</li>
<li>
<p>Timer - With cron, we can run tasks upto a minute precision. Timer can run tasks till <code>second</code> level precision. </p>
</li>
</ul>
<pre class="code literal-block"><span class="o">[</span>Timer<span class="o">]</span>
<span class="nv">OnCalendar</span><span class="o">=</span>*-*-* <span class="m">15</span>:30:15
</pre>
<p>In addition to that, we can run tasks based on system events. For example, we can run a script 15 minutes from reboot.</p>
<pre class="code literal-block"><span class="o">[</span>Timer<span class="o">]</span>
<span class="nv">OnBootSec</span><span class="o">=</span>15min
</pre>
<h4>Conclusion</h4>
<p>Systemd timer is a powerful tool that can replace cronjob in many scenarios. It provides more control and flexibility over cronjob. However, cronjob is still a good choice for simple scheduling tasks.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../2024/07/mastering-kraken2-build-custom-db.html" class="u-url">Mastering Kraken2 - Part 3 - Build Custom Database</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Chillar Anand
            </span></p>
            <p class="dateline">
            <a href="../2024/07/mastering-kraken2-build-custom-db.html" rel="bookmark">
            <time class="published dt-published" datetime="2024-08-01T10:52:30+05:30" itemprop="datePublished" title="2024-08-01">2024-08-01</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <h4>Mastering Kraken2</h4>
<p><a href="../2024/07/mastering-kraken2-initial-runs.html">Part 1 - Initial Runs</a></p>
<p><a href="../2024/07/mastering-kraken2-performance-optimisation.html">Part 2 - Classification Performance Optimisation</a></p>
<p><a href="../2024/07/mastering-kraken2-build-custom-db.html">Part 3 - Build custom database indices</a> (this post)</p>
<p><a href="../2024/08/mastering-kraken2-fda-argos-index.html">Part 4 - Build FDA-ARGOS index</a> </p>
<p>Part 5 - Regular vs Fast Builds (upcoming)</p>
<p>Part 6 - Benchmarking (upcoming)</p>
<h4>Introduction</h4>
<p>In the previous post, we learned how to improve kraken2<sup id="fnref:k2"><a class="footnote-ref" href="../2024/07/mastering-kraken2-build-custom-db.html#fn:k2">1</a></sup> classification performance. So far we have downloaded &amp; used pre-built genome indices(databases). </p>
<p>In this post, let's build a custom database for kraken2. For simplicity, let's use only refseq archaea genomes<sup id="fnref:rag"><a class="footnote-ref" href="../2024/07/mastering-kraken2-build-custom-db.html#fn:rag">2</a></sup> for building the index.</p>
<h4>Building Custom Database</h4>
<p>First, we need to download the taxonomy files. We can use the <code>k2</code> script provided by kraken2.</p>
<pre class="code literal-block">$ k2 download-taxonomy --db custom_db
</pre>
<p>This takes ~30 minutes depending on the network speed. The taxonomy files are downloaded to the <code>custom_db/taxonomy</code> directory.</p>
<pre class="code literal-block">$ ls custom_db/taxonomy
citations.dmp  division.dmp  gencode.dmp  merged.dmp  nodes.dmp
nucl_wgs.accession2taxid delnodes.dmp  gc.prt 
images.dmp  names.dmp  nucl_gb.accession2taxid  readme.txt

$ du -hs custom_db/taxonomy
43G     custom_db/taxonomy
</pre>
<p>For simplicity, let's use the archaea refseq genomes. We can use <code>kraken2-build</code> to download the refseq genomes.</p>
<pre class="code literal-block">$ k2 download-library --library archaea --db custom_db
</pre>
<p>This runs on a single thread. Instead of using <code>kraken2-build</code>, we can use <code>ncbi-genome-download</code><sup id="fnref:ngd"><a class="footnote-ref" href="../2024/07/mastering-kraken2-build-custom-db.html#fn:ngd">3</a></sup> tool to download the genomes. This provides much granular control over the download process. For example, we can download only <code>--assembly-levels complete</code> genomes. We can also download multiple genomes in parallel.</p>
<pre class="code literal-block">$ pip install ncbi-genome-download

$ conda install -c bioconda ncbi-genome-download

$ ncbi-genome-download -s refseq -F fasta --parallel <span class="m">40</span> -P archaea
Checking assemblies: <span class="m">100</span>%<span class="p">|</span>███<span class="p">|</span> <span class="m">2184</span>/2184 <span class="o">[</span><span class="m">00</span>:19&lt;<span class="m">00</span>:00, <span class="m">111</span>.60entries/s<span class="o">]</span>
Downloading assemblies: <span class="m">100</span>%<span class="p">|</span>███<span class="p">|</span> <span class="m">2184</span>/2184  <span class="o">[</span><span class="m">02</span>:04&lt;<span class="m">00</span>:00,  <span class="m">4</span>.54s/files<span class="o">]</span>
Downloading assemblies: 2184files <span class="o">[</span><span class="m">02</span>:23, 2184files/s<span class="o">]</span>
</pre>
<p>In just 2 minutes, it has downloaded all the files. Lets gunzip the files.</p>
<pre class="code literal-block">$ find refseq -name <span class="s2">"*.gz"</span> -print0 <span class="p">|</span> parallel -0 gunzip

$ du -hs refseq
<span class="m">5</span>.9G    refseq
</pre>
<p>Lets add all fasta genome files to the custom database</p>
<pre class="code literal-block">$ <span class="nb">time</span> find refseq -name <span class="s2">"*.fna"</span> -exec kraken2-build --add-to-library <span class="o">{}</span> --db custom_db <span class="se">\;</span>
<span class="m">667</span>.46s user <span class="m">90</span>.78s system <span class="m">106</span>% cpu <span class="m">12</span>:54.80 total
</pre>
<p><code>kraken2-build</code> doesn't use multiple threads for adding genomes to the database. In addition to that, it also doesn't check if the genome is already present in the database. </p>
<p>Let's use <code>k2</code> for adding genomes to the database.</p>
<pre class="code literal-block"><span class="nb">export</span> <span class="nv">KRAKEN_NUM_THREADS</span><span class="o">=</span><span class="m">40</span>

$ find . -name <span class="s2">"*.fna"</span> -exec k2 add-to-library --files <span class="o">{}</span> --db custom_db <span class="se">\;</span>
<span class="m">668</span>.37s user <span class="m">88</span>.44s system <span class="m">159</span>% cpu <span class="m">7</span>:54.40 total
</pre>
<p>This took only half the time compared to <code>kraken2-build</code>.</p>
<p>Let's build the index from the library.</p>
<pre class="code literal-block">$ <span class="nb">time</span> kraken2-build --db custom_db --build --threads <span class="m">36</span>
Creating sequence ID to taxonomy ID map <span class="o">(</span>step <span class="m">1</span><span class="o">)</span>...
Found <span class="m">0</span>/125783 targets, searched through <span class="m">60000000</span> accession IDs...
Found <span class="m">59923</span>/125783 targets, searched through <span class="m">822105735</span> accession IDs, search complete.
lookup_accession_numbers: <span class="m">65860</span>/125783 accession numbers remain unmapped, see unmapped.txt <span class="k">in</span> DB directory
Sequence ID to taxonomy ID map complete. <span class="o">[</span>2m1.950s<span class="o">]</span>
Estimating required capacity <span class="o">(</span>step <span class="m">2</span><span class="o">)</span>...
Estimated <span class="nb">hash</span> table requirement: <span class="m">5340021028</span> bytes
Capacity estimation complete. <span class="o">[</span><span class="m">23</span>.875s<span class="o">]</span>
Building database files <span class="o">(</span>step <span class="m">3</span><span class="o">)</span>...
Taxonomy parsed and converted.
CHT created with <span class="m">11</span> bits reserved <span class="k">for</span> taxid.
Completed processing of <span class="m">59911</span> sequences, <span class="m">3572145823</span> bp
Writing data to disk...  complete.
Database files completed. <span class="o">[</span>12m3.368s<span class="o">]</span>
Database construction complete. <span class="o">[</span>Total: 14m29.666s<span class="o">]</span>
kraken2-build --db custom_db --build --threads <span class="m">36</span>  <span class="m">24534</span>.98s user <span class="m">90</span>.50s system <span class="m">2831</span>% cpu <span class="m">14</span>:29.75 total

$ ls -ll
.rw-rw-r-- <span class="m">5</span>.3G anand  <span class="m">1</span> Aug <span class="m">16</span>:35 hash.k2d
drwxrwxr-x    - anand  <span class="m">1</span> Aug <span class="m">12</span>:32 library
.rw-rw-r--   <span class="m">64</span> anand  <span class="m">1</span> Aug <span class="m">16</span>:35 opts.k2d
.rw-rw-r-- <span class="m">1</span>.5M anand  <span class="m">1</span> Aug <span class="m">16</span>:22 seqid2taxid.map
.rw-rw-r-- 115k anand  <span class="m">1</span> Aug <span class="m">16</span>:23 taxo.k2d
lrwxrwxrwx   <span class="m">20</span> anand  <span class="m">1</span> Aug <span class="m">12</span>:31 taxonomy
.rw-rw-r-- <span class="m">1</span>.2M anand  <span class="m">1</span> Aug <span class="m">16</span>:22 unmapped.txt
</pre>
<p>We are able to build index for ~6GB input files in ~15 minutes.</p>
<h4>Conclusion</h4>
<p>We learnt some useful tips to speed up the custom database creation process. In the next post, we will learn about regular vs. fast builds.</p>
<div class="footnote">
<hr>
<ol>
<li id="fn:k2">
<p><a href="https://ccb.jhu.edu/software/kraken2/">Kraken2</a> <a class="footnote-backref" href="../2024/07/mastering-kraken2-build-custom-db.html#fnref:k2" title="Jump back to footnote 1 in the text">↩</a></p>
</li>
<li id="fn:rag">
<p><a href="https://ftp.ncbi.nlm.nih.gov/genomes/refseq/archaea/">RefSeq Archaea genomes</a> <a class="footnote-backref" href="../2024/07/mastering-kraken2-build-custom-db.html#fnref:rag" title="Jump back to footnote 2 in the text">↩</a></p>
</li>
<li id="fn:ngd">
<p><a href="https://github.com/kblin/ncbi-genome-download">https://github.com/kblin/ncbi-genome-download</a> <a class="footnote-backref" href="../2024/07/mastering-kraken2-build-custom-db.html#fnref:ngd" title="Jump back to footnote 3 in the text">↩</a></p>
</li>
</ol>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../2024/07/mastering-kraken2-performance-optimisation.html" class="u-url">Mastering Kraken2 - Part 2 - Performance Optimisation</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Chillar Anand
            </span></p>
            <p class="dateline">
            <a href="../2024/07/mastering-kraken2-performance-optimisation.html" rel="bookmark">
            <time class="published dt-published" datetime="2024-07-28T10:51:30+05:30" itemprop="datePublished" title="2024-07-28">2024-07-28</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <h4>Mastering Kraken2</h4>
<p><a href="../2024/07/mastering-kraken2-initial-runs.html">Part 1 - Initial Runs</a></p>
<p><a href="../2024/07/mastering-kraken2-performance-optimisation.html">Part 2 - Classification Performance Optimisation</a> (this post)</p>
<p><a href="../2024/07/mastering-kraken2-build-custom-db.html">Part 3 - Build custom database indices</a></p>
<p><a href="../2024/08/mastering-kraken2-fda-argos-index.html">Part 4 - Build FDA-ARGOS index</a> </p>
<p>Part 5 - Regular vs Fast Builds (upcoming)</p>
<p>Part 6 - Benchmarking (upcoming)</p>
<h4>Introduction</h4>
<p>In the previous post, we learned how to set up kraken2<sup id="fnref:k2"><a class="footnote-ref" href="../2024/07/mastering-kraken2-performance-optimisation.html#fn:k2">1</a></sup>, download pre-built indices, and run kraken2. In this post, we will learn various ways to speed up the classification process.</p>
<h4>Increasing RAM</h4>
<p>Kraken2 standard database is ~80GB in size. It is recommended to have at least db size RAM to run kraken2 efficiently<sup id="fnref:ksr"><a class="footnote-ref" href="../2024/07/mastering-kraken2-performance-optimisation.html#fn:ksr">2</a></sup>. Let's use 128GB RAM machine and run kraken2 with ERR10359977<sup id="fnref:err"><a class="footnote-ref" href="../2024/07/mastering-kraken2-performance-optimisation.html#fn:err">3</a></sup> sample.</p>
<pre class="code literal-block">$ <span class="nb">time</span> kraken2 --db k2_standard --report report.txt ERR10359977.fastq.gz &gt; output.txt
Loading database information... <span class="k">done</span>.
<span class="m">95064</span> sequences <span class="o">(</span><span class="m">14</span>.35 Mbp<span class="o">)</span> processed <span class="k">in</span> <span class="m">2</span>.142s <span class="o">(</span><span class="m">2662</span>.9 Kseq/m, <span class="m">402</span>.02 Mbp/m<span class="o">)</span>.
  <span class="m">94816</span> sequences classified <span class="o">(</span><span class="m">99</span>.74%<span class="o">)</span>
  <span class="m">248</span> sequences unclassified <span class="o">(</span><span class="m">0</span>.26%<span class="o">)</span>
kraken2 --db k2_standard --report report.txt ERR10359977.fastq.gz &gt;   <span class="m">1</span>.68s user <span class="m">152</span>.19s system <span class="m">35</span>% cpu <span class="m">7</span>:17.55 total
</pre>
<p>Now the time taken has come down from 40 minutes to 7 minutes. The classification speed has also increased from 0.19 Mbp/m to 402.02 Mbp/m.</p>
<p>The previous sample had only a few reads, and the speed is not a good indicator. Let's run kraken2 with a larger sample.</p>
<pre class="code literal-block">$ <span class="nb">time</span> kraken2 --db k2_standard --report report.txt --paired SRR6915097_1.fastq.gz SRR6915097_2.fastq.gz &gt; output.txt
Loading database information... <span class="k">done</span>.
Processed <span class="m">14980000</span> sequences <span class="o">(</span><span class="m">2972330207</span> bp<span class="o">)</span> ...
<span class="m">17121245</span> sequences <span class="o">(</span><span class="m">3397</span>.15 Mbp<span class="o">)</span> processed <span class="k">in</span> <span class="m">797</span>.424s <span class="o">(</span><span class="m">1288</span>.2 Kseq/m, <span class="m">255</span>.61 Mbp/m<span class="o">)</span>.
  <span class="m">9826671</span> sequences classified <span class="o">(</span><span class="m">57</span>.39%<span class="o">)</span>
  <span class="m">7294574</span> sequences unclassified <span class="o">(</span><span class="m">42</span>.61%<span class="o">)</span>
kraken2 --db k2_standard --report report.txt --paired &gt; output.txt  <span class="m">526</span>.39s user <span class="m">308</span>.24s system <span class="m">68</span>% cpu <span class="m">20</span>:23.86 total
</pre>
<p>This took almost 20 minutes to classify ~3 Gbp of data. Out of 20 minutes, 13 minutes was spent in classification. The remaining time in loading the db into memory.</p>
<p>Let's use k2_plusPF<sup id="fnref:k2p"><a class="footnote-ref" href="../2024/07/mastering-kraken2-performance-optimisation.html#fn:k2p">4</a></sup> db, which is twice the size of k2_standard and run kraken2.</p>
<pre class="code literal-block">$ <span class="nb">time</span> kraken2 --db k2_plusfp --report report.txt --paired SRR6915097_1.fastq.gz SRR6915097_2.fastq.gz &gt; output.txt
Loading database information...done.
<span class="m">17121245</span> sequences <span class="o">(</span><span class="m">3397</span>.15 Mbp<span class="o">)</span> processed <span class="k">in</span> <span class="m">755</span>.290s <span class="o">(</span><span class="m">1360</span>.1 Kseq/m, <span class="m">269</span>.87 Mbp/m<span class="o">)</span>.
  <span class="m">9903824</span> sequences classified <span class="o">(</span><span class="m">57</span>.85%<span class="o">)</span>
  <span class="m">7217421</span> sequences unclassified <span class="o">(</span><span class="m">42</span>.15%<span class="o">)</span>
kraken2 --db k2_plusfp/ --report report.txt --paired SRR6915097_1.fastq.gz  &gt;   <span class="m">509</span>.71s user <span class="m">509</span>.51s system <span class="m">55</span>% cpu <span class="m">30</span>:35.49 total
</pre>
<p>This took ~30 minutes to complete, but the classification took only 13 minutes similar to k2_standard. The remaining time was spent in loading the db into memory.</p>
<h4>Preloading db into RAM</h4>
<p>We can use vmtouch<sup id="fnref:vmt"><a class="footnote-ref" href="../2024/07/mastering-kraken2-performance-optimisation.html#fn:vmt">5</a></sup> to preload db into RAM. kraken2 provides <code>--memory-mapping</code> option to use preloaded db. </p>
<pre class="code literal-block">$ vmtouch -vt k2_standard/hash.k2d k2_standard/opts.k2d k2_standard/taxo.k2d
           Files: <span class="m">3</span>
     Directories: <span class="m">0</span>
   Touched Pages: <span class="m">20382075</span> <span class="o">(</span>77G<span class="o">)</span>
         Elapsed: <span class="m">434</span>.77 seconds
</pre>
<p>When Linux requires RAM, it will incrementally evict the db from memory. To prevent this, we can copy the db to shared memory (/dev/shm) and then use vmtouch to preload the db.</p>
<pre class="code literal-block">$ cp -r k2_standard /dev/shm

$ vmtouch -t /dev/shm/*.k2d
</pre>
<p>Now, let's run kraken2 with <code>--memory-mapping</code> option.</p>
<pre class="code literal-block">$ <span class="nb">time</span> kraken2 --db k2_standard --report report.txt --memory-mapping --paired SRR6915097_1.fastq.gz SRR6915097_2.fastq.gz &gt; output.txt
Loading database information... <span class="k">done</span>.
<span class="m">17121245</span> sequences <span class="o">(</span><span class="m">3397</span>.15 Mbp<span class="o">)</span> processed <span class="k">in</span> <span class="m">532</span>.486s <span class="o">(</span><span class="m">1929</span>.2 Kseq/m, <span class="m">382</span>.79 Mbp/m<span class="o">)</span>.
  <span class="m">9826671</span> sequences classified <span class="o">(</span><span class="m">57</span>.39%<span class="o">)</span>
  <span class="m">7294574</span> sequences unclassified <span class="o">(</span><span class="m">42</span>.61%<span class="o">)</span>
  kraken2 --db k2_standard --report report.txt --paired SRR6915097_1.fastq.gz   &gt;  <span class="m">424</span>.20s user <span class="m">11</span>.76s system <span class="m">81</span>% cpu <span class="m">8</span>:54.98 total
</pre>
<p>Now the classification took only ~10 minutes.</p>
<h4>Multi threading</h4>
<p>kraken2 supports multiple threads. I am using a machine with 40 threads.</p>
<pre class="code literal-block">$ <span class="nb">time</span> kraken2 --db k2_standard --report report.txt --paired SRR6915097_1.fastq.gz SRR6915097_2.fastq.gz --memory-mapping --threads <span class="m">32</span> &gt; output.txt
Loading database information... <span class="k">done</span>.
<span class="m">17121245</span> sequences <span class="o">(</span><span class="m">3397</span>.15 Mbp<span class="o">)</span> processed <span class="k">in</span> <span class="m">71</span>.675s <span class="o">(</span><span class="m">14332</span>.5 Kseq/m, <span class="m">2843</span>.81 Mbp/m<span class="o">)</span>.
  <span class="m">9826671</span> sequences classified <span class="o">(</span><span class="m">57</span>.39%<span class="o">)</span>
  <span class="m">7294574</span> sequences unclassified <span class="o">(</span><span class="m">42</span>.61%<span class="o">)</span>
kraken2 --db k2_standard --report report.txt --paired SRR6915097_1.fastq.gz      <span class="m">556</span>.58s user <span class="m">22</span>.85s system <span class="m">762</span>% cpu <span class="m">1</span>:16.02 total
</pre>
<p>With 32 threads, the classification took only 1 minute. Beyond 32 threads, the classification time did not decrease significantly.</p>
<h4>Optimising input files</h4>
<p>So far we have used gzipped input files. Let's use unzipped input files and run kraken2.</p>
<pre class="code literal-block">$ gunzip SRR6915097_1.fastq.gz
$ gunzip SRR6915097_2.fastq.gz

$ <span class="nb">time</span> kraken2 --db k2_standard --report report.txt --paired SRR6915097_1.fastq SRR6915097_2.fastq --memory-mapping --threads <span class="m">30</span> &gt; output.txt
Loading database information... <span class="k">done</span>.
<span class="m">17121245</span> sequences <span class="o">(</span><span class="m">3397</span>.15 Mbp<span class="o">)</span> processed <span class="k">in</span> <span class="m">34</span>.809s <span class="o">(</span><span class="m">29512</span>.0 Kseq/m, <span class="m">5855</span>.68 Mbp/m<span class="o">)</span>.
  <span class="m">9826671</span> sequences classified <span class="o">(</span><span class="m">57</span>.39%<span class="o">)</span>
  <span class="m">7294574</span> sequences unclassified <span class="o">(</span><span class="m">42</span>.61%<span class="o">)</span>
kraken2 --db k2_standard --report report.txt --paired SRR6915097_1.fastq    <span class="m">30</span>   <span class="m">565</span>.03s user <span class="m">17</span>.12s system <span class="m">1530</span>% cpu <span class="m">38</span>.047 total
</pre>
<p>Now the classification time has come down to 40 seconds.</p>
<p>Since the input fastq files are paired, interleaving the files also takes time. Lets interleave the files and run kraken2.</p>
<p>To interleave the files, lets use <code>seqfu</code> tool.</p>
<pre class="code literal-block">$ conda install -y -c conda-forge -c bioconda <span class="s2">"seqfu&gt;1.10"</span>

$ seqfu interleave -1 SRR6915097_1.fastq.gz -2 SRR6915097_2.fastq.gz &gt; SRR6915097.fastq

$ <span class="nb">time</span> kraken2 --db k2_standard --report report.txt --memory-mapping SRR6915097.fq --threads <span class="m">32</span> &gt; output.txt
Loading database information... <span class="k">done</span>.
<span class="m">34242490</span> sequences <span class="o">(</span><span class="m">3397</span>.15 Mbp<span class="o">)</span> processed <span class="k">in</span> <span class="m">20</span>.199s <span class="o">(</span><span class="m">101714</span>.1 Kseq/m, <span class="m">10090</span>.91 Mbp/m<span class="o">)</span>.
  <span class="m">17983321</span> sequences classified <span class="o">(</span><span class="m">52</span>.52%<span class="o">)</span>
  <span class="m">16259169</span> sequences unclassified <span class="o">(</span><span class="m">47</span>.48%<span class="o">)</span>
kraken2 --db k2_standard --report report.txt --memory-mapping SRR6915097.fq  <span class="m">32</span>  <span class="m">618</span>.96s user <span class="m">18</span>.24s system <span class="m">2653</span>% cpu <span class="m">24</span>.013 total
</pre>
<p>Now the classification time has come down to 24 seconds. </p>
<h4>Conclusion</h4>
<p>In terms of classification speed, we have come a long way from 0.1 Mbp/m to 1200 Mbp/m. In the next post, we will learn how to optimise the creation of custom indices.</p>
<div class="footnote">
<hr>
<ol>
<li id="fn:k2">
<p><a href="https://ccb.jhu.edu/software/kraken2/">Kraken2</a> <a class="footnote-backref" href="../2024/07/mastering-kraken2-performance-optimisation.html#fnref:k2" title="Jump back to footnote 1 in the text">↩</a></p>
</li>
<li id="fn:ksr">
<p><a href="https://github.com/DerrickWood/kraken2/blob/master/docs/MANUAL.markdown#system-requirements">Kraken System Requirements</a> <a class="footnote-backref" href="../2024/07/mastering-kraken2-performance-optimisation.html#fnref:ksr" title="Jump back to footnote 2 in the text">↩</a></p>
</li>
<li id="fn:err">
<p><a href="ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR103/077/ERR10359977/ERR10359977.fastq.gz">ERR10359977.fastq.gz</a> <a class="footnote-backref" href="../2024/07/mastering-kraken2-performance-optimisation.html#fnref:err" title="Jump back to footnote 3 in the text">↩</a></p>
</li>
<li id="fn:k2p">
<p><a href="https://benlangmead.github.io/aws-indexes/k2">Genomic Index Zone - k2</a> <a class="footnote-backref" href="../2024/07/mastering-kraken2-performance-optimisation.html#fnref:k2p" title="Jump back to footnote 4 in the text">↩</a></p>
</li>
<li id="fn:vmt">
<p><a href="https://hoytech.com/vmtouch/">https://hoytech.com/vmtouch/</a> <a class="footnote-backref" href="../2024/07/mastering-kraken2-performance-optimisation.html#fnref:vmt" title="Jump back to footnote 5 in the text">↩</a></p>
</li>
</ol>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../2024/07/mastering-kraken2-initial-runs.html" class="u-url">Mastering Kraken2 - Part 1 - Initial Runs</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Chillar Anand
            </span></p>
            <p class="dateline">
            <a href="../2024/07/mastering-kraken2-initial-runs.html" rel="bookmark">
            <time class="published dt-published" datetime="2024-07-28T10:44:25+05:30" itemprop="datePublished" title="2024-07-28">2024-07-28</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <h4>Mastering Kraken2</h4>
<p><a href="../2024/07/mastering-kraken2-initial-runs.html">Part 1 - Initial Runs</a> (this post)</p>
<p><a href="../2024/07/mastering-kraken2-performance-optimisation.html">Part 2 - Classification Performance Optimisation</a></p>
<p><a href="../2024/07/mastering-kraken2-build-custom-db.html">Part 3 - Build custom database indices</a></p>
<p><a href="../2024/08/mastering-kraken2-fda-argos-index.html">Part 4 - Build FDA-ARGOS index</a> (this post)</p>
<p>Part 5 - Regular vs Fast Builds (upcoming)</p>
<p>Part 6 - Benchmarking (upcoming)</p>
<h4>Introduction</h4>
<p>Kraken2<sup id="fnref:Kraken2"><a class="footnote-ref" href="../2024/07/mastering-kraken2-initial-runs.html#fn:Kraken2">1</a></sup> is widely used for metagenomics taxonomic classification, and it has pre-built indexes for many organisms. In this series, we will learn</p>
<ul>
<li>How to set up kraken2, download pre-built indices</li>
<li>Run kraken2 (8GB RAM) at ~0.19 Mbp/m (million base pairs per minute)</li>
<li>Learn various ways to speed up the classification process</li>
<li>Run kraken2 (128GB RAM) at ~1200 Mbp/m</li>
<li>Build custom indices</li>
</ul>
<h4>Installation</h4>
<p>We can install kraken2 from source using the <code>install_kraken2.sh</code> script as per the manual<sup id="fnref:install_kraken2"><a class="footnote-ref" href="../2024/07/mastering-kraken2-initial-runs.html#fn:install_kraken2">2</a></sup>.</p>
<pre class="code literal-block">$ git clone https://github.com/DerrickWood/kraken2
$ <span class="nb">cd</span> kraken2
$ ./install_kraken2.sh /usr/local/bin
<span class="c1"># ensure kraken2 is in the PATH</span>
$ <span class="nb">export</span> <span class="nv">PATH</span><span class="o">=</span><span class="nv">$PATH</span>:/usr/local/bin
</pre>
<p>If you already have conda installed, you can install kraken2 from conda as well.</p>
<pre class="code literal-block">$ conda install -c bioconda kraken2
</pre>
<p>If you have <code>brew</code> installed on Linux or Mac(including M1), you can install kraken2 using <code>brew</code>.</p>
<pre class="code literal-block">$ brew install brewsci/bio/kraken2
</pre>
<h4>Download pre-built indices</h4>
<p>Building kraken2 indices take a lot of time and resources. For now, let's download and use the pre-built indices. In the final post, we will learn how to build the indices.</p>
<p>Genomic Index Zone<sup id="fnref:GenomicIndexZone"><a class="footnote-ref" href="../2024/07/mastering-kraken2-initial-runs.html#fn:GenomicIndexZone">3</a></sup> provides pre-built indices for kraken2. Let's download the standard database. It contains Refeq archaea, bacteria, viral, plasmid, human1, &amp; UniVec_Core. </p>
<pre class="code literal-block">$ wget https://genome-idx.s3.amazonaws.com/kraken/k2_standard_20240605.tar.gz
$ mkdir k2_standard
$ tar -xvf k2_standard_20240605.tar.gz -C k2_standard
</pre>
<p>The extracted directory contains three files - <code>hash.k2d</code>, <code>opts.k2d</code>, <code>taxo.k2d</code> which are the kraken2 database files.</p>
<pre class="code literal-block">$ ls -l *.k2d
.rw-r--r--  83G anand <span class="m">13</span> Jul <span class="m">12</span>:34 hash.k2d
.rw-r--r--   <span class="m">64</span> anand <span class="m">13</span> Jul <span class="m">12</span>:34 opts.k2d
.rw-r--r-- <span class="m">4</span>.0M anand <span class="m">13</span> Jul <span class="m">12</span>:34 taxo.k2d
</pre>
<h4>Classification</h4>
<p>To run the taxonomic classification, let's use <code>ERR10359977</code> human gut meta genome from NCBI SRA.</p>
<pre class="code literal-block">$ wget https://ftp.sra.ebi.ac.uk/vol1/fastq/ERR103/077/ERR10359977/ERR10359977.fastq.gz
$ kraken2 --db k2_standard --report report.txt ERR10359977.fastq.gz &gt; output.txt
</pre>
<p>By default, the machine I have used has 8GB RAM and an additioinal 8GB swap. Since kraken2 needs entire db(~80GB) in memory, when the process tries to consume more than 16GB memory, the kernel will kill the process. </p>
<pre class="code literal-block">$ <span class="nb">time</span> kraken2 --db k2_standard --paired SRR6915097_1.fastq.gz SRR6915097_2.fastq.gz &gt; output.txt
Loading database information...Command terminated by signal <span class="m">9</span>
<span class="m">0</span>.02user <span class="m">275</span>.83system <span class="m">8</span>:17.43elapsed <span class="m">55</span>%CPU 
</pre>
<p>To prevent this, let's increase the swap space to 128 GB.</p>
<pre class="code literal-block"><span class="c1"># Create an empty swapfile of 128GB</span>
sudo dd <span class="k">if</span><span class="o">=</span>/dev/zero <span class="nv">of</span><span class="o">=</span>/swapfile <span class="nv">bs</span><span class="o">=</span>1G <span class="nv">count</span><span class="o">=</span><span class="m">128</span>

<span class="c1"># Turn swap off - It might take several minutes</span>
sudo swapoff -a

<span class="c1"># Set the permissions for swapfile</span>
sudo chmod <span class="m">0600</span> /swapfile

<span class="c1"># make it a swap area</span>
sudo mkswap /swapfile  

<span class="c1"># Turn the swap on</span>
sudo swapon /swapfile
</pre>
<p>We can time the classification process using the <code>time</code> command.</p>
<pre class="code literal-block">$ <span class="nb">time</span> kraken2 --db k2_standard --report report.txt ERR10359977.fastq.gz &gt; output.txt
</pre>
<p>If you have a machine with large RAM, the same scenario can be simulated using <code>systemd-run</code>. This will limit the memory usage of kraken2 to 6.5GB. </p>
<pre class="code literal-block">$ <span class="nb">time</span> systemd-run --scope -p <span class="nv">MemoryMax</span><span class="o">=</span><span class="m">6</span>.5G --user <span class="nb">time</span> kraken2 --db k2_standard --report report.txt ERR10359977.fastq.gz &gt; output.txt
</pre>
<p>Depending on the CPU performance, this will take around ~40 minutes to complete.</p>
<pre class="code literal-block">Loading database information... <span class="k">done</span>.
<span class="m">95064</span> sequences <span class="o">(</span><span class="m">14</span>.35 Mbp<span class="o">)</span> processed <span class="k">in</span> <span class="m">1026</span>.994s <span class="o">(</span><span class="m">5</span>.6 Kseq/m, <span class="m">0</span>.84 Mbp/m<span class="o">)</span>.
  <span class="m">94939</span> sequences classified <span class="o">(</span><span class="m">99</span>.87%<span class="o">)</span>
  <span class="m">125</span> sequences unclassified <span class="o">(</span><span class="m">0</span>.13%<span class="o">)</span>
  <span class="m">4</span>.24user <span class="m">658</span>.68system <span class="m">38</span>:26.78elapsed <span class="m">28</span>%CPU 
</pre>
<p>If we try gut WGS(Whole Genome Sequence) sample like <code>SRR6915097</code> <sup id="fnref:srr1"><a class="footnote-ref" href="../2024/07/mastering-kraken2-initial-runs.html#fn:srr1">4</a></sup><sup id="fnref:srr2"><a class="footnote-ref" href="../2024/07/mastering-kraken2-initial-runs.html#fn:srr2">5</a></sup>. which contains ~3.3 Gbp, it will take weeks to complete.</p>
<pre class="code literal-block">$ wget -c https://ftp.sra.ebi.ac.uk/vol1/fastq/SRR691/007/SRR6915097/SRR6915097_1.fastq.gz
$ wget -c https://ftp.sra.ebi.ac.uk/vol1/fastq/SRR691/007/SRR6915097/SRR6915097_2.fastq.gz

$ <span class="nb">time</span> systemd-run --scope -p <span class="nv">MemoryMax</span><span class="o">=</span>6G --user <span class="nb">time</span> kraken2 --db k2_standard --paired SRR6915097_1.fastq.gz SRR6915097_2.fastq.gz &gt; output.txt
</pre>
<p>I tried running this on 8 GB machine. Even after 10 days, it processed only 10% of the data.</p>
<p>If we have to process a large number of such samples, it takes months and this is not a practical solution. </p>
<h4>Conclusion</h4>
<p>In this post, we ran kraken2 on an 8GB machine and learned that it is not feasible to run kraken2 on large samples.</p>
<p>In the next post, we will learn how to speed up the classification process and run classification at 1200 Mbp/m.</p>
<p><strong>Next</strong>: <a href="../2024/07/mastering-kraken2-performance-optimisation.html">Part 2 - Performance Optimisation</a></p>
<div class="footnote">
<hr>
<ol>
<li id="fn:Kraken2">
<p><a href="https://ccb.jhu.edu/software/kraken2/">Kraken2</a> <a class="footnote-backref" href="../2024/07/mastering-kraken2-initial-runs.html#fnref:Kraken2" title="Jump back to footnote 1 in the text">↩</a></p>
</li>
<li id="fn:install_kraken2">
<p><a href="https://github.com/DerrickWood/kraken2/blob/master/docs/MANUAL.markdown#installation">Kraken2 - Manual - Install</a> <a class="footnote-backref" href="../2024/07/mastering-kraken2-initial-runs.html#fnref:install_kraken2" title="Jump back to footnote 2 in the text">↩</a></p>
</li>
<li id="fn:GenomicIndexZone">
<p><a href="https://benlangmead.github.io/aws-indexes/k2">Genomic Index Zone - k2</a> <a class="footnote-backref" href="../2024/07/mastering-kraken2-initial-runs.html#fnref:GenomicIndexZone" title="Jump back to footnote 3 in the text">↩</a></p>
</li>
<li id="fn:srr1">
<p><a href="https://ftp.sra.ebi.ac.uk/vol1/fastq/SRR691/007/SRR6915097/SRR6915097_1.fastq.gz">SRR6915097_1.fastq.gz</a> <a class="footnote-backref" href="../2024/07/mastering-kraken2-initial-runs.html#fnref:srr1" title="Jump back to footnote 4 in the text">↩</a></p>
</li>
<li id="fn:srr2">
<p><a href="https://ftp.sra.ebi.ac.uk/vol1/fastq/SRR691/007/SRR6915097/SRR6915097_2.fastq.gz">SRR6915097_1.fastq.gz</a> <a class="footnote-backref" href="../2024/07/mastering-kraken2-initial-runs.html#fnref:srr2" title="Jump back to footnote 5 in the text">↩</a></p>
</li>
</ol>
</div>
    </div>
    </article>
</div>
        <ul class="pager postindexpager clearfix">
<li class="next"><a href="index-20.html" rel="next">Older posts</a></li>
        </ul>
<!--End of body content--><footer id="footer"><div class="full-article-footer">
    <div class="article-footer">

        <div class="avatar-module">
            <img class="avatar" height="100px" src="../images/chillaranand.jpg">
</div>

        <p class="avatar-module">
            <b>Chillar Anand</b>
            <br>
            Improving Health &amp; Wealth with Technology
            <br></p>

    </div>
</div>

<div class="container align-items-center justify-content-center d-flex">

<footer class="footer"><a href="https://github.com/ChillarAnand">
<img src="../images/icons8-github.svg" alt="github-chillar-anand" height="34"></a>

  

<a href="https://stackoverflow.com/users/2698552/chillar-anand">
<img src="../images/icons8-so.svg" alt="github-chillar-anand" height="30"></a>

  

<a href="https://youtube.com/@avilpage">
<img src="../images/icons8-youtube.svg" alt="github-chillar-anand" height="34"></a>

  

<a href="https://linkedin.com/in/chillaranand">
<img src="../images/icons8-linkedin.svg" alt="github-chillar-anand" height="34"></a>

  

<a href="https://twitter.com/chillaranand">
<img src="../images/icons8-twitter.svg" alt="github-chillar-anand" height="34"></a>

</footer>
</div>

<br><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8127755709093749" crossorigin="anonymous"></script></footer>
</div>
    </div>
    </div>

                <script src="../assets/js/jquery.min.js"></script><script src="../assets/js/popper.min.js"></script><script src="../assets/js/bootstrap.min.js"></script><script src="../assets/js/baguetteBox.min.js"></script><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
    </script>
</body>
</html>
