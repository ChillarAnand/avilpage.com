<!DOCTYPE html>
<html prefix="
og: http://ogp.me/ns# article: http://ogp.me/ns/article#
" lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="Avil Page - Personal &amp; tech blog by Chillar Anand">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Avil Page</title>
<link href="../assets/css/bootstrap.min.css" rel="stylesheet" type="text/css">
<link href="../assets/css/baguetteBox.min.css" rel="stylesheet" type="text/css">
<link href="../assets/css/rst.css" rel="stylesheet" type="text/css">
<link href="../assets/css/code.css" rel="stylesheet" type="text/css">
<link href="../assets/css/theme.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" hreflang="en" href="../rss.xml">
<link rel="canonical" href="https://avilpage.com/blog/">
<link rel="next" href="index-17.html" type="text/html">
<!--[if lt IE 9]><script src="../assets/js/html5.js"></script><![endif]--><style>

 h1 {
     font-weight: bold;
     font-size: 25px;
 }

</style>
</head>
<body>
    <a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

    <!-- Menubar -->
    <nav class="navbar navbar-expand-md static-top mb-4
                navbar-dark
                bg-dark
                "><div class="container">
<!-- This keeps the margins nice -->
            <a class="navbar-brand" href="../">

                    <span id="blog-title">Avil Page</span>
            </a>
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>

            <div class="collapse navbar-collapse" id="bs-navbar">
                <ul class="navbar-nav mr-auto">
<li class="nav-item">
<a href="../top-10.html" class="nav-link">Top 10</a>
                </li>
<li class="nav-item">
<a href="../archive.html" class="nav-link">Articles</a>
                </li>
<li class="nav-item">
<a href="../rss.xml" class="nav-link">RSS</a>

                    
                </li>
</ul>
<ul class="navbar-nav navbar-right"></ul>
</div>
<!-- /.navbar-collapse -->
        </div>
<!-- /.container -->
    </nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="row justify-content-md-center">
        <div class="body-content col col-lg-6">
            <!--Body content-->
            
    
    
<div class="postindex">
    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../2023/03/custom-action-mac-finder.html" class="u-url">Automator Quick Action for KDiff3 in Finder</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Chillar Anand
            </span></p>
            <p class="dateline">
            <a href="../2023/03/custom-action-mac-finder.html" rel="bookmark">
            <time class="published dt-published" datetime="2023-03-10T08:24:11+05:30" itemprop="datePublished" title="2023-03-10">2023-03-10</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <h4>The need for quick action</h4>
<p>kdiff3<sup id="fnref:kdiff3"><a class="footnote-ref" href="../2023/03/custom-action-mac-finder.html#fn:kdiff3">1</a></sup> is a diff &amp; merge tool that compares multiple files/directories and shows the difference line by line and character by character as shown below.</p>
<p><img src="../images/mac-finder-kdiff3.png" alt="mac-finder-kdiff3"></p>
<p>In Windows, when we select multiple files/directories and right click on them, it will show the option to compare selected items with kdiff3.</p>
<p><img src="../images/mac-finder-kdiff3-windows.png" alt="mac-finder-kdiff3-windows"></p>
<p>However, in Macbook, it doesn't show this option. In this tutorial, let us see how we can create the same quick action in the right-click menu when we right-click on the files/directories.</p>
<h4>Creating Quick Action</h4>
<p>Let us open Automator<sup id="fnref:automator"><a class="footnote-ref" href="../2023/03/custom-action-mac-finder.html#fn:automator">2</a></sup>, create new file and select Quick Action.</p>
<p><img src="../images/mac-finder-quick-action.png" alt="mac-finder-automator"></p>
<p>On the left side select <code>Utilities</code> and then select <code>Run Shell Script</code>. </p>
<p>For Workflow receives current, select <code>files or folders</code> and then select <code>in Finder</code>. </p>
<p><img src="../images/mac-finder-quick-action2.png" alt="mac-finder-quick-action"></p>
<p>Then select pass input <code>as agruments</code> and in the script section let us add the following command.</p>
<pre class="code literal-block">/path/to/kdiff3 <span class="nv">$1</span> <span class="nv">$2</span>
</pre>
<p>After adding the command, save this Quick Action. </p>
<p>Now if we relaunch Finder app and then select multiple directories, and right click we can see <code>Compare with KDiff3</code> in quick actions.</p>
<p><img src="../images/mac-finder-kdiff3-quick-action.png" alt="mac-finder-kdiff3"></p>
<h4>Conclusion</h4>
<p>Even though we can use the command line to compare the files/directories, it is always good to have a quick action in the right-click menu. </p>
<div class="footnote">
<hr>
<ol>
<li id="fn:kdiff3">
<p><a href="https://kdiff3.sourceforge.io">https://kdiff3.sourceforge.io</a> <a class="footnote-backref" href="../2023/03/custom-action-mac-finder.html#fnref:kdiff3" title="Jump back to footnote 1 in the text">↩</a></p>
</li>
<li id="fn:automator">
<p><a href="https://en.wikipedia.org/wiki/Automator_(macOS)">https://en.wikipedia.org/wiki/Automator_(macOS)</a> <a class="footnote-backref" href="../2023/03/custom-action-mac-finder.html#fnref:automator" title="Jump back to footnote 2 in the text">↩</a></p>
</li>
</ol>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../2023/03/setup-k8s-anywhere-k3d.html" class="u-url">Setup Kubernetes Anywhere with Single Command</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Chillar Anand
            </span></p>
            <p class="dateline">
            <a href="../2023/03/setup-k8s-anywhere-k3d.html" rel="bookmark">
            <time class="published dt-published" datetime="2023-03-04T02:55:27+05:30" itemprop="datePublished" title="2023-03-04">2023-03-04</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <div class="embed-responsive embed-responsive-16by9">
<iframe class="embed-responsive-item" src="https://www.youtube.com/embed/Vo0mAsXe-hI" allowfullscreen>
</iframe>
</div>

<p><br></p>
<h4>Introduction</h4>
<p>In an earlier article, we have seen how to set up <a href="../2022/10/local-kubernetes-with-k3s-on-mac.html">Kubernetes on M1 Mac</a>. That involved spinning up a VM and installing Kubernetes<sup id="fnref:kubernetes"><a class="footnote-ref" href="../2023/03/setup-k8s-anywhere-k3d.html#fn:kubernetes">1</a></sup> on it. In this article, we will see how to set up Kubernetes directly on Docker so that we can use the same set-up on any operating system.</p>
<h4>Prerequisites</h4>
<p>Ensure you have Docker installed on your system. If you are on a Mac or Windows, you can install Docker Desktop<sup id="fnref:docker-desktop"><a class="footnote-ref" href="../2023/03/setup-k8s-anywhere-k3d.html#fn:docker-desktop">2</a></sup>.</p>
<h4>k3s/k3d</h4>
<p>k3s<sup id="fnref:k3s"><a class="footnote-ref" href="../2023/03/setup-k8s-anywhere-k3d.html#fn:k3s">3</a></sup> is a lightweight Kubernetes distribution by Rancher. It is a single binary that can be run on any Linux machine. But it doesn't work on Mac or Windows.</p>
<p>k3d<sup id="fnref:k3d"><a class="footnote-ref" href="../2023/03/setup-k8s-anywhere-k3d.html#fn:k3d">4</a></sup> is a wrapper around k3s that allows you to run k3s on Docker. It is a great option for running Kubernetes on your local machine.</p>
<h4>Installation</h4>
<p>k3d can be installed using the following command:</p>
<pre class="code literal-block">$ brew install k3d  <span class="c1"># mac</span>
$ chocolatey install k3d  <span class="c1"># windows</span>
$ curl -s https://raw.githubusercontent.com/k3d-io/k3d/main/install.sh <span class="p">|</span> bash <span class="c1"># linux</span>
</pre>
<p>Once it is installed, we can create a cluster using the following command:</p>
<pre class="code literal-block">$ k3d cluster create demo
</pre>
<p>This will launch a cluster with a single node. We can also setup a multi-node cluster using the following command:</p>
<pre class="code literal-block">$ k3d cluster create demo --servers <span class="m">3</span> --agents <span class="m">2</span>
</pre>
<p>We can verify the cluster is up and running using the following command:</p>
<pre class="code literal-block">$ kubectl get nodes
</pre>
<p>We can also use GUI tools like Lens to manage and navigate the cluster. In the above video we have used Lens to create a Jenkins deployment as well.</p>
<h4>Conclusion</h4>
<p>In this article, we have seen how to set up Kubernetes on Docker. This is a great option for running Kubernetes on your local machine. We can also use this to run production setup for small applications.</p>
<div class="footnote">
<hr>
<ol>
<li id="fn:kubernetes">
<p><a href="https://kubernetes.io/">https://kubernetes.io/</a> <a class="footnote-backref" href="../2023/03/setup-k8s-anywhere-k3d.html#fnref:kubernetes" title="Jump back to footnote 1 in the text">↩</a></p>
</li>
<li id="fn:docker-desktop">
<p><a href="https://www.docker.com/products/docker-desktop/">https://www.docker.com/products/docker-desktop/</a> <a class="footnote-backref" href="../2023/03/setup-k8s-anywhere-k3d.html#fnref:docker-desktop" title="Jump back to footnote 2 in the text">↩</a></p>
</li>
<li id="fn:k3s">
<p><a href="https://k3s.io/">https://k3s.io/</a> <a class="footnote-backref" href="../2023/03/setup-k8s-anywhere-k3d.html#fnref:k3s" title="Jump back to footnote 3 in the text">↩</a></p>
</li>
<li id="fn:k3d">
<p><a href="https://k3d.io/">https://k3d.io/</a> <a class="footnote-backref" href="../2023/03/setup-k8s-anywhere-k3d.html#fnref:k3d" title="Jump back to footnote 4 in the text">↩</a></p>
</li>
</ol>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../2023/02/using-conda-mamba-instead-of-pip-on-m1-mac.html" class="u-url">Using Conda/Mamba with Python Pip on M1 Mac</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Chillar Anand
            </span></p>
            <p class="dateline">
            <a href="../2023/02/using-conda-mamba-instead-of-pip-on-m1-mac.html" rel="bookmark">
            <time class="published dt-published" datetime="2023-02-28T01:01:01+05:30" itemprop="datePublished" title="2023-02-28">2023-02-28</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <h4>Introduction</h4>
<p>From 2020, all Apple MacBooks are powered by Apple Silicone(M1) chips. This chip uses Aarch64 architecture which is different from x86 architecture which was used by Intel chips earlier.</p>
<p>Python is a cross-platform language. It can run on any platform. However, Python packages are compiled for specific platforms. For example, a package compiled for x86 will not work on  Aarch64 platform. Also, many Python packages are not yet available for ARM64/Aarch64 platform.</p>
<h4>M1 Mac and Python</h4>
<p>If we want to run a python package on M1 Mac which doesn't have ARM64 support, we need to use an emulator(or a cross-architecture Docker image). This will significantly slow down the application.</p>
<p>An alternate solution is to build packages for ARM64 platform. Building binary packages from the source code requires a lot of time and effort. Also, we need to build the package for each Python version.</p>
<p>Instead of building from source, we can use Conda/Mamba to install Python packages as well as other system packages. Conda/Mamba will automatically install the correct binary for the package.</p>
<p>For example, python-confluent-kafka<sup id="fnref:confluent-kafka"><a class="footnote-ref" href="../2023/02/using-conda-mamba-instead-of-pip-on-m1-mac.html#fn:confluent-kafka">3</a></sup> package doesn't have Linux aarch64 support. To run it on aarch64 platform, we have to build from source which takes a lot of time. Instead, we can simply install it using Conda/Mamba with a single command.</p>
<pre class="code literal-block">$ conda install -c conda-forge python-confluent-kafka
</pre>
<p>Similar to pip, Conda can also install all the packages mentioned in a file like <code>requirements.txt</code>.</p>
<pre class="code literal-block">$ conda install --file requirements.txt
</pre>
<h4>Conclusion</h4>
<p>In data science ecosystem, Conda<sup id="fnref:conda"><a class="footnote-ref" href="../2023/02/using-conda-mamba-instead-of-pip-on-m1-mac.html#fn:conda">1</a></sup>/Mamba<sup id="fnref:mamba"><a class="footnote-ref" href="../2023/02/using-conda-mamba-instead-of-pip-on-m1-mac.html#fn:mamba">2</a></sup> are widely used as package managers. In web development ecosystem, they are not as widely used as pip.</p>
<p>Conda/Mamba is a great cross-platform system package manager, and it doesn't have all the Python packages available on PyPi. However, we can use it along with pip for easy package management on M1 Macbook.</p>
<div class="footnote">
<hr>
<ol>
<li id="fn:conda">
<p><a href="https://en.wikipedia.org/wiki/Conda_(package_manager)">https://en.wikipedia.org/wiki/Conda_(package_manager)</a> <a class="footnote-backref" href="../2023/02/using-conda-mamba-instead-of-pip-on-m1-mac.html#fnref:conda" title="Jump back to footnote 1 in the text">↩</a></p>
</li>
<li id="fn:mamba">
<p><a href="https://github.com/mamba-org/mamba">https://github.com/mamba-org/mamba</a> <a class="footnote-backref" href="../2023/02/using-conda-mamba-instead-of-pip-on-m1-mac.html#fnref:mamba" title="Jump back to footnote 2 in the text">↩</a></p>
</li>
<li id="fn:confluent-kafka">
<p><a href="https://pypi.org/project/confluent-kafka/">https://pypi.org/project/confluent-kafka/</a> <a class="footnote-backref" href="../2023/02/using-conda-mamba-instead-of-pip-on-m1-mac.html#fnref:confluent-kafka" title="Jump back to footnote 3 in the text">↩</a></p>
</li>
</ol>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../2023/02/stateful-hot-module-reload-in-python.html" class="u-url">Hot Module Reload In Python With Reloadium</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Chillar Anand
            </span></p>
            <p class="dateline">
            <a href="../2023/02/stateful-hot-module-reload-in-python.html" rel="bookmark">
            <time class="published dt-published" datetime="2023-02-16T11:58:58+05:30" itemprop="datePublished" title="2023-02-16">2023-02-16</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <h4>Introduction</h4>
<p>Hot module reloading is a feature that allows you to reload a module without restarting the whole application. This is very useful when we are developing/debugging an application, and we want to see the changes instantaneously.</p>
<h4>Reloadium</h4>
<p>Reloadium<sup id="fnref:reloadium"><a class="footnote-ref" href="../2023/02/stateful-hot-module-reload-in-python.html#fn:reloadium">1</a></sup> is an advanced hot reloading library for python.</p>
<p>Instead of writing an article, I thought it would be much easier to show a live demo of Reloadium. In the below video, we can see how reloadium greatly improves developer experience.</p>
<div class="embed-responsive embed-responsive-16by9">
<iframe class="embed-responsive-item" src="https://www.youtube.com/embed/9UO1raFQdo8" allowfullscreen>
</iframe>
</div>
<p><br></p>
<p>Currently, reloadium can be used as a standalone tool. We can install it from PyPi and run any arbitrary python script with reloadium.</p>
<pre class="code literal-block"><span class="o">$</span> <span class="n">pip</span> <span class="n">install</span> <span class="n">reloadium</span>
<span class="o">$</span> <span class="n">reloadium</span> <span class="n">run</span> <span class="n">myscript</span><span class="o">.</span><span class="n">py</span>
</pre>
<p>Alternatively, it is available as a plugin for PyCharm as shown in the above video. VS Code support is also in the works.</p>
<p>Reloadium is capable of profiling too. Without writing a single line of code, we can profile Python code. But that's a topic for another article.</p>
<h4>Conclusion</h4>
<p>I have been using Reloadium from a few months, and it has become an essential part of my development workflow. These days I always run all the scripts or apps in debug mode with reloadium directly. </p>
<div class="footnote">
<hr>
<ol>
<li id="fn:reloadium">
<p><a href="https://github.com/reloadware/reloadium">https://github.com/reloadware/reloadium</a> <a class="footnote-backref" href="../2023/02/stateful-hot-module-reload-in-python.html#fnref:reloadium" title="Jump back to footnote 1 in the text">↩</a></p>
</li>
</ol>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../2023/01/top-pay-after-placement-courses-in-india.html" class="u-url">Best Pay After Placement Courses In India</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Chillar Anand
            </span></p>
            <p class="dateline">
            <a href="../2023/01/top-pay-after-placement-courses-in-india.html" rel="bookmark">
            <time class="published dt-published" datetime="2023-01-23T18:01:14+05:30" itemprop="datePublished" title="2023-01-23">2023-01-23</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <h4>Introduction</h4>
<p>In India, huge number of students are graduating every year. Most of them are not able to get a job right after graduation. In order to get a job in IT industry, students need to have some technical skills.</p>
<p>There are thousands of institutes in India that are providing paid technical courses. Depending on the course, the fees can be anywhere between 5,000 to 5 lakhs. The percentage of students who are getting a job after doing these courses is extremely low. In addition to that quite a few students are not able to afford fees to join these courses.</p>
<h4>Pay After Placement Courses</h4>
<p>To combat this problem, some institutes are providing pay after placement(PAP) courses. In these courses, students will pay the fees only after getting a job with a desired package. This is a win-win situation for both the students and the institutes. This is a far better option than paying the fees upfront and not getting a job. These courses are also called as income share agreement(ISA) courses.</p>
<p>Here is a list of top pay after placement courses in India for front end developers, back end developers, full stack developers, data scientists, machine learning engineers, and data engineers.</p>
<table>
<thead><tr>
<th align="left">Site-Rank</th>
<th align="left">Institute</th>
<th align="left">Fee(Approx INR)</th>
</tr></thead>
<tbody>
<tr>
<td align="left">134,988</td>
<td align="left"><a href="https://www.sharpener.tech/">Sharpener Tech</a></td>
<td align="left">68,000</td>
</tr>
<tr>
<td align="left">59,928</td>
<td align="left"><a href="https://acciojob.com/">AccioJob</a></td>
<td align="left">177,000</td>
</tr>
<tr>
<td align="left">321,989</td>
<td align="left"><a href="https://placewit.com/">Placewit</a></td>
<td align="left">0 (Upto 10L)</td>
</tr>
<tr>
<td align="left">37,294</td>
<td align="left"><a href="https://www.masaischool.com/">Masai School</a></td>
<td align="left">350,000</td>
</tr>
<tr>
<td align="left">1,482,058</td>
<td align="left"><a href="https://digikull.com/">Digikul</a></td>
<td align="left">234,000</td>
</tr>
<tr>
<td align="left">1,554,412</td>
<td align="left"><a href="https://www.the10xacademy.com/">10xAcademy</a></td>
<td align="left">295,000</td>
</tr>
<tr>
<td align="left">295,708</td>
<td align="left"><a href="https://www.functionup.org/">Function Up</a></td>
<td align="left">295,000</td>
</tr>
<tr>
<td align="left">84,513</td>
<td align="left"><a href="https://www.almabetter.com/">AlmaBetter</a></td>
<td align="left">Not known</td>
</tr>
</tbody>
</table>
<p><br></p>
<h4>Conclusion</h4>
<p>Most of these courses have an entrance test that candidates have to clear before joining the course. However taking these courses is far better than paying the fees upfront and not getting a job. If you are interested in any of these courses, you can apply for the entrance test and join the course.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../2023/01/pipe-tail-output-into-column.html" class="u-url">Pipe tail output into column</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Chillar Anand
            </span></p>
            <p class="dateline">
            <a href="../2023/01/pipe-tail-output-into-column.html" rel="bookmark">
            <time class="published dt-published" datetime="2023-01-02T06:26:28+05:30" itemprop="datePublished" title="2023-01-02">2023-01-02</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p><code>column</code> command-line utility formats its input into multiple columns and aligns it nicely. It is useful for formatting output of csv files, or other commands. </p>
<pre class="code literal-block">$ cat users.csv
id,user,active
<span class="m">1</span>,John Doe,true
<span class="m">2</span>,Will Smith,false

$ column -s, -t &lt; users.csv
id  user        active
<span class="m">1</span>   John Doe    <span class="nb">true</span>
<span class="m">2</span>   Will Smith  <span class="nb">false</span>
</pre>
<p><code>tail</code> command-line utility prints the last 10 lines of a file. It can be used with <code>-f</code> option to follow the file as it grows.</p>
<pre class="code literal-block">$ tail -f users.csv
id,user,active
<span class="m">1</span>,John Doe,true
<span class="m">2</span>,Will Smith,false
</pre>
<p>To format the output of <code>tail -f</code> command, we can't use <code>column</code> command directly. <code>column</code> command can't produce output until it receives all the input. It needs all the input beforehand to calculate the column widths. </p>
<pre class="code literal-block">$ tail -f users.csv <span class="p">|</span> column -s, -t
</pre>
<p>So, the above command won't work. </p>
<p>As the goal is to follow the output of the file, we can use <code>watch</code> command for this. <code>watch</code> command executes a command periodically, and displays its output. </p>
<pre class="code literal-block">$ watch -n <span class="m">1</span> <span class="s2">"tail -n 20 users.csv | column -s, -t"</span>
</pre>
<p>This command will fetch the last 20 lines of the file, pipe it to column command, and display the output. It will repeat the command every 1 second.</p>
<p>As the file grows beyond 20 lines, the headers will be truncated. To preserve the headers, we can use <code>head</code> command in addition to <code>tail</code> command.</p>
<pre class="code literal-block">$ watch -n <span class="m">1</span> <span class="s2">"(head -n1 &amp;&amp; tail -n20) &lt; users.csv| column -s, -t"</span>
</pre>
<p>This command will print the first line of the file, and then the last 20 lines of the file. The output will be piped to <code>column</code> command, and displayed.</p>
<p>Here is a screenshot of the output of a demo csv.</p>
<p><img alt="pipe tail output to column" src="../images/pipe-tail-output-into-column.png"></p>
<p>This makes it easy to watch the output of a file as it grows.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../2022/12/change-kafka-log-dir-format.html" class="u-url">Change Kafka Log Directory &amp; Format It</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Chillar Anand
            </span></p>
            <p class="dateline">
            <a href="../2022/12/change-kafka-log-dir-format.html" rel="bookmark">
            <time class="published dt-published" datetime="2022-12-24T12:19:41+05:30" itemprop="datePublished" title="2022-12-24">2022-12-24</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <h4>Problem Statement</h4>
<p>On my local Mac, I was using Kafka to pass messages between various applications. Due to some reason, when I tried to start Kafka recently, it was failing to start and here are the relevant error logs.</p>
<pre class="code literal-block"><span class="o">[</span><span class="m">2022</span>-12-23 <span class="m">11</span>:57:06,217<span class="o">]</span> WARN <span class="o">[</span>Controller <span class="m">1</span><span class="o">]</span> writeNoOpRecord: failed with unknown server exception RuntimeException at epoch <span class="m">139</span> <span class="k">in</span> <span class="m">5198</span> us.  Renouncing leadership and reverting to the last committed offset <span class="m">927938</span>. <span class="o">(</span>org.apache.kafka.controller.QuorumController<span class="o">)</span>

<span class="o">[</span><span class="m">2022</span>-12-23 <span class="m">11</span>:57:06,536<span class="o">]</span> ERROR <span class="o">[</span>Controller <span class="m">1</span><span class="o">]</span> registerBroker: unable to start processing because of NotControllerException. <span class="o">(</span>org.apache.kafka.controller.QuorumController<span class="o">)</span>

<span class="o">[</span><span class="m">2022</span>-12-23 <span class="m">12</span>:23:35,834<span class="o">]</span> ERROR <span class="o">[</span>RaftManager <span class="nv">nodeId</span><span class="o">=</span><span class="m">1</span><span class="o">]</span> Had an error during log cleaning <span class="o">(</span>org.apache.kafka.raft.KafkaRaftClient<span class="o">)</span>
org.apache.kafka.common.errors.OffsetOutOfRangeException: Cannot increment the log start offset to <span class="m">927939</span> of partition __cluster_metadata-0 since it is larger than the high watermark <span class="m">926507</span>
<span class="o">[</span><span class="m">2022</span>-12-23 <span class="m">12</span>:23:36,035<span class="o">]</span> WARN <span class="o">[</span>Controller <span class="m">1</span><span class="o">]</span> writeNoOpRecord: failed with unknown server exception RuntimeException at epoch <span class="m">294</span> <span class="k">in</span> <span class="m">137</span> us.  Renouncing leadership and reverting to the last committed offset <span class="m">927938</span>. <span class="o">(</span>org.apache.kafka.controller.QuorumController<span class="o">)</span>
java.lang.RuntimeException: Cant create a new <span class="k">in</span>-memory snapshot at epoch <span class="m">926507</span> because there is already a snapshot with epoch <span class="m">927938</span>

<span class="o">[</span><span class="m">2022</span>-12-23 <span class="m">12</span>:23:36,252<span class="o">]</span> ERROR Exiting Kafka due to fatal exception during startup. <span class="o">(</span>kafka.Kafka$<span class="o">)</span>
</pre>
<h4>Debugging</h4>
<p>I tried to figure out the exact root cause. After multiple failed attempts, I decided to change the log directory temporarily and go ahead for now.</p>
<h4>Solution</h4>
<p>I create a new temporary directory and set the log directory to that.</p>
<pre class="code literal-block">$ mkdir /tmp/kafka-logs

<span class="c1"># inside server.properties</span>
log.dirs<span class="o">=</span>/tmp/kafka-logs
</pre>
<p>When I started the Kafka server, it failed.</p>
<pre class="code literal-block">$ kafka-server-start server.properties

<span class="o">[</span><span class="m">2022</span>-12-23 <span class="m">12</span>:30:50,018<span class="o">]</span> ERROR Exiting Kafka due to fatal exception <span class="o">(</span>kafka.Kafka$<span class="o">)</span>
org.apache.kafka.common.KafkaException: No <span class="sb">`</span>meta.properties<span class="sb">`</span> found <span class="k">in</span> /tmp/ <span class="o">(</span>have you run <span class="sb">`</span>kafka-storage.sh<span class="sb">`</span> to format the directory?<span class="o">)</span>
</pre>
<p>I ran the <code>kafka-storage</code> script to format the directory. First, we need to get the cluster-id. Since we already know the old kafa-logs directory, we can get the cluster-id from there.</p>
<pre class="code literal-block">$ cat ~/homebrew/var/lib/kraft-combined-logs/meta.properties 
<span class="c1">#</span>
<span class="c1">#Thu Oct 20 11:48:12 IST 2022</span>
cluster.id<span class="o">=</span>5MB5lq-XT-6JzQqJeIuhWQ
node.id<span class="o">=</span><span class="m">1</span>
<span class="nv">version</span><span class="o">=</span><span class="m">1</span>      
</pre>
<p>Now, we can format the new directory.</p>
<pre class="code literal-block">$ kafka-storage format --config server.properties --cluster-id 5MB5lq-XT-6JzQqJeIuhWQ

Formatting /tmp/kafka-logs/ with metadata.version <span class="m">3</span>.3-IV3.
</pre>
<p>After changing log directory, Kafka has started working.</p>
<pre class="code literal-block">$ kafka-start-server /path/to/server.properties
</pre>
<p>Since I have changed log directory all older messages are lost. Since I am doing this on my local machine, it is fine. Need to revisit it to debug further.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../2022/12/hands-on-rabbitmq-tutorial.html" class="u-url">Hands-on RabbitMQ Tutorial</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Chillar Anand
            </span></p>
            <p class="dateline">
            <a href="../2022/12/hands-on-rabbitmq-tutorial.html" rel="bookmark">
            <time class="published dt-published" datetime="2022-12-21T05:12:21+05:30" itemprop="datePublished" title="2022-12-21">2022-12-21</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>A short hands-on guide to get started with RabbitMQ for people who are in a hurry.</p>
<h4>What is RabbitMQ?</h4>
<p><img src="../images/rabbitmq-overview.png" alt="RabbitMQ"></p>
<p style="text-align:center;">Image Credit: CloudAMQP</p>

<p>RabbitMQ<sup id="fnref:wikipedia-rabbitmq"><a class="footnote-ref" href="../2022/12/hands-on-rabbitmq-tutorial.html#fn:wikipedia-rabbitmq">1</a></sup> is an open-source message broker software that implements the Advanced Message Queuing Protocol (AMQP). With RabbitMQ, producer and consumer applications can communicate asynchronously, and they will be completely decoupled. </p>
<h4>RabbitMQ Terminology</h4>
<p><b>Producer</b>: A producer is a client that publishes messages to the RabbitMQ broker. Producers write data to exchanges.</p>
<p><b>Consumer</b>: A consumer is a client that subscribes to queues and processes the messages. Consumers read data from queues.</p>
<p><b>Queue</b>: A queue is a buffer that stores messages. A queue is bound to an exchange and receives messages from it.</p>
<p><b>Exchange</b>: An exchange is a message routing agent that receives messages from producers and routes them to queues.</p>
<p><b>Binding</b>: A binding is a link between an exchange and a queue. It is created with a routing key. The producer sends messages to the exchange with a routing key. The exchange routes the message to the queues that are bound with a matching routing key.</p>
<h4>RabbitMQ Setup</h4>
<p>We can use the official RabbitMQ docker image to run RabbitMQ locally. We can run the following command to start a RabbitMQ container:</p>
<pre class="code literal-block">$ docker run --rm --name<span class="o">=</span>rabbitmq -p <span class="m">15672</span>:15672 -p <span class="m">5672</span>:5672 rabbitmq:3-management
</pre>
<p>This image has rabbitmq management plugin enabled. We can access the management UI at <a href="http://localhost:15672">http://localhost:15672</a>. The default username and password are both <code>guest</code>.</p>
<p>It also has <code>rabbitmqadmin</code> command line tool installed, which can manage RabbitMQ. </p>
<h4>Passing Messages from UI</h4>
<p>We can use the management UI to send and receive messages. We can create a new queue and exchange from the <code>Queues</code> section.</p>
<p><img src="../images/rabbitmq-queue.png" alt="RabbitMQ Queue"></p>
<p>Once a queue is created, we can publish and consume messages from that queue. </p>
<p><img src="../images/rabbitmq-publish.png" alt="RabbitMQ Publish"></p>
<h4>Passing Messages from CLI</h4>
<p>Instead of using web UI, we can use <code>rabbitmqadmin</code> CLI tool<sup id="fnref:rabbitmq-cli"><a class="footnote-ref" href="../2022/12/hands-on-rabbitmq-tutorial.html#fn:rabbitmq-cli">2</a></sup> to send and receive messages. Let's create a topic exchange and a queue. </p>
<pre class="code literal-block">$ docker <span class="nb">exec</span> rabbitmq rabbitmqadmin <span class="nb">declare</span> exchange <span class="nv">type</span><span class="o">=</span>direct <span class="nv">name</span><span class="o">=</span>orders
<span class="c1"># =&gt; exchange declared</span>
</pre>
<pre class="code literal-block">$ docker <span class="nb">exec</span> rabbitmq rabbitmqadmin <span class="nb">declare</span> queue <span class="nv">name</span><span class="o">=</span>orders
<span class="c1"># =&gt; queue declared</span>
</pre>
<p>Let's publish a message to the exchange:</p>
<pre class="code literal-block">$ docker <span class="nb">exec</span> rabbitmq rabbitmqadmin publish <span class="nv">routing_key</span><span class="o">=</span>orders <span class="nv">payload</span><span class="o">=</span><span class="s1">'dummy message'</span>
<span class="c1"># =&gt; Message published</span>
</pre>
<p>To receive messages from the queue, we can use the following command:</p>
<pre class="code literal-block">$ docker <span class="nb">exec</span> rabbitmq rabbitmqadmin get <span class="nv">queue</span><span class="o">=</span>orders
</pre>
<p><img src="../images/rabbitmq-get-message.png" alt="RabbitMQ CLI"></p>
<h4>Passing Messages from REST API</h4>
<p>We can also use REST API to send and receive messages. Let's create a new exchange and queue:</p>
<pre class="code literal-block">$ curl -u guest:guest -X PUT -H <span class="s2">"content-type:application/json"</span> -d <span class="s1">'{"type":"direct"}'</span> http://localhost:15672/api/exchanges/%2f/orders
</pre>
<pre class="code literal-block">$ curl -u guest:guest -X PUT -H <span class="s2">"content-type:application/json"</span> -d <span class="s1">'{"type":"topic", "durable": true}'</span> http://localhost:15672/api/queues/%2f/orders
</pre>
<p>We can publish a message to the exchange:</p>
<pre class="code literal-block">$ curl -u guest:guest -X POST -H <span class="s2">"content-type:application/json"</span> -d <span class="s1">'{"routing_key":"orders","payload":"dummy message","payload_encoding":"string", "properties": {} }'</span> http://localhost:15672/api/exchanges/%2f/orders/publish
</pre>
<p>To receive messages from the queue, we can use the following command:</p>
<pre class="code literal-block">$ curl -u guest:guest -X GET http://localhost:15672/api/queues/%2f/orders/get
</pre>
<h4>Conclusion</h4>
<p>In this post, we have seen how to get started with RabbitMQ. We have seen how to use the management UI, CLI and REST API to send and receive messages.</p>
<div class="footnote">
<hr>
<ol>
<li id="fn:wikipedia-rabbitmq">
<p><a href="https://en.wikipedia.org/wiki/RabbitMQ">https://en.wikipedia.org/wiki/RabbitMQ</a> <a class="footnote-backref" href="../2022/12/hands-on-rabbitmq-tutorial.html#fnref:wikipedia-rabbitmq" title="Jump back to footnote 1 in the text">↩</a></p>
</li>
<li id="fn:rabbitmq-cli">
<p><a href="https://www.rabbitmq.com/management-cli.html">https://www.rabbitmq.com/management-cli.html</a> <a class="footnote-backref" href="../2022/12/hands-on-rabbitmq-tutorial.html#fnref:rabbitmq-cli" title="Jump back to footnote 2 in the text">↩</a></p>
</li>
</ol>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../2022/12/hands-on-apache-kafka-tutorial.html" class="u-url">Hands-on Apache Kafka Tutorial</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Chillar Anand
            </span></p>
            <p class="dateline">
            <a href="../2022/12/hands-on-apache-kafka-tutorial.html" rel="bookmark">
            <time class="published dt-published" datetime="2022-12-17T07:12:21+05:30" itemprop="datePublished" title="2022-12-17">2022-12-17</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>A short hands-on guide to get started with Apache Kafka for people who are in a hurry.</p>
<p>In this guide, we will learn what is Apache Kafka, how to install and run it. We will also learn how to create/modify a topic and produce/consume messages from it.</p>
<h4>What is Apache Kafka?</h4>
<p><img src="../images/kafka-overview.jpg" alt="Apache Kafka"></p>
<p>Apache Kafka<sup id="fnref:wikipedia apache kafka"><a class="footnote-ref" href="../2022/12/hands-on-apache-kafka-tutorial.html#fn:wikipedia%20apache%20kafka">1</a></sup> is a distributed event store and streaming-processing platform. It is used to
build real-time data pipelines and streaming apps. It is horizontally scalable, fault-tolerant, and has high throughput.</p>
<h4>Kafka Terminology</h4>
<p><b>Topic</b>: A topic is a category or feed name to which records are published/consumed. It is configured with a set of
key-value pairs called topic configuration.</p>
<p><b>Producer</b>: A producer is a client that publishes records to the Kafka cluster. Producers write data to topics and
partitions.</p>
<p><b>Consumer</b>: A consumer is a client that subscribes to topics and processes the records. Consumers read data from
topics and partitions.</p>
<p><b>Consumer Group</b>: A consumer group is a group of consumers that share a common purpose. Consumer groups enable a
pool of processes to divide the work of consuming and processing records.</p>
<p><b>Broker</b>: A broker is a server that hosts a set of topics/partitions. It receives data from producers and sends
data to consumers.</p>
<p><b>ZooKeeper</b>: ZooKeeper is used to store the cluster configuration and the state of the cluster. All Kafka brokers
connect to ZooKeeper.</p>
<p><b>Kraft</b>: Kraft(Apache Kafka Raft) is a consensus protocol that is used to manage the metadata of the Kafka cluster.
It is introduced to remove dependency on ZooKeeper.</p>
<h4>Installing Apache Kafka</h4>
<p>We can use cp-all-in-one<sup id="fnref:cp-all-in-one"><a class="footnote-ref" href="../2022/12/hands-on-apache-kafka-tutorial.html#fn:cp-all-in-one">2</a></sup> docker compose files to run Apache Kafka locally. This image contains all the
components of Confluent Platform including Apache Kafka, Apache Zookeeper, Confluent Schema Registry, Confluent REST
Proxy, Confluent Control Center, and others.</p>
<pre class="code literal-block">$ git clone https://github.com/confluentinc/cp-all-in-one
$ <span class="nb">cd</span> cp-all-in-one/cp-all-in-one
$ docker-compose up
</pre>
<p>Confluent Control Center is a web UI to manage and monitor Apache Kafka.</p>
<p><img src="../images/kafka-control-center.png" alt="Kafka Control Center"></p>
<p>We can visit it <a href="http://localhost:9021">http://localhost:9021</a> and monitor the cluster from this UI.</p>
<h4>Producing and Consuming Messages</h4>
<p>Kafka stores messages in topics. A topic is a category or feed name to which messages are published/consumed.</p>
<p>Let us create a topic called <code>test</code> with <code>kafka-topics</code> command.</p>
<pre class="code literal-block">$ docker-compose <span class="nb">exec</span> broker kafka-topics --bootstrap-server localhost:9092 --topic <span class="nb">test</span> --create 
</pre>
<p>This will create a topic called <code>test</code> with a single partition and a replication factor of 1. In multi-node cluster, we
can use <code>--replication-factor</code>, <code>--partitions</code> to specify the number of replicas/partitions for the topic.</p>
<pre class="code literal-block">$ docker-compose <span class="nb">exec</span> broker kafka-topics --bootstrap-server localhost:9092 --topic <span class="nb">test</span> --partitions <span class="m">3</span> --replication-factor <span class="m">2</span> --create --if-not-exists
</pre>
<p>To produce messages to a topic named <code>test</code>, we can use <code>kafka-console-producer</code> and add messages to the topic:</p>
<pre class="code literal-block">$ docker-compose <span class="nb">exec</span> broker kafka-console-producer --broker-list localhost:9092 --topic <span class="nb">test</span>

&gt;order received
&gt;order updated
&gt;order shipped
&gt;order delivered
&gt;<span class="o">{</span><span class="s2">"status"</span>: <span class="s2">"completed"</span><span class="o">}</span>
</pre>
<p>To consume messages from the same topic:</p>
<pre class="code literal-block">$ docker-compose <span class="nb">exec</span> broker kafka-console-consumer --bootstrap-server localhost:9092 --topic <span class="nb">test</span> --from-beginning

order received
order updated
order shipped
order delivered
<span class="o">{</span><span class="s2">"status"</span>: <span class="s2">"completed"</span><span class="o">}</span>
</pre>
<p>Since we have not defined schema for the messages, Kafka will store the messages as byte arrays. We can explicitly define the schema for the messages using Confluent Schema Registry if required.</p>
<p>We can list all the topics in cluster using <code>kafka-topics</code>:</p>
<pre class="code literal-block">$ docker-compose <span class="nb">exec</span> broker kafka-topics --bootstrap-server localhost:9092 --list

default_ksql_processing_log
docker-connect-configs
docker-connect-offsets
docker-connect-status
<span class="nb">test</span>
</pre>
<p>To show details of a topic:</p>
<pre class="code literal-block">$ docker-compose <span class="nb">exec</span> broker kafka-topics --bootstrap-server localhost:9092 --describe --topic <span class="nb">test</span>

Topic: <span class="nb">test</span> TopicId: 7CckqkXsQXCNY0MNHYRv2w PartitionCount: <span class="m">1</span>   ReplicationFactor: <span class="m">1</span>    Configs: 
    Topic: <span class="nb">test</span> Partition: <span class="m">0</span>    Leader: <span class="m">1</span>   Replicas: <span class="m">1</span> Isr: <span class="m">1</span>  Offline:         
</pre>
<p>By default all messages are stored in the topic for 7 days. We can change this retention period using <code>retention.ms</code> configuration:</p>
<pre class="code literal-block">$ docker-compose <span class="nb">exec</span> broker kafka-topics --bootstrap-server localhost:9092 --alter --topic <span class="nb">test</span> --config retention.ms<span class="o">=</span><span class="m">10000</span>
</pre>
<p>To see all the available consumer groups, we can use <code>kafka-consumer-groups</code>:</p>
<pre class="code literal-block">$ docker-compose <span class="nb">exec</span> broker kafka-consumer-groups --bootstrap-server localhost:9092 --list
</pre>
<h4>Kafka Rest Proxy</h4>
<p>Kafka Rest Proxy<sup id="fnref:kafka rest proxy"><a class="footnote-ref" href="../2022/12/hands-on-apache-kafka-tutorial.html#fn:kafka%20rest%20proxy">3</a></sup> is a RESTful interface to Apache Kafka. It provides a RESTful interface to produce
and consume messages, view the state of the cluster, and perform administrative actions without using the native Kafka
protocol or clients.</p>
<p>To produce messages to a <code>test</code> topic with curl:</p>
<pre class="code literal-block">$ curl -X POST -H <span class="s2">"Content-Type: application/vnd.kafka.json.v2+json"</span> <span class="se">\</span>
    --data <span class="s1">'{"records":[{"value":{"status": "completed"}}]}'</span> <span class="se">\</span>
    <span class="s2">"http://localhost:8082/topics/test"</span>
</pre>
<p>To consume messages from the same topic:</p>
<pre class="code literal-block">$ curl -X GET -H <span class="s2">"Accept: application/vnd.kafka.json.v2+json"</span> <span class="se">\</span>
    <span class="s2">"http://localhost:8082/topics/test"</span>
</pre>
<p>We can dynamically configure Kafka cluster settings as well.</p>
<p>To change log level of various components of Kafka cluster using Kafka Rest Proxy.</p>
<pre class="code literal-block">$ curl -X POST -H <span class="s2">"Content-Type: application/vnd.kafka.v2+json"</span> <span class="se">\</span>
    --data <span class="s1">'{"log4j.logger.kafka.server":"DEBUG"}'</span> <span class="se">\</span>
    <span class="s2">"http://localhost:8082/config"</span>
</pre>
<p>We can update the log level of various components of Kafka cluster and check the logs.</p>
<h4>Conclusion</h4>
<p>In this article, we have seen how to install Apache Kafka locally using Docker. We have also seen how to produce and consume messages using Kafka console commands and Kafka Rest Proxy.</p>
<div class="footnote">
<hr>
<ol>
<li id="fn:wikipedia apache kafka">
<p><a href="https://en.wikipedia.org/wiki/Apache_Kafka">https://en.wikipedia.org/wiki/Apache_Kafka</a> <a class="footnote-backref" href="../2022/12/hands-on-apache-kafka-tutorial.html#fnref:wikipedia%20apache%20kafka" title="Jump back to footnote 1 in the text">↩</a></p>
</li>
<li id="fn:cp-all-in-one">
<p><a href="https://github.com/confluentinc/cp-all-in-one">https://github.com/confluentinc/cp-all-in-one</a> <a class="footnote-backref" href="../2022/12/hands-on-apache-kafka-tutorial.html#fnref:cp-all-in-one" title="Jump back to footnote 2 in the text">↩</a></p>
</li>
<li id="fn:kafka rest proxy">
<p><a href="https://github.com/confluentinc/kafka-rest">https://github.com/confluentinc/kafka-rest</a> <a class="footnote-backref" href="../2022/12/hands-on-apache-kafka-tutorial.html#fnref:kafka%20rest%20proxy" title="Jump back to footnote 3 in the text">↩</a></p>
</li>
</ol>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../2022/12/common-crawl-laptop-web-directory.html" class="u-url">Common Crawl on Laptop - Building Web Directory</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Chillar Anand
            </span></p>
            <p class="dateline">
            <a href="../2022/12/common-crawl-laptop-web-directory.html" rel="bookmark">
            <time class="published dt-published" datetime="2022-12-08T07:41:39+05:30" itemprop="datePublished" title="2022-12-08">2022-12-08</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>This series of posts discuss processing of common crawl dataset on laptop.</p>
<ol>
<li><a href="../2022/11/common-crawl-laptop-extract-subset.html">Extracting Subset of Common Crawl</a></li>
<li>
<a href="../2022/12/common-crawl-laptop-web-directory.html">Building web directory</a> (this post)</li>
</ol>
<h4>Introduction</h4>
<p>In the earlier post, we have extracted all telugu web page urls to a csv file. In this post, let's explore these urls and build a web directory from it.</p>
<h4>Explore Data</h4>
<p>Let's see how many urls are present in the extracted subset of data.</p>
<pre class="code literal-block">$ wc -l telugu.csv
  <span class="m">852025</span> telugu.csv 
</pre>
<p>In the earlier post, we have installed <code>duckdb</code> and used it for processing parquet files. <code>duckdb</code> can execute SQL queries directly on csv file. Let's use it to explore the data stored in telugu.csv.</p>
<p>Let's see how many unique domains are present in the data.</p>
<pre class="code literal-block">$ duckdb -c <span class="s2">"""</span>
<span class="s2">    SELECT COUNT(DISTINCT url_host_name_reversed) as unique_sites</span>
<span class="s2">    FROM read_csv('telugu.csv', auto_detect = TRUE);</span>
<span class="s2">"""</span>
┌──────────────┐
│ unique_sites │
├──────────────┤
│ <span class="m">13632</span>        │
└──────────────┘
</pre>
<p>There ~14k unique domains. Let's see page density across these domains.</p>
<pre class="code literal-block">$ duckdb -c <span class="s2">"""</span>
<span class="s2">SELECT count    AS page_count,</span>
<span class="s2">COUNT(*) AS sites</span>
<span class="s2">FROM (SELECT url_host_name_reversed, COUNT(*) AS count</span>
<span class="s2">FROM read_csv('te.csv', auto_detect = TRUE)</span>
<span class="s2">GROUP BY url_host_name_reversed) AS t</span>
<span class="s2">GROUP BY page_count</span>
<span class="s2">ORDER BY page_count;</span>
<span class="s2">"""</span>
┌────────────┬───────┐
│ page_count │ sites │
├────────────┼───────┤
│ <span class="m">1</span>          │ <span class="m">6326</span>  │
│ <span class="m">2</span>          │ <span class="m">1904</span>  │
│ <span class="m">3</span>          │ <span class="m">733</span>   │
│ <span class="m">4</span>          │ <span class="m">459</span>   │
│ <span class="m">5</span>          │ <span class="m">315</span>   │
</pre>
<p>About ~75% of the sites have less than 5 pages. It is highly unlikely that these sites complete content is in Telugu language. After manually checking a few of these sites, I found that there are a lot of false positives. </p>
<p>In the earlier post, we have extracted all pages where there is Telugu language content. Let's filter out pages where Telugu is <strong>primary</strong> language.</p>
<pre class="code literal-block">$ duckdb -c <span class="s2">"""</span>
<span class="s2">  COPY (</span>
<span class="s2">    SELECT * FROM read_csv('cct.csv', auto_detect=true) </span>
<span class="s2">    WHERE content_languages like 'tel%'</span>
<span class="s2">  ) TO 'te_primary.csv' (DELIMITER ',', HEADER TRUE);</span>
<span class="s2">"""</span>
</pre>
<pre class="code literal-block">$ wc -l te_primary.csv
  <span class="m">573130</span> te_primary.csv
</pre>
<pre class="code literal-block">$ duckdb -c <span class="s2">"SELECT COUNT(DISTINCT url_host_name_reversed) as unique_sites FROM read_csv('te_primary.csv', auto_detect = TRUE)"</span>                           
┌──────────────┐
│ unique_sites │
├──────────────┤
│ <span class="m">5666</span>         │
└──────────────┘    
</pre>
<p>Let's see how page density per domain has changed.</p>
<pre class="code literal-block">$ duckdb -c <span class="s2">"""</span>
<span class="s2">SELECT count    AS page_count,</span>
<span class="s2">COUNT(*) AS sites</span>
<span class="s2">FROM (SELECT url_host_name_reversed, COUNT(*) AS count</span>
<span class="s2">FROM read_csv('te_primary.csv', auto_detect = TRUE)</span>
<span class="s2">GROUP BY url_host_name_reversed) AS t</span>
<span class="s2">GROUP BY page_count</span>
<span class="s2">ORDER BY page_count</span>
<span class="s2">;</span>
<span class="s2">"""</span>
┌────────────┬───────┐
│ page_count │ sites │
├────────────┼───────┤
│ <span class="m">1</span>          │ <span class="m">2183</span>  │
│ <span class="m">2</span>          │ <span class="m">843</span>   │
│ <span class="m">3</span>          │ <span class="m">235</span>   │
│ <span class="m">4</span>          │ <span class="m">146</span>   │
│ <span class="m">5</span>          │ <span class="m">98</span>    │
</pre>
<p>Page density remains almost the same. </p>
<p>Let's filter out sites which have at least 5 pages in Telugu. This will eliminate a lot of false positives. Let's look at the most popular sites from the results.</p>
<pre class="code literal-block">   <span class="m">1</span>   │ Rank,Domain,Open Page Rank
   <span class="m">2</span>   │ <span class="m">25</span>,support.google.com,8.55
   <span class="m">3</span>   │ <span class="m">57</span>,t.me,7.76
   <span class="m">4</span>   │ <span class="m">76</span>,chrome.google.com,7.49
   <span class="m">5</span>   │ <span class="m">163</span>,support.mozilla.org,6.99
   <span class="m">6</span>   │ <span class="m">170</span>,groups.google.com,6.94
</pre>
<p>A lot of unrelated domains are present here because there might be 10+ pages in telugu in these domains as well. But we don't need these.</p>
<p>Let's look at only home page(or translated home page) where primary content language is telugu.</p>
<pre class="code literal-block">$ duckdb -c <span class="s2">"""</span>
<span class="s2">  SELECT COUNT(distinct url) </span>
<span class="s2">  FROM read_csv('te_primary.csv', auto_detect=true) </span>
<span class="s2">  WHERE (url_path = '/' or url_path = '/te/') and url_query is null;</span>
<span class="s2">"""</span>
</pre>
<p>Now the domain count has reduced to 6k. Let's export these domains to csv file.</p>
<p>To categorize these domains, Common-crawl doesn't yet provide any kind of categorisation. For now, we can use Open PageRank to sort these domains based on rank. </p>
<p>We can download top 10 million domains from Open PageRank<sup id="fnref:pagerank"><a class="footnote-ref" href="../2022/12/common-crawl-laptop-web-directory.html#fn:pagerank">3</a></sup>. Here is a simple python script to extract telugu domains from the list.</p>
<pre class="code literal-block"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">domains_file</span> <span class="o">=</span> <span class="s1">'domains.csv'</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">domains_file</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">telugu_domains</span> <span class="o">=</span> <span class="p">[</span><span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">()]</span>

<span class="n">telugu_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'.'</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="n">domain</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'.'</span><span class="p">)))</span> <span class="k">for</span> <span class="n">domain</span> <span class="ow">in</span> <span class="n">telugu_domains</span><span class="p">]</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'t10m.csv'</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">'Domain'</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">telugu_domains</span><span class="p">)]</span>

<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">'t10m_telugu.csv'</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre>
<p>Now, we have list of all telugu domains sorted by rank. In the next post, we will use this list to categorize the domains.</p>
<div class="footnote">
<hr>
<ol>
<li id="fn:common-crawl">
<p><a href="https://commoncrawl.org">https://commoncrawl.org</a> <a class="footnote-backref" href="../2022/12/common-crawl-laptop-web-directory.html#fnref:common-crawl" title="Jump back to footnote 1 in the text">↩</a></p>
</li>
<li id="fn:columnar-index-wiki">
<p><a href="https://en.wikipedia.org/wiki/Column-oriented_DBMS">https://en.wikipedia.org/wiki/Column-oriented_DBMS</a> <a class="footnote-backref" href="../2022/12/common-crawl-laptop-web-directory.html#fnref:columnar-index-wiki" title="Jump back to footnote 2 in the text">↩</a></p>
</li>
<li id="fn:pagerank">
<p><a href="https://www.domcop.com/openpagerank">https://www.domcop.com/openpagerank</a> <a class="footnote-backref" href="../2022/12/common-crawl-laptop-web-directory.html#fnref:pagerank" title="Jump back to footnote 3 in the text">↩</a></p>
</li>
<li id="fn:duckdb">
<p><a href="https://duckdb.org">https://duckdb.org</a> <a class="footnote-backref" href="../2022/12/common-crawl-laptop-web-directory.html#fnref:duckdb" title="Jump back to footnote 4 in the text">↩</a></p>
</li>
</ol>
</div>
    </div>
    </article>
</div>
        <ul class="pager postindexpager clearfix">
<li class="next"><a href="index-17.html" rel="next">Older posts</a></li>
        </ul>
<!--End of body content--><footer id="footer"><div class="container align-items-center justify-content-center d-flex">

<footer class="footer"><a href="https://github.com/ChillarAnand">
<img src="../images/icons8-github.svg" alt="github-chillar-anand" height="34"></a>

  

<a href="https://stackoverflow.com/users/2698552/chillar-anand">
<img src="../images/icons8-so.svg" alt="github-chillar-anand" height="30"></a>

  

<a href="https://youtube.com/@avilpage">
<img src="../images/icons8-youtube.svg" alt="github-chillar-anand" height="34"></a>

  

<a href="https://linkedin.com/in/chillaranand">
<img src="../images/icons8-linkedin.svg" alt="github-chillar-anand" height="34"></a>

  

<a href="https://twitter.com/chillaranand">
<img src="../images/icons8-twitter.svg" alt="github-chillar-anand" height="34"></a>

</footer>
</div>

<br><br></footer>
</div>
    </div>
    </div>

                <script src="../assets/js/jquery.min.js"></script><script src="../assets/js/popper.min.js"></script><script src="../assets/js/bootstrap.min.js"></script><script src="../assets/js/baguetteBox.min.js"></script><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
    </script>
</body>
</html>
