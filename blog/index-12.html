<!DOCTYPE html>
<html prefix="
og: http://ogp.me/ns# article: http://ogp.me/ns/article#
" lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="Avil Page - Personal &amp; tech blog by Chillar Anand">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Avil Page (old posts, page 12) | Avil Page</title>
<link href="../assets/css/bootstrap.min.css" rel="stylesheet" type="text/css">
<link href="../assets/css/baguetteBox.min.css" rel="stylesheet" type="text/css">
<link href="../assets/css/rst.css" rel="stylesheet" type="text/css">
<link href="../assets/css/code.css" rel="stylesheet" type="text/css">
<link href="../assets/css/theme.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" hreflang="en" href="../rss.xml">
<link rel="canonical" href="https://avilpage.com/blog/index-12.html">
<link rel="prev" href="index-13.html" type="text/html">
<link rel="next" href="index-11.html" type="text/html">
<!--[if lt IE 9]><script src="../assets/js/html5.js"></script><![endif]--><style>

 h1 {
     font-weight: bold;
     font-size: 25px;
 }

</style>
</head>
<body>
    <a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

    <!-- Menubar -->
    <nav class="navbar navbar-expand-md static-top mb-4
                navbar-dark
                bg-dark
                "><div class="container">
<!-- This keeps the margins nice -->
            <a class="navbar-brand" href="../">

                    <span id="blog-title">Avil Page</span>
            </a>
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>

            <div class="collapse navbar-collapse" id="bs-navbar">
                <ul class="navbar-nav mr-auto">
<li class="nav-item">
<a href="../archive.html" class="nav-link">Archive</a>
                </li>
<li class="nav-item">
<a href="../top-10.html" class="nav-link">Top 10</a>
                </li>
<li class="nav-item">
<a href="../rss.xml" class="nav-link">RSS</a>

                    
                </li>
</ul>
<ul class="navbar-nav navbar-right"></ul>
</div>
<!-- /.navbar-collapse -->
        </div>
<!-- /.container -->
    </nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="row justify-content-md-center">
        <div class="body-content col col-lg-6">
            <!--Body content-->
            
    
    
<div class="postindex">
    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../2018/11/archive-millions-pages-wget-minutes.html" class="u-url">Archive Million Pages With wget In Minutes</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Chillar Anand
            </span></p>
            <p class="dateline">
            <a href="../2018/11/archive-millions-pages-wget-minutes.html" rel="bookmark">
            <time class="published dt-published" datetime="2018-11-18T17:21:21+05:30" itemprop="datePublished" title="2018-11-18">2018-11-18</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <h4>Introduction</h4>
<p><a href="https://github.com/webrecorder/webrecorder">webrecorder</a>, <a href="https://github.com/internetarchive/heritrix3">heritrix</a>, <a href="https://nutch.apache.org/">nutch</a>, <a href="https://scrapy.org/">scrapy</a>, <a href="https://github.com/gocolly/colly">colly</a>, <a href="https://github.com/scrapinghub/frontera">frontera</a> are popular tools for large scale web crawling and archiving.</p>
<p>These tools require some learning curve and some of them don't have inbuilt support for warc(<a href="https://en.wikipedia.org/wiki/Web_ARChive">Web ARChive</a>) output format.</p>
<p><code>wget</code> comes bundled with most *nix systems and has inbuilt support for warc output. In this article we will see how to quickly archive web pages with wget.</p>
<h4>Archiving with wget</h4>
<p>In previous article we have extracted a <a href="../2018/11/comparision-alexa-majestic-domcorp-top-million-sites.html">superset of top 1 million domains</a>. We can use that list or urls to archive. Save this list to a file called <code>urls.txt</code>.</p>
<p>This can be archived with the following command.</p>
<div class="code"><pre class="code literal-block"><span class="nv">file</span><span class="o">=</span>urls.txt
wget<span class="w"> </span>-i<span class="w"> </span><span class="nv">$file</span><span class="w"> </span>--warc-file<span class="o">=</span><span class="nv">$file</span><span class="w"> </span>-t<span class="w"> </span><span class="m">3</span><span class="w"> </span>--timeout<span class="o">=</span><span class="m">4</span><span class="w"> </span>-q<span class="w"> </span>-o<span class="w"> </span>/dev/null<span class="w"> </span>-O<span class="w"> </span>/dev/null
</pre></div>

<p>wget has the ability to continue partially downloaded files. But this option won't work with warc output. So, it is better to split this list into small chunks and process them. One added advantage of this approach is we can parallely download multiple chunks with wget.</p>
<div class="code"><pre class="code literal-block">mkdir<span class="w"> </span>-p<span class="w"> </span>chunks
split<span class="w"> </span>-l<span class="w"> </span><span class="m">1000</span><span class="w"> </span>urls.txt<span class="w"> </span>chunks/<span class="w"> </span>-d<span class="w"> </span>--additional-suffix<span class="o">=</span>.txt<span class="w"> </span>-a<span class="w"> </span><span class="m">3</span>
</pre></div>

<p>This will split the file into several chunks each containing 1000 urls. wget doesn't have multithreading support. We can write a for loop to schedule a seperate process for each chunk.</p>
<div class="code"><pre class="code literal-block"><span class="k">for</span><span class="w"> </span><span class="nv">file</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span>`<span class="nv">ls</span><span class="w"> </span><span class="o">-</span><span class="nv">r</span><span class="w"> </span><span class="nv">chunks</span><span class="cm">/*.txt`</span>
<span class="cm">do</span>
<span class="cm">   wget -i $file --warc-file=$file -t 3 --timeout=4 -q -o /dev/null -O /dev/null &amp;</span>
<span class="cm">done</span>
</pre></div>

<p>To archive 1000 urls, it takes ~15 minutes. In less than 20 minutes, it will download entire million pages.</p>
<p>Also, each process takes ~8MB of memory. To run 1000 process, a system needs 8GB+ memory. Otherwise, number of parallel processes should be reduced which increases overall run time.</p>
<p>Each archive chunk will be ~150MB and consume lot of storage. All downloaded acrhives can be zipped to reduce storage.</p>
<div class="code"><pre class="code literal-block">gzip<span class="w"> </span>*.warc
</pre></div>

<p>Here is an idempotent shell script to download and archive files in batches.</p>
<div class="code"><pre class="code literal-block"><span class="ch">#! /bin/sh</span>

<span class="nb">set</span><span class="w"> </span>-x

<span class="nv">batch</span><span class="o">=</span><span class="m">1000</span>
<span class="nv">size</span><span class="o">=</span><span class="sb">`</span>expr<span class="w"> </span><span class="si">${#</span><span class="nv">batch</span><span class="si">}</span><span class="w"> </span>-<span class="w"> </span><span class="m">1</span><span class="sb">`</span>
<span class="nv">maxproc</span><span class="o">=</span><span class="m">50</span>
<span class="nv">file</span><span class="o">=</span>urls.txt
<span class="nv">dir</span><span class="o">=</span><span class="nv">$HOME</span><span class="s1">'/projects/chunks'</span><span class="nv">$batch</span>


mkdir<span class="w"> </span>-p<span class="w"> </span><span class="nv">$dir</span>
split<span class="w"> </span>-l<span class="w"> </span><span class="nv">$batch</span><span class="w"> </span><span class="nv">$file</span><span class="w"> </span><span class="nv">$dir</span><span class="s1">'/'</span><span class="w"> </span>-d<span class="w"> </span>--additional-suffix<span class="o">=</span>.txt<span class="w"> </span>-a<span class="w"> </span><span class="nv">$size</span>
sleep<span class="w"> </span><span class="m">1</span>

<span class="nv">useragent</span><span class="o">=</span><span class="s1">'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'</span>


<span class="k">for</span><span class="w"> </span>file<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="sb">`</span>ls<span class="w"> </span>-r<span class="w"> </span><span class="nv">$dir</span>/*.txt<span class="sb">`</span>
<span class="k">do</span>
<span class="w">    </span><span class="nv">warcfile</span><span class="o">=</span><span class="nv">$file</span><span class="s1">'.warc'</span>
<span class="w">    </span><span class="nv">warczip</span><span class="o">=</span><span class="nv">$warcfile</span><span class="s1">'.gz'</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="o">[</span><span class="w"> </span>-f<span class="w"> </span><span class="nv">$warczip</span><span class="w"> </span><span class="o">]</span><span class="w"> </span><span class="o">||</span><span class="w"> </span><span class="o">[</span><span class="w"> </span>-f<span class="w"> </span><span class="nv">$warcfile</span><span class="w"> </span><span class="o">]</span><span class="p">;</span><span class="w"> </span><span class="k">then</span>
<span class="w">        </span><span class="k">continue</span>
<span class="w">    </span><span class="k">fi</span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="o">[</span><span class="w"> </span><span class="k">$(</span>pgrep<span class="w"> </span>wget<span class="w"> </span>-c<span class="k">)</span><span class="w"> </span>-lt<span class="w"> </span><span class="nv">$maxproc</span><span class="w"> </span><span class="o">]</span><span class="p">;</span><span class="w"> </span><span class="k">then</span>
<span class="w">        </span><span class="nb">echo</span><span class="w"> </span><span class="nv">$file</span>
<span class="w">        </span>wget<span class="w"> </span>-H<span class="w"> </span><span class="s2">"user-agent: </span><span class="nv">$useragent</span><span class="s2">"</span><span class="w"> </span>-i<span class="w"> </span><span class="nv">$file</span><span class="w"> </span>--warc-file<span class="o">=</span><span class="nv">$file</span><span class="w"> </span>-t<span class="w"> </span><span class="m">3</span><span class="w"> </span>--timeout<span class="o">=</span><span class="m">4</span><span class="w"> </span>-q<span class="w"> </span>-o<span class="w"> </span>/dev/null<span class="w"> </span>-O<span class="w"> </span>/dev/null<span class="w"> </span><span class="p">&amp;</span>
<span class="w">        </span>sleep<span class="w"> </span><span class="m">2</span>
<span class="w">    </span><span class="k">else</span>
<span class="w">        </span>sleep<span class="w"> </span><span class="m">300</span>
<span class="w">        </span><span class="k">for</span><span class="w"> </span>filename<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="sb">`</span>find<span class="w"> </span><span class="nv">$dir</span><span class="w"> </span>-name<span class="w"> </span><span class="s1">'*.warc'</span><span class="w"> </span>-mmin<span class="w"> </span>+5<span class="sb">`</span>
<span class="w">        </span><span class="k">do</span>
<span class="w">            </span>gzip<span class="w"> </span><span class="nv">$filename</span><span class="w"> </span>-9
<span class="w">        </span><span class="k">done</span>
<span class="w">    </span><span class="k">fi</span>
<span class="k">done</span>
</pre></div>

<h4>Conclusion</h4>
<p>In this article, we have seen how to archive million pages with wget in few minutes.</p>
<p>wget2 has multithreading support and <a href="https://gitlab.com/gnuwget/wget2/issues/65">it might have warc output soon</a>. With that, archiving with wget becomes much easier.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../2018/11/comparision-alexa-majestic-domcorp-top-million-sites.html" class="u-url">Alexa vs Domcop vs Majestic - Top Million Sites</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Chillar Anand
            </span></p>
            <p class="dateline">
            <a href="../2018/11/comparision-alexa-majestic-domcorp-top-million-sites.html" rel="bookmark">
            <time class="published dt-published" datetime="2018-11-02T12:04:58+05:30" itemprop="datePublished" title="2018-11-02">2018-11-02</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <h4>Introduction</h4>
<p>Alexa<sup id="fnref:alexa"><a class="footnote-ref" href="../2018/11/comparision-alexa-majestic-domcorp-top-million-sites.html#fn:alexa">1</a></sup>, Domcop<sup id="fnref:domcop"><a class="footnote-ref" href="../2018/11/comparision-alexa-majestic-domcorp-top-million-sites.html#fn:domcop">2</a></sup>(based on CommonCrawl<sup id="fnref:commoncrawl"><a class="footnote-ref" href="../2018/11/comparision-alexa-majestic-domcorp-top-million-sites.html#fn:commoncrawl">3</a></sup> data) Majestic<sup id="fnref:majestic"><a class="footnote-ref" href="../2018/11/comparision-alexa-majestic-domcorp-top-million-sites.html#fn:majestic">4</a></sup> &amp;  provide top 1 million popular websites based on their analytics. In this article we will download this data and compare them using Linux command line tools.</p>
<h4>Collecting data</h4>
<p>Let's download data from above sources and extract domain names. The data format is different for each source. We can use <code>awk</code> tool to extract domains column from the source. After extracting data, sort it and save it to a file.</p>
<p>Extracting domains from alexa.</p>
<div class="code"><pre class="code literal-block"><span class="c1"># alexa</span>

$<span class="w"> </span>wget<span class="w"> </span>http://s3.amazonaws.com/alexa-static/top-1m.csv.zip

$<span class="w"> </span>unzip<span class="w"> </span>top-1m.csv.zip

<span class="c1"># data sorted by ranking</span>
$<span class="w"> </span>head<span class="w"> </span>-n<span class="w"> </span><span class="m">5</span><span class="w"> </span>top-1m.csv
<span class="m">1</span>,google.com
<span class="m">2</span>,youtube.com
<span class="m">3</span>,facebook.com
<span class="m">4</span>,baidu.com
<span class="m">5</span>,wikipedia.org

$<span class="w"> </span>awk<span class="w"> </span>-F<span class="w"> </span><span class="s2">","</span><span class="w"> </span><span class="s1">'{print $2}'</span><span class="w"> </span>top-1m.csv<span class="w"> </span><span class="p">|</span><span class="w"> </span>sort<span class="w"> </span>&gt;<span class="w"> </span>alexa

<span class="c1"># domains after sorting alphabetically</span>
$<span class="w"> </span>head<span class="w"> </span>-n<span class="w"> </span><span class="m">5</span><span class="w"> </span>alexa
<span class="m">00000</span>.life
<span class="m">00</span>-000.pl
<span class="m">00004</span>.tel
<span class="m">00008888</span>.tumblr.com
0002rick.tumblr.com
</pre></div>

<p>Extracting domain names from domcop.</p>
<div class="code"><pre class="code literal-block"><span class="c1"># Domcop</span>

$<span class="w"> </span>wget<span class="w"> </span>https://www.domcop.com/files/top/top10milliondomains.csv.zip

$<span class="w"> </span>unzip<span class="w"> </span>top10milliondomains.csv.zip

<span class="c1"># data sorted by ranking</span>
$<span class="w"> </span>head<span class="w"> </span>-n<span class="w"> </span><span class="m">5</span><span class="w"> </span>top10milliondomains.csv
<span class="s2">"Rank"</span>,<span class="s2">"Domain"</span>,<span class="s2">"Open Page Rank"</span>
<span class="s2">"1"</span>,<span class="s2">"fonts.googleapis.com"</span>,<span class="s2">"10.00"</span>
<span class="s2">"2"</span>,<span class="s2">"facebook.com"</span>,<span class="s2">"10.00"</span>
<span class="s2">"3"</span>,<span class="s2">"youtube.com"</span>,<span class="s2">"10.00"</span>
<span class="s2">"4"</span>,<span class="s2">"twitter.com"</span>,<span class="s2">"10.00"</span>

$<span class="w"> </span>awk<span class="w"> </span>-F<span class="w"> </span><span class="s2">"\"*,\"*"</span><span class="w"> </span><span class="s1">'{if(NR&gt;1)print $2}'</span><span class="w"> </span>top10milliondomains.csv.zip<span class="w"> </span><span class="p">|</span><span class="w"> </span>sort<span class="w"> </span>&gt;<span class="w"> </span>domcop

<span class="c1"># domains after sorting alphabetically</span>
$<span class="w"> </span>head<span class="w"> </span>-n<span class="w"> </span><span class="m">5</span><span class="w"> </span>domcop
00000000b.com
000000book.com
<span class="m">0000180</span>.fortunecity.com
<span class="m">000139418</span>.wixsite.com
000fashions.blogspot.com
</pre></div>

<p>Extracting domain names from majestic.</p>
<div class="code"><pre class="code literal-block"><span class="c1"># Majestic</span>

$<span class="w"> </span>wget<span class="w"> </span>http://downloads.majestic.com/majestic_million.csv

<span class="c1"># data sorted by ranking</span>
$<span class="w"> </span>head<span class="w"> </span>-n<span class="w"> </span><span class="m">5</span><span class="w"> </span>majestic_million.csv
GlobalRank,TldRank,Domain,TLD,RefSubNets,RefIPs,IDN_Domain,IDN_TLD,PrevGlobalRank,PrevTldRank,PrevRefSubNets,PrevRefIPs
<span class="m">1</span>,1,google.com,com,474277,3016409,google.com,com,1,1,474577,3012875
<span class="m">2</span>,2,facebook.com,com,462854,3093315,facebook.com,com,2,2,462860,3090006
<span class="m">3</span>,3,youtube.com,com,422434,2504924,youtube.com,com,3,3,422377,2501555
<span class="m">4</span>,4,twitter.com,com,412950,2497935,twitter.com,com,4,4,413220,2495261

$<span class="w"> </span>awk<span class="w"> </span>-F<span class="w"> </span><span class="s2">"\"*,\"*"</span><span class="w"> </span><span class="s1">'{if(NR&gt;1)print $2}'</span><span class="w"> </span>majestic_million.csv<span class="w"> </span><span class="p">|</span><span class="w"> </span>sort<span class="w"> </span>&gt;<span class="w"> </span>majestic

<span class="c1"># domains after sorting alphabetically</span>
$<span class="w"> </span>head<span class="w"> </span>-n<span class="w"> </span><span class="m">5</span><span class="w"> </span>majestic
<span class="m">00000</span>.xn--p1ai
<span class="m">0000666</span>.com
<span class="m">0000</span>.jp
0000www.com
<span class="m">0000</span>.xn--p1ai
</pre></div>

<h4>Comparing Data</h4>
<p>We have collected and extracted domains from above sources. Let's compare the domains to see how similar they are using <code>comm</code> tool.</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>comm<span class="w"> </span>-123<span class="w"> </span>alexa<span class="w"> </span>domcop<span class="w"> </span>--total
<span class="m">871851</span><span class="w">  </span><span class="m">871851</span><span class="w">  </span><span class="m">128149</span><span class="w">  </span>total

$<span class="w"> </span>comm<span class="w"> </span>-123<span class="w"> </span>alexa<span class="w"> </span>majestic<span class="w"> </span>--total
<span class="m">788454</span><span class="w">  </span><span class="m">788454</span><span class="w">  </span><span class="m">211546</span><span class="w">  </span>total

$<span class="w"> </span>comm<span class="w"> </span>-123<span class="w"> </span>domcop<span class="w"> </span>majestic<span class="w"> </span>--total
<span class="m">784388</span><span class="w">  </span><span class="m">784388</span><span class="w">  </span><span class="m">215612</span><span class="w">  </span>total
</pre></div>

<div class="code"><pre class="code literal-block">$<span class="w"> </span>comm<span class="w"> </span>-12<span class="w"> </span>alexa<span class="w"> </span>domcop<span class="w"> </span><span class="p">|</span><span class="w"> </span>comm<span class="w"> </span>-123<span class="w"> </span>-<span class="w"> </span>majestic<span class="w"> </span>--total
<span class="m">31314</span><span class="w">   </span><span class="m">903165</span><span class="w">  </span><span class="m">96835</span><span class="w">   </span>total
</pre></div>

<p>So, only 96,835(9.6%) domains are common between all the datasets and the overlap between any two sources is ~20%. Here is a venn diagram showing the overlap between them.</p>
<p align="center">
<img src="../images/million-alexa-majestic-domcop.png"></p>

<h4>Conclusion</h4>
<p>We have collected data from alexa, domcorp &amp; majestic, extracted domains from it and observed that there is only a small overlap between them.</p>
<div class="footnote">
<hr>
<ol>
<li id="fn:alexa">
<p><a href="http://s3.amazonaws.com/alexa-static/top-1m.csv.zip">http://s3.amazonaws.com/alexa-static/top-1m.csv.zip</a> <a class="footnote-backref" href="../2018/11/comparision-alexa-majestic-domcorp-top-million-sites.html#fnref:alexa" title="Jump back to footnote 1 in the text">↩</a></p>
</li>
<li id="fn:domcop">
<p><a href="https://www.domcop.com/files/top/top10milliondomains.csv.zip">https://www.domcop.com/files/top/top10milliondomains.csv.zip</a> <a class="footnote-backref" href="../2018/11/comparision-alexa-majestic-domcorp-top-million-sites.html#fnref:domcop" title="Jump back to footnote 2 in the text">↩</a></p>
</li>
<li id="fn:commoncrawl">
<p><a href="https://commoncrawl.org/">https://commoncrawl.org/</a> <a class="footnote-backref" href="../2018/11/comparision-alexa-majestic-domcorp-top-million-sites.html#fnref:commoncrawl" title="Jump back to footnote 3 in the text">↩</a></p>
</li>
<li id="fn:majestic">
<p><a href="http://downloads.majestic.com/majestic_million.csv">http://downloads.majestic.com/majestic_million.csv</a> <a class="footnote-backref" href="../2018/11/comparision-alexa-majestic-domcorp-top-million-sites.html#fnref:majestic" title="Jump back to footnote 4 in the text">↩</a></p>
</li>
</ol>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../2018/10/cd-python-chalice-aws.html" class="u-url">Setup Continous Deployment For Python Chalice</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Chillar Anand
            </span></p>
            <p class="dateline">
            <a href="../2018/10/cd-python-chalice-aws.html" rel="bookmark">
            <time class="published dt-published" datetime="2018-10-30T21:21:21+05:30" itemprop="datePublished" title="2018-10-30">2018-10-30</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <h4>Outline</h4>
<p><a href="https://pypi.org/project/chalice/">Chalice</a> is a microframework developed by Amazon for quickly creating and deploying serverless applications in Python.</p>
<p>In this article, we will see how to setup continous deployment with <a href="https://github.com">GitHub</a> and <a href="https://docs.aws.amazon.com/codepipeline/latest/userguide/welcome.html">AWS CodePipeline</a>.</p>
<h4>CD Setup</h4>
<p>Chalice provides cli command <code>deploy</code> to deploy from local system.</p>
<p>Chalice also provides cli command <code>generate-pipeline</code> command to generate CloudFormation template. This template is useful to automatically generate several resources required for AWS pipeline.</p>
<p align="center">
<img src="../images/aws-python-pipeline.png" height="300px" width="600"></p>

<p>This by default uses CodeCommit repository for hosting code. We can use GitHub repo as a source instead of CodeCommit.</p>
<p>Chalice by default provides a build file to package code and push it to S3. In the deploy step, it uses this artifact to deploy the code.</p>
<p>We can use a custom buildpsec file to directly deploy the code from build step.</p>
<div class="code"><pre class="code literal-block"><span class="n">version</span><span class="o">:</span><span class="w"> </span><span class="mf">0.1</span>

<span class="n">phases</span><span class="o">:</span>
<span class="w">  </span><span class="k">install</span><span class="o">:</span>
<span class="w">    </span><span class="n">commands</span><span class="o">:</span>
<span class="w">      </span><span class="o">-</span><span class="w"> </span><span class="n">echo</span><span class="w"> </span><span class="n">Entering</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="k">install</span><span class="w"> </span><span class="k">phase</span>
<span class="w">      </span><span class="o">-</span><span class="w"> </span><span class="n">echo</span><span class="w"> </span><span class="n">Installing</span><span class="w"> </span><span class="n">dependencies</span>
<span class="w">      </span><span class="o">-</span><span class="w"> </span><span class="n">sudo</span><span class="w"> </span><span class="n">pip</span><span class="w"> </span><span class="k">install</span><span class="w"> </span><span class="o">--</span><span class="k">upgrade</span><span class="w"> </span><span class="n">awscli</span>
<span class="w">      </span><span class="o">-</span><span class="w"> </span><span class="n">aws</span><span class="w"> </span><span class="o">--</span><span class="n">version</span>
<span class="w">      </span><span class="o">-</span><span class="w"> </span><span class="n">sudo</span><span class="w"> </span><span class="n">pip</span><span class="w"> </span><span class="k">install</span><span class="w"> </span><span class="n">chalice</span>
<span class="w">      </span><span class="o">-</span><span class="w"> </span><span class="n">sudo</span><span class="w"> </span><span class="n">pip</span><span class="w"> </span><span class="k">install</span><span class="w"> </span><span class="o">-</span><span class="n">r</span><span class="w"> </span><span class="n">requirements</span><span class="p">.</span><span class="n">txt</span>

<span class="w">  </span><span class="n">build</span><span class="o">:</span>
<span class="w">    </span><span class="n">commands</span><span class="o">:</span>
<span class="w">      </span><span class="o">-</span><span class="w"> </span><span class="n">echo</span><span class="w"> </span><span class="n">entered</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">build</span><span class="w"> </span><span class="k">phase</span>
<span class="w">      </span><span class="o">-</span><span class="w"> </span><span class="n">echo</span><span class="w"> </span><span class="n">Build</span><span class="w"> </span><span class="n">started</span><span class="w"> </span><span class="k">on</span><span class="w"> </span><span class="n n-Quoted">`date`</span>
<span class="w">      </span><span class="o">-</span><span class="w"> </span><span class="n">chalice</span><span class="w"> </span><span class="n">deploy</span><span class="w"> </span><span class="o">--</span><span class="n">stage</span><span class="w"> </span><span class="n">staging</span>
</pre></div>

<p>This buildspec file install requirements and deploys chalice app to staging. We can add one more build step to deploy it production after manual intervention.</p>
<h4>Conclusion</h4>
<p>We have seen how to setup continous deployment for chalice application with GitHub and AWS CodePipeline.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../2018/08/parsing-and-transforming-mitmproxy-request-flows.html" class="u-url">Parsing &amp; Transforming mitmproxy Request Flows</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Chillar Anand
            </span></p>
            <p class="dateline">
            <a href="../2018/08/parsing-and-transforming-mitmproxy-request-flows.html" rel="bookmark">
            <time class="published dt-published" datetime="2018-08-11T21:21:21+05:30" itemprop="datePublished" title="2018-08-11">2018-08-11</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p><a href="https://mitmproxy.org/">mitmproxy</a> is a free and open source interactive HTTPS proxy. It provides command-line interface, web interface and Python API for interaction and customizing it for our needs.</p>
<p>mitmproxy provides an option to export web request flows to curl/httpie/raw formats. From mitmproxy, we can press <code>e</code>(export) and then we can select format for exporting.</p>
<p align="center">
<img src="../images/mitm-curl.png" height="300px" width="600"></p>

<p>Exporting multiple requests with this interface becomes tedious. Instead we can save all requests to a file and write a python script to export them.</p>
<p>Start mitmproxy with this command so that all request flows are appended to <code>requests.mitm</code> file for later use.</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>mitmproxy<span class="w"> </span>-w<span class="w"> </span>+requests.mitm
</pre></div>

<p>Here is a python script to parse this dump file and print request URLs.</p>
<div class="code"><pre class="code literal-block"><span class="kn">from</span> <span class="nn">mitmproxy.io</span> <span class="kn">import</span> <span class="n">FlowReader</span>


<span class="n">filename</span> <span class="o">=</span> <span class="s1">'requests.mitm'</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
    <span class="n">reader</span> <span class="o">=</span> <span class="n">FlowReader</span><span class="p">(</span><span class="n">fp</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">flow</span> <span class="ow">in</span> <span class="n">reader</span><span class="o">.</span><span class="n">stream</span><span class="p">():</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">flow</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">url</span><span class="p">)</span>
</pre></div>

<p><code>flow.request</code> object has more attributes to provide information about the request.</p>
<div class="code"><pre class="code literal-block"><span class="n">In</span> <span class="p">[</span><span class="mi">31</span><span class="p">]:</span> <span class="nb">dir</span><span class="p">(</span><span class="n">flow</span><span class="o">.</span><span class="n">request</span><span class="p">)</span>
<span class="n">Out</span><span class="p">[</span><span class="mi">31</span><span class="p">]:</span>
<span class="p">[</span><span class="o">...</span>
 <span class="s1">'host'</span><span class="p">,</span>
 <span class="s1">'host_header'</span><span class="p">,</span>
 <span class="s1">'http_version'</span><span class="p">,</span>
 <span class="s1">'method'</span><span class="p">,</span>
 <span class="s1">'multipart_form'</span><span class="p">,</span>
 <span class="s1">'path'</span><span class="p">,</span>
 <span class="s1">'raw_content'</span><span class="p">,</span>
 <span class="o">...</span>
 <span class="s1">'wrap'</span><span class="p">]</span>
</pre></div>

<p>We can use the mitmproxy export utilities to transform mitm flows to other formats.</p>
<div class="code"><pre class="code literal-block"><span class="n">In</span> <span class="p">[</span><span class="mi">32</span><span class="p">]:</span> <span class="n">flow</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">reader</span><span class="o">.</span><span class="n">stream</span><span class="p">())</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">33</span><span class="p">]:</span> <span class="kn">from</span> <span class="nn">mitmproxy.addons</span> <span class="kn">import</span> <span class="n">export</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">34</span><span class="p">]:</span> <span class="n">export</span><span class="o">.</span><span class="n">curl_command</span><span class="p">(</span><span class="n">flow</span><span class="p">)</span>
<span class="n">Out</span><span class="p">[</span><span class="mi">34</span><span class="p">]:</span> <span class="s2">"curl -H 'Host:mitm.it' -H 'Proxy-Connection:keep-alive' -H 'User-Agent:Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36' -H 'DNT:1' -H 'Accept:image/webp,image/apng,image/*,*/*;q=0.8' -H 'Referer:http://mitm.it/' -H 'Accept-Encoding:gzip, deflate' -H 'Accept-Language:en-US,en;q=0.9,ms;q=0.8,te;q=0.7' -H 'content-length:0' 'http://mitm.it/favicon.ico'"</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">35</span><span class="p">]:</span> <span class="n">export</span><span class="o">.</span><span class="n">raw</span><span class="p">(</span><span class="n">flow</span><span class="p">)</span>
<span class="n">Out</span><span class="p">[</span><span class="mi">35</span><span class="p">]:</span> <span class="sa">b</span><span class="s1">'GET /favicon.ico HTTP/1.1</span><span class="se">\r\n</span><span class="s1">Host: mitm.it</span><span class="se">\r\n</span><span class="s1">Proxy-Connection: keep-alive</span><span class="se">\r\n</span><span class="s1">User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36</span><span class="se">\r\n</span><span class="s1">DNT: 1</span><span class="se">\r\n</span><span class="s1">Accept: image/webp,image/apng,image/*,*/*;q=0.8</span><span class="se">\r\n</span><span class="s1">Referer: http://mitm.it/</span><span class="se">\r\n</span><span class="s1">Accept-Encoding: gzip, deflate</span><span class="se">\r\n</span><span class="s1">Accept-Language: en-US,en;q=0.9,ms;q=0.8,te;q=0.7</span><span class="se">\r\n\r\n</span><span class="s1">'</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">36</span><span class="p">]:</span> <span class="n">export</span><span class="o">.</span><span class="n">httpie_command</span><span class="p">(</span><span class="n">flow</span><span class="p">)</span>
<span class="n">Out</span><span class="p">[</span><span class="mi">36</span><span class="p">]:</span> <span class="s2">"http GET http://mitm.it/favicon.ico 'Host:mitm.it' 'Proxy-Connection:keep-alive' 'User-Agent:Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36' 'DNT:1' 'Accept:image/webp,image/apng,image/*,*/*;q=0.8' 'Referer:http://mitm.it/' 'Accept-Encoding:gzip, deflate' 'Accept-Language:en-US,en;q=0.9,ms;q=0.8,te;q=0.7' 'content-length:0'"</span>
</pre></div>

<p>With these utilities we can transform mitmproxy request flow to curl command or any other custom form to fit our needs.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../2018/07/linux-performance-analysis-in-seconds.html" class="u-url">Linux Performance Analysis In Less Than 10 Seconds</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Chillar Anand
            </span></p>
            <p class="dateline">
            <a href="../2018/07/linux-performance-analysis-in-seconds.html" rel="bookmark">
            <time class="published dt-published" datetime="2018-07-24T21:21:21+05:30" itemprop="datePublished" title="2018-07-24">2018-07-24</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>If you are using a Linux System or managing a Linux server, you might come across a situation where a process is taking too long to complete. In this article we will see how to track down such performance issues in Linux.</p>
<p>Netflix TechBlog has an article on how to <a href="https://medium.com/netflix-techblog/linux-performance-analysis-in-60-000-milliseconds-accc10403c55">anlyze Linux performance in 60 seconds</a>. This article  provides 10+ tools to use in order to see the resource usage and pinpoint the bottleneck.</p>
<p>It is strenuous to remember all those tools/options and laborious to run all those commands when working on multiple systems.</p>
<p>Instead, we can use <a href="http://atoptool.nl/">atop</a>, a tool for one stop solution for performance analysis. Here is a comparision of atop with other tools from <a href="https://lwn.net/Articles/387202/">LWN</a>.</p>
<p align="center">
<img src="../images/linux-performance-analysis-tools.png" height="300px" width="600"></p>

<p>atop shows live &amp; historical data measurement at system level as well as process level. To get the glimpse of system resource(CPU, memory, network, disk) usage install and run atop with</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>sudo<span class="w"> </span>apt<span class="w"> </span>install<span class="w"> </span>--yes<span class="w"> </span>atop

$<span class="w"> </span>atop
</pre></div>

<p align="center">
<img src="../images/atop.png" height="300px" width="600"></p>

<p>By default, atop shows resources used in the last interval only and sorts them by CPU usage. We can use</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>atop<span class="w"> </span>-A<span class="w"> </span>-f<span class="w"> </span><span class="m">4</span>
</pre></div>

<p><code>-A</code> sorts the processes automatically in the order of the most busy system resource.</p>
<p><code>-f</code> shows both active as well as inactive system resources in the ouput.</p>
<p><code>4</code> sets refresh interval to 4 seconds.</p>
<p>Just by looking at the output of atop, we get a glimpse of overall system resource usage as well as individual processes resource usage.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../2018/05/django-tips-tricks-log-sql-queries-to-console.html" class="u-url">Django Tips &amp; Tricks #10 - Log SQL Queries To Console</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Chillar Anand
            </span></p>
            <p class="dateline">
            <a href="../2018/05/django-tips-tricks-log-sql-queries-to-console.html" rel="bookmark">
            <time class="published dt-published" datetime="2018-06-14T21:21:21+05:30" itemprop="datePublished" title="2018-06-14">2018-06-14</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>Django ORM makes easy to interact with database. To understand what is happening behing the scenes or to see SQL performance, we can log all the SQL queries that be being executed. In this article, we will see various ways to achieve this.</p>
<h4>Using debug-toolbar</h4>
<p><a href="https://pypi.org/project/django-debug-toolbar/" target="_blank">Django debug toolbar</a> provides panels to show debug information about requests. It has SQL panel which shows all executed SQL queries and time taken for them.</p>
<p align="center">
<img src="../images/django-sql-log-toolbar.png" height="300px" width="600"></p>

<p>When building REST APIs or micro services where django templating engine is not used, <a href="https://github.com/jazzband/django-debug-toolbar/issues/1059" target="_blank">this method won't work</a>. In these situations, we have to log SQL queries to console.</p>
<h4>Using django-extensions</h4>
<p><a href="https://pypi.org/project/django-extensions/">Django-extensions</a> provides lot of utilities for productive development. For <code>runserver_plus</code> and <code>shell_plus</code> commands, it accepts and optional <code>--print-sql</code> argument, which prints all the SQL queries that are being executed.</p>
<div class="code"><pre class="code literal-block">./manage.py<span class="w"> </span>runserver_plus<span class="w"> </span>--print-sql
./manage.py<span class="w"> </span>shell_plus<span class="w"> </span>--print-sql
</pre></div>

<p>Whenever an SQL query gets executed, it prints the query and time taken for it in console.</p>
<div class="code"><pre class="code literal-block"><span class="n">In</span> <span class="p">[</span><span class="mi">42</span><span class="p">]:</span> <span class="n">User</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">is_staff</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">Out</span><span class="p">[</span><span class="mi">42</span><span class="p">]:</span> <span class="n">SELECT</span> <span class="s2">"auth_user"</span><span class="o">.</span><span class="s2">"id"</span><span class="p">,</span>
       <span class="s2">"auth_user"</span><span class="o">.</span><span class="s2">"password"</span><span class="p">,</span>
       <span class="s2">"auth_user"</span><span class="o">.</span><span class="s2">"last_login"</span><span class="p">,</span>
       <span class="s2">"auth_user"</span><span class="o">.</span><span class="s2">"is_superuser"</span><span class="p">,</span>
       <span class="s2">"auth_user"</span><span class="o">.</span><span class="s2">"username"</span><span class="p">,</span>
       <span class="s2">"auth_user"</span><span class="o">.</span><span class="s2">"first_name"</span><span class="p">,</span>
       <span class="s2">"auth_user"</span><span class="o">.</span><span class="s2">"last_name"</span><span class="p">,</span>
       <span class="s2">"auth_user"</span><span class="o">.</span><span class="s2">"email"</span><span class="p">,</span>
       <span class="s2">"auth_user"</span><span class="o">.</span><span class="s2">"is_staff"</span><span class="p">,</span>
       <span class="s2">"auth_user"</span><span class="o">.</span><span class="s2">"is_active"</span><span class="p">,</span>
       <span class="s2">"auth_user"</span><span class="o">.</span><span class="s2">"date_joined"</span>
  <span class="n">FROM</span> <span class="s2">"auth_user"</span>
 <span class="n">WHERE</span> <span class="s2">"auth_user"</span><span class="o">.</span><span class="s2">"is_staff"</span> <span class="o">=</span> <span class="n">true</span>
 <span class="n">LIMIT</span> <span class="mi">21</span>


<span class="n">Execution</span> <span class="n">time</span><span class="p">:</span> <span class="mf">0.002107</span><span class="n">s</span> <span class="p">[</span><span class="n">Database</span><span class="p">:</span> <span class="n">default</span><span class="p">]</span>

<span class="o">&lt;</span><span class="n">QuerySet</span> <span class="p">[</span><span class="o">&lt;</span><span class="n">User</span><span class="p">:</span> <span class="n">anand</span><span class="o">&gt;</span><span class="p">,</span> <span class="o">&lt;</span><span class="n">User</span><span class="p">:</span> <span class="n">chillar</span><span class="o">&gt;</span><span class="p">]</span><span class="o">&gt;</span>
</pre></div>

<h4>Using django-querycount</h4>
<p><a href="https://pypi.org/project/django-querycount/">Django-querycount</a> provides a middleware to show SQL query count and show duplicate queries on console.</p>
<div class="code"><pre class="code literal-block"><span class="p">|</span>------<span class="p">|</span>-----------<span class="p">|</span>----------<span class="p">|</span>----------<span class="p">|</span>----------<span class="p">|</span>------------<span class="p">|</span>
<span class="p">|</span><span class="w"> </span>Type<span class="w"> </span><span class="p">|</span><span class="w"> </span>Database<span class="w">  </span><span class="p">|</span><span class="w">   </span>Reads<span class="w">  </span><span class="p">|</span><span class="w">  </span>Writes<span class="w">  </span><span class="p">|</span><span class="w">  </span>Totals<span class="w">  </span><span class="p">|</span><span class="w"> </span>Duplicates<span class="w"> </span><span class="p">|</span>
<span class="p">|</span>------<span class="p">|</span>-----------<span class="p">|</span>----------<span class="p">|</span>----------<span class="p">|</span>----------<span class="p">|</span>------------<span class="p">|</span>
<span class="p">|</span><span class="w"> </span>RESP<span class="w"> </span><span class="p">|</span><span class="w">  </span>default<span class="w">  </span><span class="p">|</span><span class="w">    </span><span class="m">3</span><span class="w">     </span><span class="p">|</span><span class="w">    </span><span class="m">0</span><span class="w">     </span><span class="p">|</span><span class="w">    </span><span class="m">3</span><span class="w">     </span><span class="p">|</span><span class="w">     </span><span class="m">1</span><span class="w">      </span><span class="p">|</span>
<span class="p">|</span>------<span class="p">|</span>-----------<span class="p">|</span>----------<span class="p">|</span>----------<span class="p">|</span>----------<span class="p">|</span>------------<span class="p">|</span>
Total<span class="w"> </span>queries:<span class="w"> </span><span class="m">3</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span>.7738s


Repeated<span class="w"> </span><span class="m">1</span><span class="w"> </span>times.
SELECT<span class="w"> </span><span class="s2">"django_session"</span>.<span class="s2">"session_key"</span>,
<span class="s2">"django_session"</span>.<span class="s2">"session_data"</span>,<span class="w"> </span><span class="s2">"django_session"</span>.<span class="s2">"expire_date"</span><span class="w"> </span>FROM
<span class="s2">"django_session"</span><span class="w"> </span>WHERE<span class="w"> </span><span class="o">(</span><span class="s2">"django_session"</span>.<span class="s2">"session_key"</span><span class="w"> </span><span class="o">=</span>
<span class="s1">'dummy_key AND "django_session"."expire_date"</span>
<span class="s1">&gt; '</span><span class="m">2018</span>-05-31T09:38:56.369469+00:00<span class="err">'</span>::timestamptz<span class="o">)</span>
</pre></div>

<p>This package provides <a href="https://github.com/bradmontgomery/django-querycount#settings">additional settings</a> to customize output.</p>
<h4>Django logging</h4>
<p>Instead of using any 3rd party package, we can use <code>django.db.backends</code> logger to print all the SQL queries.</p>
<p>Add <code>django.db.backends</code> to loggers list and set log level and handlers.</p>
<div class="code"><pre class="code literal-block">    <span class="s1">'loggers'</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">'django.db.backends'</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">'level'</span><span class="p">:</span> <span class="s1">'DEBUG'</span><span class="p">,</span>
            <span class="s1">'handlers'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'console'</span><span class="p">,</span> <span class="p">],</span>
        <span class="p">},</span>
</pre></div>

<p>In runserver console, we can see all SQL queries that are being executed.</p>
<div class="code"><pre class="code literal-block">(0.001) SELECT "django_admin_log"."id", "django_admin_log"."action_time", "django_admin_log"."user_id", "django_admin_log"."content_type_id", "django_admin_log"."object_id", "django_admin_log"."object_repr", "django_admin_log"."action_flag", "django_admin_log"."change_message", "auth_user"."id", "auth_user"."password", "auth_user"."last_login", "auth_user"."is_superuser", "auth_user"."username", "auth_user"."first_name", "auth_user"."last_name", "auth_user"."email", "auth_user"."is_staff", "auth_user"."is_active", "auth_user"."date_joined", "django_content_type"."id", "django_content_type"."app_label", "django_content_type"."model" FROM "django_admin_log" INNER JOIN "auth_user" ON ("django_admin_log"."user_id" = "auth_user"."id") LEFT OUTER JOIN "django_content_type" ON ("django_admin_log"."content_type_id" = "django_content_type"."id") WHERE "django_admin_log"."user_id" = 4 ORDER BY "django_admin_log"."action_time" DESC LIMIT 10; args=(4,)
[2018/06/03 15:06:59] HTTP GET /admin/ 200 [1.69, 127.0.0.1:47734]
</pre></div>

<p>These are few ways to log all SQL queries to console. We can also write a custom middleware for better logging of these queries and get some insights.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../2018/05/deploying-scaling-django-channels.html" class="u-url">How To Deploy Django Channels To Production</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Chillar Anand
            </span></p>
            <p class="dateline">
            <a href="../2018/05/deploying-scaling-django-channels.html" rel="bookmark">
            <time class="published dt-published" datetime="2018-05-18T21:21:21+05:30" itemprop="datePublished" title="2018-05-18">2018-05-18</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>In this article, we will see how to deploy <a href="https://pypi.org/project/channels/">django channels</a> to production and how we can scale it to handle more load. We will be using nginx as proxy server, <a href="https://pypi.org/project/daphne/">daphne</a> as ASGI server, gunicorn as WSGI server and redis for channel back-end.</p>
<p>Daphne can serve HTTP requests as well as WebSocket requests. For stability and performance, we will use uwsgi/gunicorn to serve HTTP requests and daphne to serve websocket requests.</p>
<p>We will be using systemd to create and manage processes instead of depending on third party process managers like supervisor or circus. We will be using ansible for managing deployments. If you don't want to use ansible, you can just replace template variables in the following files with actual values.</p>
<h4>Nginx Setup</h4>
<p>Nginx will be routing requests to WSGI server and ASGI server based on URL. Here is nginx configuration for server.</p>
<div class="code"><pre class="code literal-block"><span class="n">server</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">listen</span><span class="w"> </span><span class="p">{{</span><span class="w"> </span><span class="n">server_name</span><span class="w"> </span><span class="p">}}:</span><span class="mi">80</span><span class="p">;</span>
<span class="w">    </span><span class="n">server_name</span><span class="w"> </span><span class="p">{{</span><span class="w"> </span><span class="n">server_name</span><span class="w"> </span><span class="p">}}</span><span class="w"> </span><span class="n">www</span><span class="o">.</span><span class="p">{{</span><span class="w"> </span><span class="n">server_name</span><span class="w"> </span><span class="p">}};</span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">301</span><span class="w"> </span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">avilpage</span><span class="o">.</span><span class="n">com</span><span class="o">$</span><span class="n">request_uri</span><span class="p">;</span>
<span class="p">}</span>


<span class="n">server</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">listen</span><span class="w"> </span><span class="p">{{</span><span class="w"> </span><span class="n">server_name</span><span class="w"> </span><span class="p">}}:</span><span class="mi">443</span><span class="w"> </span><span class="n">ssl</span><span class="p">;</span>
<span class="w">    </span><span class="n">server_name</span><span class="w"> </span><span class="p">{{</span><span class="w"> </span><span class="n">server_name</span><span class="w"> </span><span class="p">}}</span><span class="w"> </span><span class="n">www</span><span class="o">.</span><span class="p">{{</span><span class="w"> </span><span class="n">server_name</span><span class="w"> </span><span class="p">}};</span>

<span class="w">    </span><span class="n">ssl_certificate</span><span class="w">     </span><span class="o">/</span><span class="n">root</span><span class="o">/</span><span class="n">certs</span><span class="o">/</span><span class="n">avilpage</span><span class="o">.</span><span class="n">com</span><span class="o">.</span><span class="n">chain</span><span class="o">.</span><span class="n">crt</span><span class="p">;</span>
<span class="w">    </span><span class="n">ssl_certificate_key</span><span class="w"> </span><span class="o">/</span><span class="n">root</span><span class="o">/</span><span class="n">certs</span><span class="o">/</span><span class="n">avilpage</span><span class="o">.</span><span class="n">com</span><span class="o">.</span><span class="n">key</span><span class="p">;</span>

<span class="w">    </span><span class="n">access_log</span><span class="w"> </span><span class="o">/</span><span class="k">var</span><span class="o">/</span><span class="nb">log</span><span class="o">/</span><span class="n">nginx</span><span class="o">/</span><span class="n">avilpage</span><span class="o">.</span><span class="n">com</span><span class="o">.</span><span class="n">access</span><span class="o">.</span><span class="n">log</span><span class="p">;</span>
<span class="w">    </span><span class="n">error_log</span><span class="w"> </span><span class="o">/</span><span class="k">var</span><span class="o">/</span><span class="nb">log</span><span class="o">/</span><span class="n">nginx</span><span class="o">/</span><span class="n">avilpage</span><span class="o">.</span><span class="n">com</span><span class="o">.</span><span class="n">error</span><span class="o">.</span><span class="n">log</span><span class="p">;</span>

<span class="w">    </span><span class="n">location</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">proxy_pass</span><span class="w"> </span><span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="mf">0.0</span><span class="o">.</span><span class="mf">0.0</span><span class="p">:</span><span class="mi">8000</span><span class="p">;</span>
<span class="w">            </span><span class="n">proxy_set_header</span><span class="w"> </span><span class="n">X</span><span class="o">-</span><span class="n">Forwarded</span><span class="o">-</span><span class="n">For</span><span class="w"> </span><span class="o">$</span><span class="n">proxy_add_x_forwarded_for</span><span class="p">;</span>
<span class="w">            </span><span class="n">proxy_set_header</span><span class="w"> </span><span class="n">Host</span><span class="w"> </span><span class="o">$</span><span class="n">http_host</span><span class="p">;</span>
<span class="w">            </span><span class="n">proxy_set_header</span><span class="w"> </span><span class="n">X</span><span class="o">-</span><span class="n">Real</span><span class="o">-</span><span class="n">IP</span><span class="w"> </span><span class="o">$</span><span class="n">remote_addr</span><span class="p">;</span>
<span class="w">            </span><span class="n">proxy_redirect</span><span class="w"> </span><span class="n">off</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="n">location</span><span class="w"> </span><span class="o">/</span><span class="n">ws</span><span class="o">/</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">proxy_pass</span><span class="w"> </span><span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="mf">0.0</span><span class="o">.</span><span class="mf">0.0</span><span class="p">:</span><span class="mi">9000</span><span class="p">;</span>
<span class="w">            </span><span class="n">proxy_http_version</span><span class="w"> </span><span class="mf">1.1</span><span class="p">;</span>

<span class="w">            </span><span class="n">proxy_read_timeout</span><span class="w"> </span><span class="mi">86400</span><span class="p">;</span>
<span class="w">            </span><span class="n">proxy_redirect</span><span class="w">     </span><span class="n">off</span><span class="p">;</span>

<span class="w">            </span><span class="n">proxy_set_header</span><span class="w"> </span><span class="n">Upgrade</span><span class="w"> </span><span class="o">$</span><span class="n">http_upgrade</span><span class="p">;</span>
<span class="w">            </span><span class="n">proxy_set_header</span><span class="w"> </span><span class="n">Connection</span><span class="w"> </span><span class="s2">"upgrade"</span><span class="p">;</span>
<span class="w">            </span><span class="n">proxy_set_header</span><span class="w"> </span><span class="n">Host</span><span class="w"> </span><span class="o">$</span><span class="n">host</span><span class="p">;</span>
<span class="w">            </span><span class="n">proxy_set_header</span><span class="w"> </span><span class="n">X</span><span class="o">-</span><span class="n">Real</span><span class="o">-</span><span class="n">IP</span><span class="w"> </span><span class="o">$</span><span class="n">remote_addr</span><span class="p">;</span>
<span class="w">            </span><span class="n">proxy_set_header</span><span class="w"> </span><span class="n">X</span><span class="o">-</span><span class="n">Forwarded</span><span class="o">-</span><span class="n">For</span><span class="w"> </span><span class="o">$</span><span class="n">proxy_add_x_forwarded_for</span><span class="p">;</span>
<span class="w">            </span><span class="n">proxy_set_header</span><span class="w"> </span><span class="n">X</span><span class="o">-</span><span class="n">Forwarded</span><span class="o">-</span><span class="n">Host</span><span class="w"> </span><span class="o">$</span><span class="n">server_name</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="n">location</span><span class="w"> </span><span class="o">/</span><span class="k">static</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">alias</span><span class="w"> </span><span class="p">{{</span><span class="w"> </span><span class="n">project_root</span><span class="w"> </span><span class="p">}}</span><span class="o">/</span><span class="k">static</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="n">location</span><span class="w">  </span><span class="o">/</span><span class="n">favicon</span><span class="o">.</span><span class="n">ico</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">alias</span><span class="w"> </span><span class="p">{{</span><span class="w"> </span><span class="n">project_root</span><span class="w"> </span><span class="p">}}</span><span class="o">//</span><span class="k">static</span><span class="o">/</span><span class="n">img</span><span class="o">/</span><span class="n">favicon</span><span class="o">.</span><span class="n">ico</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="n">location</span><span class="w">  </span><span class="o">/</span><span class="n">robots</span><span class="o">.</span><span class="n">txt</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">alias</span><span class="w"> </span><span class="p">{{</span><span class="w"> </span><span class="n">project_root</span><span class="w"> </span><span class="p">}}</span><span class="o">/</span><span class="k">static</span><span class="o">/</span><span class="n">txt</span><span class="o">/</span><span class="n">robots</span><span class="o">.</span><span class="n">txt</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>

<span class="p">}</span>
</pre></div>

<h4>WSGI Server Setup</h4>
<p>We will use gunicorn for wsgi server. We can run gunicorn with</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>gunicorn<span class="w"> </span>avilpage.wsgi<span class="w"> </span>--bind<span class="w"> </span><span class="m">0</span>.0.0.0:8000<span class="w"> </span>--log-level<span class="w"> </span>error<span class="w"> </span>--log-file<span class="o">=</span>-<span class="w"> </span>--settings<span class="w"> </span>avilpage.production_settings
</pre></div>

<p>We can create a systemd unit file to make it as a service.</p>
<div class="code"><pre class="code literal-block"><span class="k">[Unit]</span>
<span class="na">Description</span><span class="o">=</span><span class="s">gunicorn</span>
<span class="na">After</span><span class="o">=</span><span class="s">network.target</span>


<span class="k">[Service]</span>
<span class="na">PIDFile</span><span class="o">=</span><span class="s">/run/gunicorn/pid</span>
<span class="na">User</span><span class="o">=</span><span class="s">root</span>
<span class="na">Group</span><span class="o">=</span><span class="s">root</span>
<span class="na">WorkingDirectory</span><span class="o">=</span><span class="s">{{ project_root }}</span>
<span class="na">Environment</span><span class="o">=</span><span class="s">"DJANGO_SETTINGS_MODULE={{ project_name }}.production_settings"</span>
<span class="na">ExecStart</span><span class="o">=</span><span class="s">{{ venv_bin }}/gunicorn {{ project_name}}.wsgi --bind 0.0.0.0:8000 --log-level error --log-file=- --workers 5 --preload</span>


<span class="na">ExecReload</span><span class="o">=</span><span class="s">/bin/kill -s HUP $MAINPID</span>
<span class="na">ExecStop</span><span class="o">=</span><span class="s">/bin/kill -s TERM $MAINPID</span>
<span class="na">Restart</span><span class="o">=</span><span class="s">on-abort</span>
<span class="na">PrivateTmp</span><span class="o">=</span><span class="s">true</span>


<span class="k">[Install]</span>
<span class="na">WantedBy</span><span class="o">=</span><span class="s">multi-user.target</span>
</pre></div>

<p>Whenever server restarts, systemd will automatically start gunicorn service. We can also restart gunicorn manually with</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>sudo<span class="w"> </span>service<span class="w"> </span>gunicorn<span class="w"> </span>restart
</pre></div>

<h4>ASGI Server Setup</h4>
<p>We will use daphne for ASGI server and it can be started with</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>daphne<span class="w"> </span>avilpage.asgi:application<span class="w"> </span>--bind<span class="w"> </span><span class="m">0</span>.0.0.0<span class="w"> </span>--port<span class="w"> </span><span class="m">9000</span><span class="w"> </span>--verbosity<span class="w"> </span><span class="m">1</span>
</pre></div>

<p>We can create a systemd unit file like the previous one to create a service.</p>
<div class="code"><pre class="code literal-block"><span class="k">[Unit]</span>
<span class="na">Description</span><span class="o">=</span><span class="s">daphne daemon</span>
<span class="na">After</span><span class="o">=</span><span class="s">network.target</span>


<span class="k">[Service]</span>
<span class="na">PIDFile</span><span class="o">=</span><span class="s">/run/daphne/pid</span>
<span class="na">User</span><span class="o">=</span><span class="s">root</span>
<span class="na">Group</span><span class="o">=</span><span class="s">root</span>
<span class="na">WorkingDirectory</span><span class="o">=</span><span class="s">{{ project_root }}</span>
<span class="na">Environment</span><span class="o">=</span><span class="s">"DJANGO_SETTINGS_MODULE={{ project_name }}.production_settings"</span>
<span class="na">ExecStart</span><span class="o">=</span><span class="s">{{ venv_bin }}/daphne --bind 0.0.0.0 --port 9000 --verbosity 0 {{project_name}}.asgi:application</span>
<span class="na">ExecReload</span><span class="o">=</span><span class="s">/bin/kill -s HUP $MAINPID</span>
<span class="na">ExecStop</span><span class="o">=</span><span class="s">/bin/kill -s TERM $MAINPID</span>
<span class="na">Restart</span><span class="o">=</span><span class="s">on-abort</span>
<span class="na">PrivateTmp</span><span class="o">=</span><span class="s">true</span>


<span class="k">[Install]</span>
<span class="na">WantedBy</span><span class="o">=</span><span class="s">multi-user.target</span>
</pre></div>

<h4>Deployment</h4>
<p>Here is <a href="https://github.com/ChillarAnand/eddie/blob/master/ubuntu/config/playbooks/django_setup.yml">an ansible playbook</a> which is used to deploy these config files to our server. To run the playbook on server <code>avilpage.com</code>, execute</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>ansible-playbook<span class="w"> </span>-i<span class="w"> </span>avilpage.com,<span class="w"> </span>django_setup.yml
</pre></div>

<h4>Scaling</h4>
<p>Now that we have deployed channels to production, we can do performance test to see how our server performs under load.</p>
<p>For WebSockets, we can use <a href="https://www.npmjs.com/package/thor">Thor</a> to run performance test.</p>
<div class="code"><pre class="code literal-block">thor<span class="w"> </span>-C<span class="w"> </span><span class="m">100</span><span class="w"> </span>-A<span class="w"> </span><span class="m">1000</span><span class="w"> </span>wss://avilpage.com/ws/books/
</pre></div>

<p>Our server is able to handle <code>100 requests per second</code> with a <code>latency of 800ms</code>. This is good enough for low traffic website.</p>
<p>To improve performance, we can use unix sockets instead of rip/port for gunicorn and daphne. Also, daphne has support for multiprocessing using <a href="../2018/05/deploying-scaling-django-channels.html">shared file descriptors</a>. Unfortunately, it doesn't work as expected. As <a href="https://github.com/django/daphne/issues/182#issuecomment-387507887">mentioned here</a>, we can use systemd templates and spawn multiple daphne process.</p>
<p>An alternate way is to use <a href="https://pypi.org/project/uvicorn/">uvicorn</a> to start multiple workers. Install uvicorn using pip</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>uvicorn
</pre></div>

<p>Start uvicorn ASGI server with</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>uvicorn<span class="w"> </span>avilpage.asgi<span class="w"> </span>--log-level<span class="w"> </span>critical<span class="w"> </span>--workers<span class="w"> </span><span class="m">4</span>
</pre></div>

<p>This will spin up 4 workers which should be able to handle more load. If this performance is not sufficient, we have to setup a load balancer and spin up multiple servers(just like scaling any other web application).</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../2018/04/reliable-way-to-test-external-apis-without-mocking.html" class="u-url">Reliable Way To Test External APIs Without Mocking</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Chillar Anand
            </span></p>
            <p class="dateline">
            <a href="../2018/04/reliable-way-to-test-external-apis-without-mocking.html" rel="bookmark">
            <time class="published dt-published" datetime="2018-04-08T21:21:21+05:30" itemprop="datePublished" title="2018-04-08">2018-04-08</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>Let us write a function which retrieves user information from GitHub API.</p>
<div class="code"><pre class="code literal-block"><span class="kn">import</span> <span class="nn">requests</span>


<span class="k">def</span> <span class="nf">get_github_user_info</span><span class="p">(</span><span class="n">username</span><span class="p">):</span>
    <span class="n">url</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">'https://api.github.com/users/</span><span class="si">{</span><span class="n">username</span><span class="si">}</span><span class="s1">'</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">response</span><span class="o">.</span><span class="n">ok</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span>
</pre></div>

<p>To test this function, we can write a test case to call the external API and check if it is returning valid data.</p>
<div class="code"><pre class="code literal-block"><span class="k">def</span> <span class="nf">test_get_github_user_info</span><span class="p">():</span>
    <span class="n">username</span> <span class="o">=</span> <span class="s1">'ChillarAnand'</span>
    <span class="n">info</span> <span class="o">=</span> <span class="n">get_github_user_info</span><span class="p">(</span><span class="n">username</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">info</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="k">assert</span> <span class="n">username</span> <span class="o">==</span> <span class="n">info</span><span class="p">[</span><span class="s1">'login'</span><span class="p">]</span>
</pre></div>

<p>Even though this test case is reliable, this won't be efficient when we have many APIs to test as it sends unwanted requests to external API and makes tests slower due to I/O.</p>
<p>A widely used solution to avoid external API calls is <a href="https://en.wikipedia.org/wiki/Mock_object">mocking</a>. Instead of getting the response from external API, use a mock object which returns similar data.</p>
<div class="code"><pre class="code literal-block"><span class="kn">from</span> <span class="nn">unittest</span> <span class="kn">import</span> <span class="n">mock</span>


<span class="k">def</span> <span class="nf">test_get_github_user_info_with_mock</span><span class="p">():</span>
    <span class="k">with</span> <span class="n">mock</span><span class="o">.</span><span class="n">patch</span><span class="p">(</span><span class="s1">'requests.get'</span><span class="p">)</span> <span class="k">as</span> <span class="n">mock_get</span><span class="p">:</span>
        <span class="n">username</span> <span class="o">=</span> <span class="s1">'ChillarAnand'</span>

        <span class="n">mock_get</span><span class="o">.</span><span class="n">return_value</span><span class="o">.</span><span class="n">ok</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">json_response</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"login"</span><span class="p">:</span> <span class="n">username</span><span class="p">}</span>
        <span class="n">mock_get</span><span class="o">.</span><span class="n">return_value</span><span class="o">.</span><span class="n">json</span><span class="o">.</span><span class="n">return_value</span> <span class="o">=</span> <span class="n">json_response</span>

        <span class="n">info</span> <span class="o">=</span> <span class="n">get_github_user_info</span><span class="p">(</span><span class="n">username</span><span class="p">)</span>

        <span class="k">assert</span> <span class="n">info</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="k">assert</span> <span class="n">username</span> <span class="o">==</span> <span class="n">info</span><span class="p">[</span><span class="s1">'login'</span><span class="p">]</span>
</pre></div>

<p>This solves above problems but creates additional problems.</p>
<ul>
<li>Unreliable. Even though test cases pass, we are not sure if API is up and is returning a valid response.</li>
<li>Maintenance. We need to ensure mock responses are up to date with API.</li>
</ul>
<p>To avoid this, we can cache the responses using <a href="https://pypi.python.org/pypi/requests-cache">requests-cache</a>.</p>
<div class="code"><pre class="code literal-block"><span class="kn">import</span> <span class="nn">requests_cache</span>

<span class="n">requests_cache</span><span class="o">.</span><span class="n">install_cache</span><span class="p">(</span><span class="s1">'github_cache'</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">test_get_github_user_info_without_mock</span><span class="p">():</span>
    <span class="n">username</span> <span class="o">=</span> <span class="s1">'ChillarAnand'</span>
    <span class="n">info</span> <span class="o">=</span> <span class="n">get_github_user_info</span><span class="p">(</span><span class="n">username</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">info</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="k">assert</span> <span class="n">username</span> <span class="o">==</span> <span class="n">info</span><span class="p">[</span><span class="s1">'login'</span><span class="p">]</span>
</pre></div>

<p>When running tests from developer machine, it will call the API for the first time and uses the cached response for subsequent API calls. On CI pipeline, it will hit the external API as there won't be any cache.</p>
<p>When the response from external API changes, we need to invalidate the cache. Even if we miss cache invalidation, test cases will fail in CI pipeline before going into production.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../2018/03/convert-browser-requests-to-python-requests.html" class="u-url">Convert Browser Requests To Python Requests For Scraping</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Chillar Anand
            </span></p>
            <p class="dateline">
            <a href="../2018/03/convert-browser-requests-to-python-requests.html" rel="bookmark">
            <time class="published dt-published" datetime="2018-03-26T21:21:21+05:30" itemprop="datePublished" title="2018-03-26">2018-03-26</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>Scraping content behind a login page is bit difficult as there are wide variety of authentication mechanisms and web server needs correct headers, session, cookies to authenticate the request.</p>
<p>If we need a crawler which runs everyday to scrape content, then we have to implement authentication mechanism. If we need to quickly scrape content just for once, implementing authentication is an overhead.</p>
<p>Instead, we can manually login to the website, capture an authenticated request and use it for scraping other pages by changing url/form parameters.</p>
<p>From browser developer options, we can capture <a href="https://curl.haxx.se/">curl</a> equivalent command for any request from <code>Network</code> tab with <code>copy as cURL</code> option.</p>
<p align="center">
<img src="../images/requests-python-browser.png" height="300px" width="600"></p>

<p>Here is one such request.</p>
<div class="code"><pre class="code literal-block"><span class="n">curl</span> <span class="s1">'http://avilpage.com/dummy'</span> <span class="o">-</span><span class="n">H</span> <span class="s1">'Cookie: ASPSESSIONIDSABAAQDA=FKOHHAGAFODIIGNNNDFKNGLM'</span> <span class="o">-</span><span class="n">H</span> <span class="s1">'Origin: http://avilpage.com'</span> <span class="o">-</span><span class="n">H</span> <span class="s1">'Accept-Encoding: gzip, deflate'</span> <span class="o">-</span><span class="n">H</span> <span class="s1">'Accept-Language: en-US,en;q=0.9,ms;q=0.8,te;q=0.7'</span> <span class="o">-</span><span class="n">H</span> <span class="s1">'Upgrade-Insecure-Requests: 1'</span> <span class="o">-</span><span class="n">H</span> <span class="s1">'User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36'</span> <span class="o">-</span><span class="n">H</span> <span class="s1">'Content-Type: application/x-www-form-urlencoded'</span> <span class="o">-</span><span class="n">H</span> <span class="s1">'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8'</span> <span class="o">-</span><span class="n">H</span> <span class="s1">'Cache-Control: max-age=0'</span> <span class="o">-</span><span class="n">H</span> <span class="s1">'Referer: http://avilpage.com/'</span> <span class="o">-</span><span class="n">H</span> <span class="s1">'Connection: keep-alive'</span> <span class="o">-</span><span class="n">H</span> <span class="s1">'DNT: 1'</span> <span class="o">--</span><span class="n">data</span> <span class="s1">'page=2&amp;category=python'</span> <span class="o">--</span><span class="n">compressed</span>
</pre></div>

<p>Once we get curl command, we can directly convert it to python requests using <a href="https://pypi.python.org/pypi/uncurl/">uncurl</a>.</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>uncurl
</pre></div>

<p>Since the copied curl request is in clipboard, we can pipe it to uncurl.</p>
<div class="code"><pre class="code literal-block"><span class="err">$</span> <span class="n">clipit</span> <span class="o">-</span><span class="n">c</span> <span class="o">|</span> <span class="n">uncurl</span>

<span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="s2">"http://avilpage.com/dummy"</span><span class="p">,</span>
    <span class="n">data</span><span class="o">=</span><span class="s1">'page=2&amp;category=python'</span><span class="p">,</span>
    <span class="n">headers</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">"Accept"</span><span class="p">:</span> <span class="s2">"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8"</span><span class="p">,</span>
        <span class="s2">"Accept-Encoding"</span><span class="p">:</span> <span class="s2">"gzip, deflate"</span><span class="p">,</span>
        <span class="s2">"Accept-Language"</span><span class="p">:</span> <span class="s2">"en-US,en;q=0.9,ms;q=0.8,te;q=0.7"</span><span class="p">,</span>
        <span class="s2">"Cache-Control"</span><span class="p">:</span> <span class="s2">"max-age=0"</span><span class="p">,</span>
        <span class="s2">"Content-Type"</span><span class="p">:</span> <span class="s2">"application/x-www-form-urlencoded"</span><span class="p">,</span>
        <span class="s2">"Origin"</span><span class="p">:</span> <span class="s2">"http://avilpage.com"</span><span class="p">,</span>
        <span class="s2">"Referer"</span><span class="p">:</span> <span class="s2">"http://avilpage.com/"</span><span class="p">,</span>
        <span class="s2">"Upgrade-Insecure-Requests"</span><span class="p">:</span> <span class="s2">"1"</span><span class="p">,</span>
        <span class="s2">"User-Agent"</span><span class="p">:</span> <span class="s2">"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36"</span>
    <span class="p">},</span>
    <span class="n">cookies</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">"ASPSESSIONIDSABAAQDA"</span><span class="p">:</span> <span class="s2">"FKOHHAGAFODIIGNNNDFKNGLM"</span>
    <span class="p">},</span>
<span class="p">)</span>
</pre></div>

<p>If we have to use some other programming language, we can use <a href="https://curl.trillworks.com/">curlconverter</a> to convert curl command to Go or Node.js equivalent code.</p>
<p>Now, we can use this code to get contents of current page and then continue scraping from the urls in it.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../2018/02/deploy-django-web-app-android.html" class="u-url">Running Django Web Apps On Android Devices</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Chillar Anand
            </span></p>
            <p class="dateline">
            <a href="../2018/02/deploy-django-web-app-android.html" rel="bookmark">
            <time class="published dt-published" datetime="2018-02-19T17:40:56+05:30" itemprop="datePublished" title="2018-02-19">2018-02-19</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>When deploying a django webapp to Linux servers, Nginx/Apache as server, PostgreSQL/MySQL as database are preferred. For this tutorial, we will be using django development server with SQLite database.</p>
<p>First install <a href="https://play.google.com/store/apps/details?id=berserker.android.apps.sshdroid">SSHDroid</a> app on Android. It will start ssh server on port 2222. If android phone is rooted, we can run ssh on port 22.</p>
<p>Now install <a href="https://play.google.com/store/apps/details?id=org.qpython.qpy">QPython</a>. This comes bundled with pip, which will install required python packages.</p>
<p>Instead of installing these two apps, we can use <a href="https://github.com/termux/termux-app/">Termux</a>, <a href="https://github.com/corbinlc/GNURootDebian">GNURoot Debian</a> or some other app which provides Linux environment in Android. These apps will provide <code>apt</code> package manager, which can install <code>python</code> and <code>openssh-server</code> packages.</p>
<p>I have used <a href="https://github.com/ChillarAnand/django-bookmarks">django-bookmarks</a>, a simple CRUD app to test this setup. We can use rsync or adb shell to copy django project to android.</p>
<div class="code"><pre class="code literal-block">rsync<span class="w"> </span>-razP<span class="w"> </span>django-bookmarks<span class="w"> </span>:<span class="nv">$USER</span>@<span class="nv">$HOST</span>:/data/local/
</pre></div>

<p>Now ssh into android, install django and start django server.</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>ssh<span class="w"> </span>-v<span class="w"> </span><span class="nv">$USER</span>@<span class="nv">$HOST</span>
</pre></div>

<div class="code"><pre class="code literal-block">$<span class="w"> </span>python<span class="w"> </span>-m<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>django
$<span class="w"> </span><span class="nb">cd</span><span class="w"> </span>/data/local/django-bookmarks
$<span class="w"> </span>python<span class="w"> </span>manage.py<span class="w"> </span>runvserver
</pre></div>

<p>This will start development server on port 8000. To share this webapp with others, we will expose it with <a href="https://serveo.net/">serveo</a>.</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>ssh<span class="w"> </span>-R<span class="w"> </span><span class="m">80</span>:localhost:8000<span class="w"> </span>serveo.net

Forwarding<span class="w"> </span>HTTP<span class="w"> </span>traffic<span class="w"> </span>from<span class="w"> </span>https://incepro.serveo.net
Press<span class="w"> </span>g<span class="w"> </span>to<span class="w"> </span>start<span class="w"> </span>a<span class="w"> </span>GUI<span class="w"> </span>session<span class="w"> </span>and<span class="w"> </span>ctrl-c<span class="w"> </span>to<span class="w"> </span>quit.
</pre></div>

<p>Now we can share our django app with anyone.</p>
<p>I have used Moto G4 Plus phone to run this app. I have done a quick load test with Apache Bench.</p>
<div class="code"><pre class="code literal-block">ab<span class="w"> </span>-k<span class="w"> </span>-c<span class="w"> </span><span class="m">50</span><span class="w"> </span>-n<span class="w"> </span><span class="m">1000</span><span class="w">  </span><span class="se">\</span>
-H<span class="w"> </span><span class="s2">"Accept-Encoding: gzip, deflate"</span><span class="w"> </span><span class="se">\</span>
http://incepro.serveo/list/
</pre></div>

<p>It is able to server 15+ requests concurrently with an average response time of 800ms.</p>
<p>We can write a simple shell script or ansible playbook to automate this deployment process and we can host a low traffic website on an android phone if required.</p>
    </div>
    </article>
</div>
        <ul class="pager postindexpager clearfix">
<li class="previous"><a href="index-13.html" rel="prev">Newer posts</a></li>
            <li class="next"><a href="index-11.html" rel="next">Older posts</a></li>
        </ul>
<!--End of body content--><footer id="footer"><div class="container align-items-center justify-content-center d-flex">

<footer class="footer"><a href="https://github.com/ChillarAnand">
<img src="../images/icons8-github.svg" alt="github-chillar-anand" height="34"></a>

  

<a href="https://stackoverflow.com/users/2698552/chillar-anand">
<img src="../images/icons8-so.svg" alt="github-chillar-anand" height="30"></a>

  

<a href="https://youtube.com/@avilpage">
<img src="../images/icons8-youtube.svg" alt="github-chillar-anand" height="34"></a>

  

<a href="https://linkedin.com/in/chillaranand">
<img src="../images/icons8-linkedin.svg" alt="github-chillar-anand" height="34"></a>

  

<a href="https://twitter.com/chillaranand">
<img src="../images/icons8-twitter.svg" alt="github-chillar-anand" height="34"></a>

</footer>
</div>

<br><br></footer>
</div>
    </div>
    </div>

                <script src="../assets/js/jquery.min.js"></script><script src="../assets/js/popper.min.js"></script><script src="../assets/js/bootstrap.min.js"></script><script src="../assets/js/baguetteBox.min.js"></script><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
    </script>
</body>
</html>
